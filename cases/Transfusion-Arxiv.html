<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model</title>
<!--Generated on Tue Aug 20 08:57:06 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2408.11039v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S1" title="In Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2" title="In Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Background</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.SS1" title="In 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Language Modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.SS2" title="In 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Diffusion</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.SS2.SSS0.Px1" title="In 2.2 Diffusion ‣ 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Forward Process</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.SS2.SSS0.Px2" title="In 2.2 Diffusion ‣ 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Reverse Process</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.SS2.SSS0.Px3" title="In 2.2 Diffusion ‣ 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Noise Schedule</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.SS2.SSS0.Px4" title="In 2.2 Diffusion ‣ 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.SS3" title="In 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Latent Image Representation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3" title="In Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Transfusion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3.SS0.SSS0.Px1" title="In 3 Transfusion ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Data Representation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3.SS0.SSS0.Px2" title="In 3 Transfusion ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Model Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3.SS0.SSS0.Px3" title="In 3 Transfusion ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Transfusion Attention</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3.SS0.SSS0.Px4" title="In 3 Transfusion ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Training Objective</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3.SS0.SSS0.Px5" title="In 3 Transfusion ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4" title="In Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1" title="In 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Setup</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1.SSS0.Px1" title="In 4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1.SSS0.Px2" title="In 4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Baseline</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1.SSS0.Px3" title="In 4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1.SSS0.Px4" title="In 4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Latent Image Representation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1.SSS0.Px5" title="In 4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Model Configuration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1.SSS0.Px6" title="In 4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Optimization</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1.SSS0.Px7" title="In 4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title">Inference</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS2" title="In 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Controlled Comparison with Chameleon</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3" title="In 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Architecture Ablations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3.SSS1" title="In 4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Attention Masking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3.SSS2" title="In 4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Patch Size</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3.SSS3" title="In 4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.3 </span>Patch Encoding/Decoding Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3.SSS4" title="In 4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.4 </span>Image Noising</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS4" title="In 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Comparison with Image Generation Literature</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS5" title="In 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Image Editing</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S5" title="In Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S6" title="In Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#A1" title="In Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Autoencoder Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#A2" title="In Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Examples: Image Generation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#A3" title="In Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Examples: Image Editing</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Transfusion: Predict the Next Token and
<br class="ltx_break"/>Diffuse Images with One Multi-Modal Model</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_text ltx_font_bold" id="id1.1.1">Chunting Zhou<sup class="ltx_sup" id="id1.1.1.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id1.1.1.1.1">μ</span></sup></span>   <span class="ltx_text ltx_font_bold" id="id2.2.2">Lili Yu<sup class="ltx_sup" id="id2.2.2.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id2.2.2.1.1">μ∗</span></sup></span>   <span class="ltx_text ltx_font_bold" id="id3.3.3">Arun Babu<sup class="ltx_sup" id="id3.3.3.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id3.3.3.1.1">δ</span></sup></span>   <span class="ltx_text ltx_font_bold" id="id4.4.4">Kushal Tirumala<sup class="ltx_sup" id="id4.4.4.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id4.4.4.1.1">μ</span></sup></span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id5.5.5">Michihiro Yasunaga<sup class="ltx_sup" id="id5.5.5.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id5.5.5.1.1">μ</span></sup></span>   <span class="ltx_text ltx_font_bold" id="id6.6.6">Leonid Shamis<sup class="ltx_sup" id="id6.6.6.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id6.6.6.1.1">μ</span></sup></span>   <span class="ltx_text ltx_font_bold" id="id7.7.7">Jacob Kahn<sup class="ltx_sup" id="id7.7.7.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id7.7.7.1.1">μ</span></sup></span>   <span class="ltx_text ltx_font_bold" id="id8.8.8">Xuezhe Ma<sup class="ltx_sup" id="id8.8.8.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id8.8.8.1.1">σ</span></sup></span>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id9.9.9">Luke Zettlemoyer<sup class="ltx_sup" id="id9.9.9.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id9.9.9.1.1">μ</span></sup></span>   <span class="ltx_text ltx_font_bold" id="id10.10.10">Omer Levy<sup class="ltx_sup" id="id10.10.10.1"><span class="ltx_text ltx_font_medium ltx_font_italic" id="id10.10.10.1.1">†</span></sup></span>
<br class="ltx_break"/>
<br class="ltx_break"/><sup class="ltx_sup" id="id14.14.id1"><span class="ltx_text ltx_font_italic" id="id14.14.id1.1">μ</span></sup> Meta 
<br class="ltx_break"/><sup class="ltx_sup" id="id15.15.id2"><span class="ltx_text ltx_font_italic" id="id15.15.id2.1">δ</span></sup> Waymo
<sup class="ltx_sup" id="id16.16.id3"><span class="ltx_text ltx_font_italic" id="id16.16.id3.1">σ</span></sup> University of Southern California
</span><span class="ltx_author_notes">Equal contribution.Work done while at Meta.</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id17.id1">We introduce Transfusion, a recipe for training a multi-modal model over discrete and continuous data.
Transfusion combines the language modeling loss function (next token prediction) with diffusion to train a single transformer over mixed-modality sequences.
We pretrain multiple Transfusion models up to 7B parameters from scratch on a mixture of text and image data, establishing scaling laws with respect to a variety of uni- and cross-modal benchmarks.
Our experiments show that Transfusion scales significantly better than quantizing images and training a language model over discrete image tokens.
By introducing modality-specific encoding and decoding layers, we can further improve the performance of Transfusion models, and even compress each image to just 16 patches.
We further demonstrate that scaling our Transfusion recipe to 7B parameters and 2T multi-modal tokens produces a model that can generate images and text on a par with similar scale diffusion models and language models, reaping the benefits of both worlds.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Multi-modal generative models need to be able to perceive, process, and produce both discrete elements (such as text or code) and continuous elements (e.g. image, audio, and video data).
While language models trained on the next token prediction objective dominate discrete modalities <cite class="ltx_cite ltx_citemacro_citep">(OpenAI et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib31" title="">2024</a>; Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib14" title="">2024</a>)</cite>, diffusion models <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib22" title="">2020</a>; Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib37" title="">2022a</a>)</cite> and their generalizations <cite class="ltx_cite ltx_citemacro_citep">(Lipman et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib27" title="">2022</a>)</cite> are the state of the art for generating continuous modalities <cite class="ltx_cite ltx_citemacro_citep">(Dai et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib11" title="">2023</a>; Esser et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib17" title="">2024b</a>; Bar-Tal et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib2" title="">2024</a>)</cite>.
Many efforts have been made to combine these approaches, including extending a language model to use a diffusion model as a tool, either explicitly <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib29" title="">2023</a>)</cite> or by grafting a pretrained diffusion model onto the language model <cite class="ltx_cite ltx_citemacro_citep">(Dong et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib12" title="">2023</a>; Koh et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib24" title="">2024</a>)</cite>.
Alternatively, one can quantize the continuous modalities <cite class="ltx_cite ltx_citemacro_citep">(Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib48" title="">2017</a>)</cite> and train a standard language model over discrete tokens <cite class="ltx_cite ltx_citemacro_citep">(Ramesh et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib35" title="">2021</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib50" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib51" title="">2023</a>)</cite>, simplifying the model’s architecture at the cost of losing information.
In this work, we show it is possible to fully integrate both modalities, with no information loss, by training a single model to both predict discrete text tokens and diffuse continuous images.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">We introduce <span class="ltx_text ltx_font_bold" id="S1.p2.1.1">Transfusion</span>, a recipe for training a model that can seamlessly generate discrete and continuous modalities.
We demonstrate Transfusion by pretraining a transformer model on 50% text and 50% image data using a different objective for each modality: next token prediction for text and diffusion for images.
The model is exposed to both modalities and loss functions at each training step.
Standard embedding layers convert text tokens to vectors, while patchification layers represent each image as a sequence of patch vectors.
We apply causal attention for text tokens and bidirectional attention for image patches.
For inference, we introduce a decoding algorithm that combines the standard practices of text generation from language models and image generation from diffusion models.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates Transfusion.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In a controlled comparison with Chameleon’s discretization approach <cite class="ltx_cite ltx_citemacro_citep">(Chameleon Team, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib6" title="">2024</a>)</cite>, we show that Transfusion models scale better in every combination of modalities.
In text-to-image generation, we find that Transfusion exceeds the Chameleon approach at less than a third of the compute, as measured by both FID and CLIP scores.
When controlling for FLOPs, Transfusion achieves approximately 2<math alttext="\times" class="ltx_Math" display="inline" id="S1.p3.1.m1.1"><semantics id="S1.p3.1.m1.1a"><mo id="S1.p3.1.m1.1.1" xref="S1.p3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.p3.1.m1.1b"><times id="S1.p3.1.m1.1.1.cmml" xref="S1.p3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p3.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p3.1.m1.1d">×</annotation></semantics></math> lower FID scores than Chameleon models.
We observe a similar trend in image-to-text generation, where Transfusion matches Chameleon at 21.8% of the FLOPs.
Surprisingly, Transfusion is also more efficient at learning text-to-text prediction, achieving perplexity parity on text tasks around 50% to 60% of Chameleon’s FLOPs.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Ablation experiments reveal critical components and potential improvements for Transfusion.
We observe that the intra-image bidirectional attention is important, and that replacing it with causal attention hurts text-to-image generation.
We also find that adding U-Net down and up blocks to encode and decode images enables Transfusion to compress larger image patches with relatively small loss to performance, potentially decreasing the serving costs by up to 64<math alttext="\times" class="ltx_Math" display="inline" id="S1.p4.1.m1.1"><semantics id="S1.p4.1.m1.1a"><mo id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><times id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S1.p4.1.m1.1d">×</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Finally, we demonstrate that Transfusion can generate images at similar quality to other diffusion models.
We train from scratch a 7B transformer enhanced with U-Net down/up layers (0.27B parameters) over 2T tokens: 1T text tokens, and approximately 5 epochs of 692M images and their captions, amounting to another 1T patches/tokens.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">2</span></a> shows some generated images sampled from the model.
On the GenEval <cite class="ltx_cite ltx_citemacro_citep">(Ghosh et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib19" title="">2023</a>)</cite> benchmark, our model outperforms other popular models such as DALL-E 2 and SDXL; unlike those image generation models, it can generate text, reaching the same level of performance as Llama 1 on text benchmarks.
Our experiments thus show that Transfusion is a promising approach for training truly multi-modal models.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="172" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.4.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.5.2" style="font-size:90%;">A high-level illustration of Transfusion. A single transformer perceives, processes, and produces data of every modality. Discrete (text) tokens are processed autoregressively and trained on the <span class="ltx_text" id="S1.F1.5.2.1" style="color:#2171C7;">next token prediction</span> objective. Continuous (image) vectors are processed together in parallel and trained on the <span class="ltx_text" id="S1.F1.5.2.2" style="color:#E69500;">diffusion</span> objective. Marker BOI and EOI tokens separate the modalities.</span></figcaption>
</figure>
<figure class="ltx_figure" id="S1.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf1.g1" src="extracted/5802141/samples/avocado_armchair.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf1.2.1.1" style="font-size:90%;">((a))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf2.g1" src="extracted/5802141/samples/bread_apple_knife.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf2.2.1.1" style="font-size:90%;">((b))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf3.g1" src="extracted/5802141/samples/corgi.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf3.2.1.1" style="font-size:90%;">((c))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf4.g1" src="extracted/5802141/samples/fractal.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf4.2.1.1" style="font-size:90%;">((d))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf5.g1" src="extracted/5802141/samples/jay_macroons.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf5.2.1.1" style="font-size:90%;">((e))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf6.g1" src="extracted/5802141/samples/transfusion.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf6.2.1.1" style="font-size:90%;">((f))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf7.g1" src="extracted/5802141/samples/hand3.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf7.2.1.1" style="font-size:90%;">((g))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf8.g1" src="extracted/5802141/samples/bunny_cloud.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf8.2.1.1" style="font-size:90%;">((h))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf9"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf9.g1" src="extracted/5802141/samples/start_blue_tshirt.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf9.2.1.1" style="font-size:90%;">((i))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf10"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf10.g1" src="extracted/5802141/samples/tulips.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf10.2.1.1" style="font-size:90%;">((j))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf11"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf11.g1" src="extracted/5802141/samples/racoon_royal_2.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf11.2.1.1" style="font-size:90%;">((k))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf12"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf12.g1" src="extracted/5802141/samples/three_sphere.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf12.2.1.1" style="font-size:90%;">((l))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf13"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf13.g1" src="extracted/5802141/samples/transparent_duck.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf13.2.1.1" style="font-size:90%;">((m))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf14"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf14.g1" src="extracted/5802141/samples/chromeplated_cat.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf14.2.1.1" style="font-size:90%;">((n))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf15"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf15.g1" src="extracted/5802141/samples/kangaroo.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf15.2.1.1" style="font-size:90%;">((o))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S1.F2.sf16"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="S1.F2.sf16.g1" src="extracted/5802141/samples/egg_and_bird.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.sf16.2.1.1" style="font-size:90%;">((p))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S1.F2.3.2" style="font-size:90%;">Generated images from a 7B Transfusion trained on 2T multi-modal tokens.</span></figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Transfusion is a single model trained with two objectives: language modeling and diffusion.
Each of these objectives represents the state of the art in discrete and continuous data modeling, respectively.
This section briefly defines these objectives, as well as background on latent image representations.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Language Modeling</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.10">Given a sequence of discrete tokens <math alttext="y=y_{1},...,y_{n}" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.3"><semantics id="S2.SS1.p1.1.m1.3a"><mrow id="S2.SS1.p1.1.m1.3.3" xref="S2.SS1.p1.1.m1.3.3.cmml"><mi id="S2.SS1.p1.1.m1.3.3.4" xref="S2.SS1.p1.1.m1.3.3.4.cmml">y</mi><mo id="S2.SS1.p1.1.m1.3.3.3" xref="S2.SS1.p1.1.m1.3.3.3.cmml">=</mo><mrow id="S2.SS1.p1.1.m1.3.3.2.2" xref="S2.SS1.p1.1.m1.3.3.2.3.cmml"><msub id="S2.SS1.p1.1.m1.2.2.1.1.1" xref="S2.SS1.p1.1.m1.2.2.1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.2.2.1.1.1.2" xref="S2.SS1.p1.1.m1.2.2.1.1.1.2.cmml">y</mi><mn id="S2.SS1.p1.1.m1.2.2.1.1.1.3" xref="S2.SS1.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S2.SS1.p1.1.m1.3.3.2.2.3" xref="S2.SS1.p1.1.m1.3.3.2.3.cmml">,</mo><mi id="S2.SS1.p1.1.m1.1.1" mathvariant="normal" xref="S2.SS1.p1.1.m1.1.1.cmml">…</mi><mo id="S2.SS1.p1.1.m1.3.3.2.2.4" xref="S2.SS1.p1.1.m1.3.3.2.3.cmml">,</mo><msub id="S2.SS1.p1.1.m1.3.3.2.2.2" xref="S2.SS1.p1.1.m1.3.3.2.2.2.cmml"><mi id="S2.SS1.p1.1.m1.3.3.2.2.2.2" xref="S2.SS1.p1.1.m1.3.3.2.2.2.2.cmml">y</mi><mi id="S2.SS1.p1.1.m1.3.3.2.2.2.3" xref="S2.SS1.p1.1.m1.3.3.2.2.2.3.cmml">n</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.3b"><apply id="S2.SS1.p1.1.m1.3.3.cmml" xref="S2.SS1.p1.1.m1.3.3"><eq id="S2.SS1.p1.1.m1.3.3.3.cmml" xref="S2.SS1.p1.1.m1.3.3.3"></eq><ci id="S2.SS1.p1.1.m1.3.3.4.cmml" xref="S2.SS1.p1.1.m1.3.3.4">𝑦</ci><list id="S2.SS1.p1.1.m1.3.3.2.3.cmml" xref="S2.SS1.p1.1.m1.3.3.2.2"><apply id="S2.SS1.p1.1.m1.2.2.1.1.1.cmml" xref="S2.SS1.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.2.2.1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.1.m1.2.2.1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.2.2.1.1.1.2">𝑦</ci><cn id="S2.SS1.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S2.SS1.p1.1.m1.2.2.1.1.1.3">1</cn></apply><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">…</ci><apply id="S2.SS1.p1.1.m1.3.3.2.2.2.cmml" xref="S2.SS1.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.3.3.2.2.2.1.cmml" xref="S2.SS1.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S2.SS1.p1.1.m1.3.3.2.2.2.2.cmml" xref="S2.SS1.p1.1.m1.3.3.2.2.2.2">𝑦</ci><ci id="S2.SS1.p1.1.m1.3.3.2.2.2.3.cmml" xref="S2.SS1.p1.1.m1.3.3.2.2.2.3">𝑛</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.3c">y=y_{1},...,y_{n}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.3d">italic_y = italic_y start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_y start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> from a closed vocabulary <math alttext="V" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">V</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">italic_V</annotation></semantics></math>, a language model predicts the probability of the sequence <math alttext="P(y)" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><mrow id="S2.SS1.p1.3.m3.1.2" xref="S2.SS1.p1.3.m3.1.2.cmml"><mi id="S2.SS1.p1.3.m3.1.2.2" xref="S2.SS1.p1.3.m3.1.2.2.cmml">P</mi><mo id="S2.SS1.p1.3.m3.1.2.1" xref="S2.SS1.p1.3.m3.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.p1.3.m3.1.2.3.2" xref="S2.SS1.p1.3.m3.1.2.cmml"><mo id="S2.SS1.p1.3.m3.1.2.3.2.1" stretchy="false" xref="S2.SS1.p1.3.m3.1.2.cmml">(</mo><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">y</mi><mo id="S2.SS1.p1.3.m3.1.2.3.2.2" stretchy="false" xref="S2.SS1.p1.3.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.2.cmml" xref="S2.SS1.p1.3.m3.1.2"><times id="S2.SS1.p1.3.m3.1.2.1.cmml" xref="S2.SS1.p1.3.m3.1.2.1"></times><ci id="S2.SS1.p1.3.m3.1.2.2.cmml" xref="S2.SS1.p1.3.m3.1.2.2">𝑃</ci><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">P(y)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">italic_P ( italic_y )</annotation></semantics></math>.
Standard language models decompose <math alttext="P(y)" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m4.1"><semantics id="S2.SS1.p1.4.m4.1a"><mrow id="S2.SS1.p1.4.m4.1.2" xref="S2.SS1.p1.4.m4.1.2.cmml"><mi id="S2.SS1.p1.4.m4.1.2.2" xref="S2.SS1.p1.4.m4.1.2.2.cmml">P</mi><mo id="S2.SS1.p1.4.m4.1.2.1" xref="S2.SS1.p1.4.m4.1.2.1.cmml">⁢</mo><mrow id="S2.SS1.p1.4.m4.1.2.3.2" xref="S2.SS1.p1.4.m4.1.2.cmml"><mo id="S2.SS1.p1.4.m4.1.2.3.2.1" stretchy="false" xref="S2.SS1.p1.4.m4.1.2.cmml">(</mo><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">y</mi><mo id="S2.SS1.p1.4.m4.1.2.3.2.2" stretchy="false" xref="S2.SS1.p1.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.2.cmml" xref="S2.SS1.p1.4.m4.1.2"><times id="S2.SS1.p1.4.m4.1.2.1.cmml" xref="S2.SS1.p1.4.m4.1.2.1"></times><ci id="S2.SS1.p1.4.m4.1.2.2.cmml" xref="S2.SS1.p1.4.m4.1.2.2">𝑃</ci><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">P(y)</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m4.1d">italic_P ( italic_y )</annotation></semantics></math> into a product of conditional probabilities <math alttext="\prod_{i=1}^{n}P_{\theta}(y_{i}|y_{&lt;i})" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m5.1"><semantics id="S2.SS1.p1.5.m5.1a"><mrow id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml"><msubsup id="S2.SS1.p1.5.m5.1.1.2" xref="S2.SS1.p1.5.m5.1.1.2.cmml"><mo id="S2.SS1.p1.5.m5.1.1.2.2.2" xref="S2.SS1.p1.5.m5.1.1.2.2.2.cmml">∏</mo><mrow id="S2.SS1.p1.5.m5.1.1.2.2.3" xref="S2.SS1.p1.5.m5.1.1.2.2.3.cmml"><mi id="S2.SS1.p1.5.m5.1.1.2.2.3.2" xref="S2.SS1.p1.5.m5.1.1.2.2.3.2.cmml">i</mi><mo id="S2.SS1.p1.5.m5.1.1.2.2.3.1" xref="S2.SS1.p1.5.m5.1.1.2.2.3.1.cmml">=</mo><mn id="S2.SS1.p1.5.m5.1.1.2.2.3.3" xref="S2.SS1.p1.5.m5.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.SS1.p1.5.m5.1.1.2.3" xref="S2.SS1.p1.5.m5.1.1.2.3.cmml">n</mi></msubsup><mrow id="S2.SS1.p1.5.m5.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.cmml"><msub id="S2.SS1.p1.5.m5.1.1.1.3" xref="S2.SS1.p1.5.m5.1.1.1.3.cmml"><mi id="S2.SS1.p1.5.m5.1.1.1.3.2" xref="S2.SS1.p1.5.m5.1.1.1.3.2.cmml">P</mi><mi id="S2.SS1.p1.5.m5.1.1.1.3.3" xref="S2.SS1.p1.5.m5.1.1.1.3.3.cmml">θ</mi></msub><mo id="S2.SS1.p1.5.m5.1.1.1.2" xref="S2.SS1.p1.5.m5.1.1.1.2.cmml">⁢</mo><mrow id="S2.SS1.p1.5.m5.1.1.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.cmml"><mo id="S2.SS1.p1.5.m5.1.1.1.1.1.2" stretchy="false" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p1.5.m5.1.1.1.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.cmml"><msub id="S2.SS1.p1.5.m5.1.1.1.1.1.1.2" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.cmml"><mi id="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.2" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.3" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.cmml"><mi id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.2" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.2.cmml">y</mi><mrow id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.cmml"><mi id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.2" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.1" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.3" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msub></mrow><mo id="S2.SS1.p1.5.m5.1.1.1.1.1.3" stretchy="false" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1"><apply id="S2.SS1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.2.1.cmml" xref="S2.SS1.p1.5.m5.1.1.2">superscript</csymbol><apply id="S2.SS1.p1.5.m5.1.1.2.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.2.2.1.cmml" xref="S2.SS1.p1.5.m5.1.1.2">subscript</csymbol><csymbol cd="latexml" id="S2.SS1.p1.5.m5.1.1.2.2.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2.2.2">product</csymbol><apply id="S2.SS1.p1.5.m5.1.1.2.2.3.cmml" xref="S2.SS1.p1.5.m5.1.1.2.2.3"><eq id="S2.SS1.p1.5.m5.1.1.2.2.3.1.cmml" xref="S2.SS1.p1.5.m5.1.1.2.2.3.1"></eq><ci id="S2.SS1.p1.5.m5.1.1.2.2.3.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2.2.3.2">𝑖</ci><cn id="S2.SS1.p1.5.m5.1.1.2.2.3.3.cmml" type="integer" xref="S2.SS1.p1.5.m5.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.SS1.p1.5.m5.1.1.2.3.cmml" xref="S2.SS1.p1.5.m5.1.1.2.3">𝑛</ci></apply><apply id="S2.SS1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1"><times id="S2.SS1.p1.5.m5.1.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.2"></times><apply id="S2.SS1.p1.5.m5.1.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.3.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.1.3.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.3.2">𝑃</ci><ci id="S2.SS1.p1.5.m5.1.1.1.3.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.3.3">𝜃</ci></apply><apply id="S2.SS1.p1.5.m5.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.p1.5.m5.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.2">𝑦</ci><ci id="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.2">𝑦</ci><apply id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3"><lt id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.1.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.2.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.3.cmml" xref="S2.SS1.p1.5.m5.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">\prod_{i=1}^{n}P_{\theta}(y_{i}|y_{&lt;i})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m5.1d">∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_P start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_y start_POSTSUBSCRIPT &lt; italic_i end_POSTSUBSCRIPT )</annotation></semantics></math>.
This creates an autoregressive classification task, where the probability distribution of each token <math alttext="y_{i}" class="ltx_Math" display="inline" id="S2.SS1.p1.6.m6.1"><semantics id="S2.SS1.p1.6.m6.1a"><msub id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml"><mi id="S2.SS1.p1.6.m6.1.1.2" xref="S2.SS1.p1.6.m6.1.1.2.cmml">y</mi><mi id="S2.SS1.p1.6.m6.1.1.3" xref="S2.SS1.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><apply id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m6.1.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.p1.6.m6.1.1.2.cmml" xref="S2.SS1.p1.6.m6.1.1.2">𝑦</ci><ci id="S2.SS1.p1.6.m6.1.1.3.cmml" xref="S2.SS1.p1.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">y_{i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.6.m6.1d">italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is predicted conditioned on the prefix of a sequence <math alttext="y_{&lt;i}" class="ltx_Math" display="inline" id="S2.SS1.p1.7.m7.1"><semantics id="S2.SS1.p1.7.m7.1a"><msub id="S2.SS1.p1.7.m7.1.1" xref="S2.SS1.p1.7.m7.1.1.cmml"><mi id="S2.SS1.p1.7.m7.1.1.2" xref="S2.SS1.p1.7.m7.1.1.2.cmml">y</mi><mrow id="S2.SS1.p1.7.m7.1.1.3" xref="S2.SS1.p1.7.m7.1.1.3.cmml"><mi id="S2.SS1.p1.7.m7.1.1.3.2" xref="S2.SS1.p1.7.m7.1.1.3.2.cmml"></mi><mo id="S2.SS1.p1.7.m7.1.1.3.1" xref="S2.SS1.p1.7.m7.1.1.3.1.cmml">&lt;</mo><mi id="S2.SS1.p1.7.m7.1.1.3.3" xref="S2.SS1.p1.7.m7.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.7.m7.1b"><apply id="S2.SS1.p1.7.m7.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.7.m7.1.1.1.cmml" xref="S2.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p1.7.m7.1.1.2.cmml" xref="S2.SS1.p1.7.m7.1.1.2">𝑦</ci><apply id="S2.SS1.p1.7.m7.1.1.3.cmml" xref="S2.SS1.p1.7.m7.1.1.3"><lt id="S2.SS1.p1.7.m7.1.1.3.1.cmml" xref="S2.SS1.p1.7.m7.1.1.3.1"></lt><csymbol cd="latexml" id="S2.SS1.p1.7.m7.1.1.3.2.cmml" xref="S2.SS1.p1.7.m7.1.1.3.2">absent</csymbol><ci id="S2.SS1.p1.7.m7.1.1.3.3.cmml" xref="S2.SS1.p1.7.m7.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.7.m7.1c">y_{&lt;i}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.7.m7.1d">italic_y start_POSTSUBSCRIPT &lt; italic_i end_POSTSUBSCRIPT</annotation></semantics></math> using a single distribution <math alttext="P_{\theta}" class="ltx_Math" display="inline" id="S2.SS1.p1.8.m8.1"><semantics id="S2.SS1.p1.8.m8.1a"><msub id="S2.SS1.p1.8.m8.1.1" xref="S2.SS1.p1.8.m8.1.1.cmml"><mi id="S2.SS1.p1.8.m8.1.1.2" xref="S2.SS1.p1.8.m8.1.1.2.cmml">P</mi><mi id="S2.SS1.p1.8.m8.1.1.3" xref="S2.SS1.p1.8.m8.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.8.m8.1b"><apply id="S2.SS1.p1.8.m8.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.8.m8.1.1.1.cmml" xref="S2.SS1.p1.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.p1.8.m8.1.1.2.cmml" xref="S2.SS1.p1.8.m8.1.1.2">𝑃</ci><ci id="S2.SS1.p1.8.m8.1.1.3.cmml" xref="S2.SS1.p1.8.m8.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.8.m8.1c">P_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.8.m8.1d">italic_P start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> parameterized by <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS1.p1.9.m9.1"><semantics id="S2.SS1.p1.9.m9.1a"><mi id="S2.SS1.p1.9.m9.1.1" xref="S2.SS1.p1.9.m9.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.9.m9.1b"><ci id="S2.SS1.p1.9.m9.1.1.cmml" xref="S2.SS1.p1.9.m9.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.9.m9.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.9.m9.1d">italic_θ</annotation></semantics></math>.
The model can be optimized by minimizing the cross-entropy between <math alttext="P_{\theta}" class="ltx_Math" display="inline" id="S2.SS1.p1.10.m10.1"><semantics id="S2.SS1.p1.10.m10.1a"><msub id="S2.SS1.p1.10.m10.1.1" xref="S2.SS1.p1.10.m10.1.1.cmml"><mi id="S2.SS1.p1.10.m10.1.1.2" xref="S2.SS1.p1.10.m10.1.1.2.cmml">P</mi><mi id="S2.SS1.p1.10.m10.1.1.3" xref="S2.SS1.p1.10.m10.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.10.m10.1b"><apply id="S2.SS1.p1.10.m10.1.1.cmml" xref="S2.SS1.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.10.m10.1.1.1.cmml" xref="S2.SS1.p1.10.m10.1.1">subscript</csymbol><ci id="S2.SS1.p1.10.m10.1.1.2.cmml" xref="S2.SS1.p1.10.m10.1.1.2">𝑃</ci><ci id="S2.SS1.p1.10.m10.1.1.3.cmml" xref="S2.SS1.p1.10.m10.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.10.m10.1c">P_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.10.m10.1d">italic_P start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> and the empirical distribution of the data, yielding the standard next-token prediction objective, colloquially referred to as <span class="ltx_text ltx_font_italic" id="S2.SS1.p1.10.1">LM loss</span>:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{LM}}=\mathbb{E}_{y_{i}}\big{[}-\log P_{\theta}(y_{i}|y_{&lt;i}%
)\big{]}" class="ltx_Math" display="block" id="S2.E1.m1.1"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml"><msub id="S2.E1.m1.1.1.3" xref="S2.E1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.3.2" xref="S2.E1.m1.1.1.3.2.cmml">ℒ</mi><mtext id="S2.E1.m1.1.1.3.3" xref="S2.E1.m1.1.1.3.3a.cmml">LM</mtext></msub><mo id="S2.E1.m1.1.1.2" xref="S2.E1.m1.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml"><msub id="S2.E1.m1.1.1.1.3" xref="S2.E1.m1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.3.2.cmml">𝔼</mi><msub id="S2.E1.m1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.3.3.2.cmml">y</mi><mi id="S2.E1.m1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.3.3.3.cmml">i</mi></msub></msub><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.2.cmml"><mo id="S2.E1.m1.1.1.1.1.1.2" maxsize="120%" minsize="120%" xref="S2.E1.m1.1.1.1.1.2.1.cmml">[</mo><mrow id="S2.E1.m1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1a" rspace="0.167em" xref="S2.E1.m1.1.1.1.1.1.1.cmml">−</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml">log</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.3a" lspace="0.167em" xref="S2.E1.m1.1.1.1.1.1.1.1.3.cmml">⁡</mo><msub id="S2.E1.m1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2.2.cmml">P</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.3.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2.3.cmml">θ</mi></msub></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml">y</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo fence="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml">y</mi><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml"></mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">&lt;</mo><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">i</mi></mrow></msub></mrow><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.1.3" maxsize="120%" minsize="120%" xref="S2.E1.m1.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1"><eq id="S2.E1.m1.1.1.2.cmml" xref="S2.E1.m1.1.1.2"></eq><apply id="S2.E1.m1.1.1.3.cmml" xref="S2.E1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.3.2">ℒ</ci><ci id="S2.E1.m1.1.1.3.3a.cmml" xref="S2.E1.m1.1.1.3.3"><mtext id="S2.E1.m1.1.1.3.3.cmml" mathsize="70%" xref="S2.E1.m1.1.1.3.3">LM</mtext></ci></apply><apply id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><times id="S2.E1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.3.2">𝔼</ci><apply id="S2.E1.m1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.3.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.3.3.2">𝑦</ci><ci id="S2.E1.m1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.3.3.3">𝑖</ci></apply></apply><apply id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1"><minus id="S2.E1.m1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1"></minus><apply id="S2.E1.m1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.2"></times><apply id="S2.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3"><log id="S2.E1.m1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.1"></log><apply id="S2.E1.m1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2.2">𝑃</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.3.2.3">𝜃</ci></apply></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.2">𝑦</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.2">𝑦</ci><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3"><lt id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.1"></lt><csymbol cd="latexml" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.2">absent</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\mathcal{L}_{\text{LM}}=\mathbb{E}_{y_{i}}\big{[}-\log P_{\theta}(y_{i}|y_{&lt;i}%
)\big{]}</annotation><annotation encoding="application/x-llamapun" id="S2.E1.m1.1d">caligraphic_L start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ - roman_log italic_P start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( italic_y start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT | italic_y start_POSTSUBSCRIPT &lt; italic_i end_POSTSUBSCRIPT ) ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.p1.11">Once trained, language models can also be used to generate text by sampling token by token from the model distribution <math alttext="P_{\theta}" class="ltx_Math" display="inline" id="S2.SS1.p1.11.m1.1"><semantics id="S2.SS1.p1.11.m1.1a"><msub id="S2.SS1.p1.11.m1.1.1" xref="S2.SS1.p1.11.m1.1.1.cmml"><mi id="S2.SS1.p1.11.m1.1.1.2" xref="S2.SS1.p1.11.m1.1.1.2.cmml">P</mi><mi id="S2.SS1.p1.11.m1.1.1.3" xref="S2.SS1.p1.11.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.11.m1.1b"><apply id="S2.SS1.p1.11.m1.1.1.cmml" xref="S2.SS1.p1.11.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.11.m1.1.1.1.cmml" xref="S2.SS1.p1.11.m1.1.1">subscript</csymbol><ci id="S2.SS1.p1.11.m1.1.1.2.cmml" xref="S2.SS1.p1.11.m1.1.1.2">𝑃</ci><ci id="S2.SS1.p1.11.m1.1.1.3.cmml" xref="S2.SS1.p1.11.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.11.m1.1c">P_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.11.m1.1d">italic_P start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math>, typically using temperature and top-p truncation.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Diffusion</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.2">Denoising diffusion probabilistic models (a.k.a. <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.2.1">DDPM</span> or <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.2.2">diffusion models</span>) operate on the principle of learning to reverse a gradual noise-addition process <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib22" title="">2020</a>)</cite>.
Unlike language models that typically work with discrete tokens (<math alttext="y" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mi id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><ci id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">y</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">italic_y</annotation></semantics></math>), diffusion models operate over continuous vectors (<math alttext="\mathbf{x}" class="ltx_Math" display="inline" id="S2.SS2.p1.2.m2.1"><semantics id="S2.SS2.p1.2.m2.1a"><mi id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml">𝐱</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><ci id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">𝐱</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">\mathbf{x}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.2.m2.1d">bold_x</annotation></semantics></math>), making them particularly suited for tasks involving continuous data like images.
The diffusion framework involves two processes: a forward process that describes how the original data is turned into noise, and a reverse process of denoising that the model learns to perform.</p>
</div>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Forward Process</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.8">From a mathematical perspective, the forward process defines how the noised data (which serves as the model input) is created.
Given a data point <math alttext="\mathbf{x}_{0}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px1.p1.1.m1.1a"><msub id="S2.SS2.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml">𝐱</mi><mn id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.2">𝐱</ci><cn id="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.1.m1.1c">\mathbf{x}_{0}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.1.m1.1d">bold_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math>, <cite class="ltx_cite ltx_citemacro_citet">Ho et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib22" title="">2020</a>)</cite> define a Markov chain that gradually adds Gaussian noise over <math alttext="T" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.2.m2.1"><semantics id="S2.SS2.SSS0.Px1.p1.2.m2.1a"><mi id="S2.SS2.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.2.m2.1b"><ci id="S2.SS2.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.2.m2.1d">italic_T</annotation></semantics></math> steps, creating a sequence of increasingly noisy versions <math alttext="\mathbf{x}_{1},\mathbf{x}_{2},...,\mathbf{x}_{T}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.3.m3.4"><semantics id="S2.SS2.SSS0.Px1.p1.3.m3.4a"><mrow id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.4.cmml"><msub id="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.2.cmml">𝐱</mi><mn id="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.3" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.4" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.4.cmml">,</mo><msub id="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.cmml"><mi id="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.2.cmml">𝐱</mi><mn id="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.3" xref="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.3.cmml">2</mn></msub><mo id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.5" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.4.cmml">,</mo><mi id="S2.SS2.SSS0.Px1.p1.3.m3.1.1" mathvariant="normal" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml">…</mi><mo id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.6" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.4.cmml">,</mo><msub id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.2" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.3" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.3.cmml">T</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.3.m3.4b"><list id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.4.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3"><apply id="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.2">𝐱</ci><cn id="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.3.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.3.m3.2.2.1.1.3">1</cn></apply><apply id="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.2">𝐱</ci><cn id="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.3.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.3.m3.3.3.2.2.3">2</cn></apply><ci id="S2.SS2.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.1.1">…</ci><apply id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.2">𝐱</ci><ci id="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.3.m3.4.4.3.3.3">𝑇</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.3.m3.4c">\mathbf{x}_{1},\mathbf{x}_{2},...,\mathbf{x}_{T}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.3.m3.4d">bold_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , bold_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , bold_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT</annotation></semantics></math>.
Each step of this process is defined by <math alttext="q(\mathbf{x}_{t}|\mathbf{x}_{t-1})=\mathcal{N}(\mathbf{x}_{t};\sqrt{1-\beta_{t%
}}\mathbf{x}_{t-1},\beta_{t}\mathbf{I})" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.4.m4.4"><semantics id="S2.SS2.SSS0.Px1.p1.4.m4.4a"><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.4.4" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.cmml"><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.3.cmml">q</mi><mo id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.2.cmml">⁢</mo><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml"><mo id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.2" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml"><msub id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.3.cmml">t</mi></msub><mo fence="false" id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.2.cmml">𝐱</mi><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.2.cmml">t</mi><mo id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.1.cmml">−</mo><mn id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.3" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.5" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.5.cmml">=</mo><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.5" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.5.cmml">𝒩</mi><mo id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.4" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.4.cmml">⁢</mo><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml"><mo id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.4" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml">(</mo><msub id="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.5" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml">;</mo><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.cmml"><msqrt id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.cmml"><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.cmml"><mn id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.2.cmml">1</mn><mo id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.1.cmml">−</mo><msub id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.2.cmml">β</mi><mi id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.1.cmml">⁢</mo><msub id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.2.cmml">𝐱</mi><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.2.cmml">t</mi><mo id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.1.cmml">−</mo><mn id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.6" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml">,</mo><mrow id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.cmml"><msub id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.cmml"><mi id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.2" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.2.cmml">β</mi><mi id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.3.cmml">t</mi></msub><mo id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.1" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.1.cmml">⁢</mo><mi id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.3" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.3.cmml">𝐈</mi></mrow><mo id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.7" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.4.m4.4b"><apply id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4"><eq id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.5.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.5"></eq><apply id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1"><times id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.2"></times><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.3">𝑞</ci><apply id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.2">𝐱</ci><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.2.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.2">𝐱</ci><apply id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3"><minus id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.1"></minus><ci id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.2">𝑡</ci><cn id="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.3.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.4.m4.1.1.1.1.1.1.3.3.3">1</cn></apply></apply></apply></apply><apply id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4"><times id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.4.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.4"></times><ci id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.5.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.5">𝒩</ci><list id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.4.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3"><apply id="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.2">𝐱</ci><ci id="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.2.2.2.1.1.1.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2"><times id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.1"></times><apply id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2"><root id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2a.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2"></root><apply id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2"><minus id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.1"></minus><cn id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.2.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.2">1</cn><apply id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.2">𝛽</ci><ci id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.2.2.3.3">𝑡</ci></apply></apply></apply><apply id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.2">𝐱</ci><apply id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3"><minus id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.1"></minus><ci id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.2">𝑡</ci><cn id="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.3.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.4.m4.3.3.3.2.2.2.3.3.3">1</cn></apply></apply></apply><apply id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3"><times id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.1"></times><apply id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.2">𝛽</ci><ci id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.2.3">𝑡</ci></apply><ci id="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.4.m4.4.4.4.3.3.3.3">𝐈</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.4.m4.4c">q(\mathbf{x}_{t}|\mathbf{x}_{t-1})=\mathcal{N}(\mathbf{x}_{t};\sqrt{1-\beta_{t%
}}\mathbf{x}_{t-1},\beta_{t}\mathbf{I})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.4.m4.4d">italic_q ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT ) = caligraphic_N ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ; square-root start_ARG 1 - italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG bold_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT , italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT bold_I )</annotation></semantics></math>, where <math alttext="\beta_{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.5.m5.1"><semantics id="S2.SS2.SSS0.Px1.p1.5.m5.1a"><msub id="S2.SS2.SSS0.Px1.p1.5.m5.1.1" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml">β</mi><mi id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.5.m5.1b"><apply id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.2">𝛽</ci><ci id="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.5.m5.1c">\beta_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.5.m5.1d">italic_β start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> increases over time according to a predefined noise schedule (see below).
This process can be reparameterized in a way that allows us to directly sample <math alttext="\mathbf{x}_{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.6.m6.1"><semantics id="S2.SS2.SSS0.Px1.p1.6.m6.1a"><msub id="S2.SS2.SSS0.Px1.p1.6.m6.1.1" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.6.m6.1.1.2" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px1.p1.6.m6.1.1.3" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.6.m6.1b"><apply id="S2.SS2.SSS0.Px1.p1.6.m6.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.6.m6.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.6.m6.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1.2">𝐱</ci><ci id="S2.SS2.SSS0.Px1.p1.6.m6.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.6.m6.1c">\mathbf{x}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.6.m6.1d">bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> from <math alttext="\mathbf{x}_{0}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.7.m7.1"><semantics id="S2.SS2.SSS0.Px1.p1.7.m7.1a"><msub id="S2.SS2.SSS0.Px1.p1.7.m7.1.1" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.cmml"><mi id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.2" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.2.cmml">𝐱</mi><mn id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.3" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.7.m7.1b"><apply id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.2">𝐱</ci><cn id="S2.SS2.SSS0.Px1.p1.7.m7.1.1.3.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.7.m7.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.7.m7.1c">\mathbf{x}_{0}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.7.m7.1d">bold_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> using a single sample of Gaussian noise <math alttext="\boldsymbol{\epsilon}\sim\mathcal{N}(\mathbf{0},\mathbf{I})" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.8.m8.2"><semantics id="S2.SS2.SSS0.Px1.p1.8.m8.2a"><mrow id="S2.SS2.SSS0.Px1.p1.8.m8.2.3" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.2" mathvariant="bold-italic" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.2.cmml">ϵ</mi><mo id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.1" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.1.cmml">∼</mo><mrow id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.2" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.2.cmml">𝒩</mi><mo id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.1" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.1.cmml">⁢</mo><mrow id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.2" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.1.cmml"><mo id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.2.1" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.1.cmml">(</mo><mn id="S2.SS2.SSS0.Px1.p1.8.m8.1.1" xref="S2.SS2.SSS0.Px1.p1.8.m8.1.1.cmml">𝟎</mn><mo id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.2.2" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.1.cmml">,</mo><mi id="S2.SS2.SSS0.Px1.p1.8.m8.2.2" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.2.cmml">𝐈</mi><mo id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.2.3" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.8.m8.2b"><apply id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3"><csymbol cd="latexml" id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.1">similar-to</csymbol><ci id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.2">bold-italic-ϵ</ci><apply id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3"><times id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.1"></times><ci id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.2">𝒩</ci><interval closure="open" id="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.3.3.3.2"><cn id="S2.SS2.SSS0.Px1.p1.8.m8.1.1.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.8.m8.1.1">0</cn><ci id="S2.SS2.SSS0.Px1.p1.8.m8.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.8.m8.2.2">𝐈</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.8.m8.2c">\boldsymbol{\epsilon}\sim\mathcal{N}(\mathbf{0},\mathbf{I})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.8.m8.2d">bold_italic_ϵ ∼ caligraphic_N ( bold_0 , bold_I )</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{x}_{t}=\sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t}}%
\boldsymbol{\epsilon}" class="ltx_Math" display="block" id="S2.E2.m1.1"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><msub id="S2.E2.m1.1.1.2" xref="S2.E2.m1.1.1.2.cmml"><mi id="S2.E2.m1.1.1.2.2" xref="S2.E2.m1.1.1.2.2.cmml">𝐱</mi><mi id="S2.E2.m1.1.1.2.3" xref="S2.E2.m1.1.1.2.3.cmml">t</mi></msub><mo id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.cmml">=</mo><mrow id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml"><mrow id="S2.E2.m1.1.1.3.2" xref="S2.E2.m1.1.1.3.2.cmml"><msqrt id="S2.E2.m1.1.1.3.2.2" xref="S2.E2.m1.1.1.3.2.2.cmml"><msub id="S2.E2.m1.1.1.3.2.2.2" xref="S2.E2.m1.1.1.3.2.2.2.cmml"><mover accent="true" id="S2.E2.m1.1.1.3.2.2.2.2" xref="S2.E2.m1.1.1.3.2.2.2.2.cmml"><mi id="S2.E2.m1.1.1.3.2.2.2.2.2" xref="S2.E2.m1.1.1.3.2.2.2.2.2.cmml">α</mi><mo id="S2.E2.m1.1.1.3.2.2.2.2.1" xref="S2.E2.m1.1.1.3.2.2.2.2.1.cmml">¯</mo></mover><mi id="S2.E2.m1.1.1.3.2.2.2.3" xref="S2.E2.m1.1.1.3.2.2.2.3.cmml">t</mi></msub></msqrt><mo id="S2.E2.m1.1.1.3.2.1" xref="S2.E2.m1.1.1.3.2.1.cmml">⁢</mo><msub id="S2.E2.m1.1.1.3.2.3" xref="S2.E2.m1.1.1.3.2.3.cmml"><mi id="S2.E2.m1.1.1.3.2.3.2" xref="S2.E2.m1.1.1.3.2.3.2.cmml">𝐱</mi><mn id="S2.E2.m1.1.1.3.2.3.3" xref="S2.E2.m1.1.1.3.2.3.3.cmml">0</mn></msub></mrow><mo id="S2.E2.m1.1.1.3.1" xref="S2.E2.m1.1.1.3.1.cmml">+</mo><mrow id="S2.E2.m1.1.1.3.3" xref="S2.E2.m1.1.1.3.3.cmml"><msqrt id="S2.E2.m1.1.1.3.3.2" xref="S2.E2.m1.1.1.3.3.2.cmml"><mrow id="S2.E2.m1.1.1.3.3.2.2" xref="S2.E2.m1.1.1.3.3.2.2.cmml"><mn id="S2.E2.m1.1.1.3.3.2.2.2" xref="S2.E2.m1.1.1.3.3.2.2.2.cmml">1</mn><mo id="S2.E2.m1.1.1.3.3.2.2.1" xref="S2.E2.m1.1.1.3.3.2.2.1.cmml">−</mo><msub id="S2.E2.m1.1.1.3.3.2.2.3" xref="S2.E2.m1.1.1.3.3.2.2.3.cmml"><mover accent="true" id="S2.E2.m1.1.1.3.3.2.2.3.2" xref="S2.E2.m1.1.1.3.3.2.2.3.2.cmml"><mi id="S2.E2.m1.1.1.3.3.2.2.3.2.2" xref="S2.E2.m1.1.1.3.3.2.2.3.2.2.cmml">α</mi><mo id="S2.E2.m1.1.1.3.3.2.2.3.2.1" xref="S2.E2.m1.1.1.3.3.2.2.3.2.1.cmml">¯</mo></mover><mi id="S2.E2.m1.1.1.3.3.2.2.3.3" xref="S2.E2.m1.1.1.3.3.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo id="S2.E2.m1.1.1.3.3.1" xref="S2.E2.m1.1.1.3.3.1.cmml">⁢</mo><mi class="ltx_mathvariant_bold-italic" id="S2.E2.m1.1.1.3.3.3" mathvariant="bold-italic" xref="S2.E2.m1.1.1.3.3.3.cmml">ϵ</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><eq id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"></eq><apply id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.2.2">𝐱</ci><ci id="S2.E2.m1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.2.3">𝑡</ci></apply><apply id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3"><plus id="S2.E2.m1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.3.1"></plus><apply id="S2.E2.m1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.3.2"><times id="S2.E2.m1.1.1.3.2.1.cmml" xref="S2.E2.m1.1.1.3.2.1"></times><apply id="S2.E2.m1.1.1.3.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2"><root id="S2.E2.m1.1.1.3.2.2a.cmml" xref="S2.E2.m1.1.1.3.2.2"></root><apply id="S2.E2.m1.1.1.3.2.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.2.2.2.1.cmml" xref="S2.E2.m1.1.1.3.2.2.2">subscript</csymbol><apply id="S2.E2.m1.1.1.3.2.2.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2.2.2"><ci id="S2.E2.m1.1.1.3.2.2.2.2.1.cmml" xref="S2.E2.m1.1.1.3.2.2.2.2.1">¯</ci><ci id="S2.E2.m1.1.1.3.2.2.2.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2.2.2.2">𝛼</ci></apply><ci id="S2.E2.m1.1.1.3.2.2.2.3.cmml" xref="S2.E2.m1.1.1.3.2.2.2.3">𝑡</ci></apply></apply><apply id="S2.E2.m1.1.1.3.2.3.cmml" xref="S2.E2.m1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.2.3.1.cmml" xref="S2.E2.m1.1.1.3.2.3">subscript</csymbol><ci id="S2.E2.m1.1.1.3.2.3.2.cmml" xref="S2.E2.m1.1.1.3.2.3.2">𝐱</ci><cn id="S2.E2.m1.1.1.3.2.3.3.cmml" type="integer" xref="S2.E2.m1.1.1.3.2.3.3">0</cn></apply></apply><apply id="S2.E2.m1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.3.3"><times id="S2.E2.m1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.3.3.1"></times><apply id="S2.E2.m1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.3.3.2"><root id="S2.E2.m1.1.1.3.3.2a.cmml" xref="S2.E2.m1.1.1.3.3.2"></root><apply id="S2.E2.m1.1.1.3.3.2.2.cmml" xref="S2.E2.m1.1.1.3.3.2.2"><minus id="S2.E2.m1.1.1.3.3.2.2.1.cmml" xref="S2.E2.m1.1.1.3.3.2.2.1"></minus><cn id="S2.E2.m1.1.1.3.3.2.2.2.cmml" type="integer" xref="S2.E2.m1.1.1.3.3.2.2.2">1</cn><apply id="S2.E2.m1.1.1.3.3.2.2.3.cmml" xref="S2.E2.m1.1.1.3.3.2.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.3.2.2.3.1.cmml" xref="S2.E2.m1.1.1.3.3.2.2.3">subscript</csymbol><apply id="S2.E2.m1.1.1.3.3.2.2.3.2.cmml" xref="S2.E2.m1.1.1.3.3.2.2.3.2"><ci id="S2.E2.m1.1.1.3.3.2.2.3.2.1.cmml" xref="S2.E2.m1.1.1.3.3.2.2.3.2.1">¯</ci><ci id="S2.E2.m1.1.1.3.3.2.2.3.2.2.cmml" xref="S2.E2.m1.1.1.3.3.2.2.3.2.2">𝛼</ci></apply><ci id="S2.E2.m1.1.1.3.3.2.2.3.3.cmml" xref="S2.E2.m1.1.1.3.3.2.2.3.3">𝑡</ci></apply></apply></apply><ci id="S2.E2.m1.1.1.3.3.3.cmml" xref="S2.E2.m1.1.1.3.3.3">bold-italic-ϵ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">\mathbf{x}_{t}=\sqrt{\bar{\alpha}_{t}}\mathbf{x}_{0}+\sqrt{1-\bar{\alpha}_{t}}%
\boldsymbol{\epsilon}</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.1d">bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = square-root start_ARG over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG bold_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + square-root start_ARG 1 - over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG bold_italic_ϵ</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.9">Here, <math alttext="\bar{\alpha}_{t}=\prod_{s=1}^{t}(1-\beta_{s})" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px1.p1.9.m1.1"><semantics id="S2.SS2.SSS0.Px1.p1.9.m1.1a"><mrow id="S2.SS2.SSS0.Px1.p1.9.m1.1.1" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.cmml"><msub id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.cmml"><mover accent="true" id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.cmml"><mi id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.2" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.2.cmml">α</mi><mo id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.1" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.1.cmml">¯</mo></mover><mi id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.3" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.3.cmml">t</mi></msub><mo id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.2" rspace="0.111em" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.2.cmml">=</mo><mrow id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.cmml"><msubsup id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.cmml"><mo id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.2" rspace="0em" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.2.cmml">∏</mo><mrow id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.2" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.2.cmml">s</mi><mo id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.1" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.3" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.3" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.3.cmml">t</mi></msubsup><mrow id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.cmml"><mo id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.2" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.cmml"><mn id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.2" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.2.cmml">β</mi><mi id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.3" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.3.cmml">s</mi></msub></mrow><mo id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.3" stretchy="false" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px1.p1.9.m1.1b"><apply id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1"><eq id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.2"></eq><apply id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3">subscript</csymbol><apply id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2"><ci id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.1">¯</ci><ci id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.2.2">𝛼</ci></apply><ci id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.3.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1"><apply id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2">superscript</csymbol><apply id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2">subscript</csymbol><csymbol cd="latexml" id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.2.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.2">product</csymbol><apply id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3"><eq id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.1"></eq><ci id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.2">𝑠</ci><cn id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.3.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.2.3">𝑡</ci></apply><apply id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1"><minus id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.1"></minus><cn id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.2.cmml" type="integer" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.2">1</cn><apply id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.2">𝛽</ci><ci id="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px1.p1.9.m1.1.1.1.1.1.1.3.3">𝑠</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px1.p1.9.m1.1c">\bar{\alpha}_{t}=\prod_{s=1}^{t}(1-\beta_{s})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px1.p1.9.m1.1d">over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ∏ start_POSTSUBSCRIPT italic_s = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_t end_POSTSUPERSCRIPT ( 1 - italic_β start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT )</annotation></semantics></math>, providing a useful abstraction over the original Markov chain.
In fact, both the training objective and the noise scheduler are eventually expressed (and implemented) in these terms.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Reverse Process</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.9">The diffusion model is trained to perform the reverse process <math alttext="p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px2.p1.1.m1.1a"><mrow id="S2.SS2.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><msub id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">p</mi><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">θ</mi></msub><mo id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">⁢</mo><mrow id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.cmml"><mo id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.cmml"><msub id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.2.cmml">𝐱</mi><mrow id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.cmml"><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.1.cmml">−</mo><mn id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.1" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.1.cmml">|</mo><msub id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.2" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.3" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.3.cmml">t</mi></msub></mrow><mo id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1"><times id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.2"></times><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.2">𝑝</ci><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.3.3">𝜃</ci></apply><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.1">conditional</csymbol><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.2">𝐱</ci><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3"><minus id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.1"></minus><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.2">𝑡</ci><cn id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.2">𝐱</ci><ci id="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.3.cmml" xref="S2.SS2.SSS0.Px2.p1.1.m1.1.1.1.1.1.3.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.1.m1.1c">p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT | bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>, learning to denoise the data step by step.
There are several ways to do so; in this work, we follow the approach of <cite class="ltx_cite ltx_citemacro_citet">Ho et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib22" title="">2020</a>)</cite> and model the Gaussian noise <math alttext="\boldsymbol{\epsilon}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.2.m2.1"><semantics id="S2.SS2.SSS0.Px2.p1.2.m2.1a"><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.SSS0.Px2.p1.2.m2.1.1" mathvariant="bold-italic" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.2.m2.1b"><ci id="S2.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.2.m2.1.1">bold-italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.2.m2.1c">\boldsymbol{\epsilon}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.2.m2.1d">bold_italic_ϵ</annotation></semantics></math> in Equation <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.E2" title="In Forward Process ‣ 2.2 Diffusion ‣ 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">2</span></a> as a proxy for the cumulative noise at step <math alttext="t" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.3.m3.1"><semantics id="S2.SS2.SSS0.Px2.p1.3.m3.1a"><mi id="S2.SS2.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.3.m3.1b"><ci id="S2.SS2.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.3.m3.1d">italic_t</annotation></semantics></math>.
Specifically, a model <math alttext="\epsilon_{\theta}(\cdot)" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.4.m4.1"><semantics id="S2.SS2.SSS0.Px2.p1.4.m4.1a"><mrow id="S2.SS2.SSS0.Px2.p1.4.m4.1.2" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.cmml"><msub id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.cmml"><mi id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.2" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.2.cmml">ϵ</mi><mi id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.3" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.3.cmml">θ</mi></msub><mo id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.1" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.1.cmml">⁢</mo><mrow id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.3.2" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.cmml"><mo id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.3.2.1" stretchy="false" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.cmml">(</mo><mo id="S2.SS2.SSS0.Px2.p1.4.m4.1.1" lspace="0em" rspace="0em" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1.cmml">⋅</mo><mo id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.3.2.2" stretchy="false" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.4.m4.1b"><apply id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2"><times id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.1.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.1"></times><apply id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.1.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.2.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.2">italic-ϵ</ci><ci id="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.3.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.2.2.3">𝜃</ci></apply><ci id="S2.SS2.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.4.m4.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.4.m4.1c">\epsilon_{\theta}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.4.m4.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( ⋅ )</annotation></semantics></math> with parameters <math alttext="\theta" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.5.m5.1"><semantics id="S2.SS2.SSS0.Px2.p1.5.m5.1a"><mi id="S2.SS2.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1.cmml">θ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.5.m5.1b"><ci id="S2.SS2.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.5.m5.1.1">𝜃</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.5.m5.1c">\theta</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.5.m5.1d">italic_θ</annotation></semantics></math> is trained to estimate the noise <math alttext="\boldsymbol{\epsilon}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.6.m6.1"><semantics id="S2.SS2.SSS0.Px2.p1.6.m6.1a"><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.SSS0.Px2.p1.6.m6.1.1" mathvariant="bold-italic" xref="S2.SS2.SSS0.Px2.p1.6.m6.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.6.m6.1b"><ci id="S2.SS2.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.6.m6.1.1">bold-italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.6.m6.1c">\boldsymbol{\epsilon}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.6.m6.1d">bold_italic_ϵ</annotation></semantics></math> given the noised data <math alttext="\mathbf{x}_{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.7.m7.1"><semantics id="S2.SS2.SSS0.Px2.p1.7.m7.1a"><msub id="S2.SS2.SSS0.Px2.p1.7.m7.1.1" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.cmml"><mi id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.2" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.3" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.7.m7.1b"><apply id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.2.cmml" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.2">𝐱</ci><ci id="S2.SS2.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="S2.SS2.SSS0.Px2.p1.7.m7.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.7.m7.1c">\mathbf{x}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.7.m7.1d">bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and timestep <math alttext="t" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.8.m8.1"><semantics id="S2.SS2.SSS0.Px2.p1.8.m8.1a"><mi id="S2.SS2.SSS0.Px2.p1.8.m8.1.1" xref="S2.SS2.SSS0.Px2.p1.8.m8.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.8.m8.1b"><ci id="S2.SS2.SSS0.Px2.p1.8.m8.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.8.m8.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.8.m8.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.8.m8.1d">italic_t</annotation></semantics></math>.
In practice, the model often conditions on additional contextual information <math alttext="c" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px2.p1.9.m9.1"><semantics id="S2.SS2.SSS0.Px2.p1.9.m9.1a"><mi id="S2.SS2.SSS0.Px2.p1.9.m9.1.1" xref="S2.SS2.SSS0.Px2.p1.9.m9.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px2.p1.9.m9.1b"><ci id="S2.SS2.SSS0.Px2.p1.9.m9.1.1.cmml" xref="S2.SS2.SSS0.Px2.p1.9.m9.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px2.p1.9.m9.1c">c</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px2.p1.9.m9.1d">italic_c</annotation></semantics></math>, such as a caption when generating an image.
The parameters of the noise prediction model are thus optimized by minimizing the mean squared error loss:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{DDPM}}=\mathbb{E}_{\mathbf{x}_{0},t,\boldsymbol{\epsilon}}%
\big{[}||\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_{t},t%
,c)||^{2}\big{]}" class="ltx_Math" display="block" id="S2.E3.m1.6"><semantics id="S2.E3.m1.6a"><mrow id="S2.E3.m1.6.6" xref="S2.E3.m1.6.6.cmml"><msub id="S2.E3.m1.6.6.3" xref="S2.E3.m1.6.6.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E3.m1.6.6.3.2" xref="S2.E3.m1.6.6.3.2.cmml">ℒ</mi><mtext id="S2.E3.m1.6.6.3.3" xref="S2.E3.m1.6.6.3.3a.cmml">DDPM</mtext></msub><mo id="S2.E3.m1.6.6.2" xref="S2.E3.m1.6.6.2.cmml">=</mo><mrow id="S2.E3.m1.6.6.1" xref="S2.E3.m1.6.6.1.cmml"><msub id="S2.E3.m1.6.6.1.3" xref="S2.E3.m1.6.6.1.3.cmml"><mi id="S2.E3.m1.6.6.1.3.2" xref="S2.E3.m1.6.6.1.3.2.cmml">𝔼</mi><mrow id="S2.E3.m1.3.3.3.3" xref="S2.E3.m1.3.3.3.4.cmml"><msub id="S2.E3.m1.3.3.3.3.1" xref="S2.E3.m1.3.3.3.3.1.cmml"><mi id="S2.E3.m1.3.3.3.3.1.2" xref="S2.E3.m1.3.3.3.3.1.2.cmml">𝐱</mi><mn id="S2.E3.m1.3.3.3.3.1.3" xref="S2.E3.m1.3.3.3.3.1.3.cmml">0</mn></msub><mo id="S2.E3.m1.3.3.3.3.2" xref="S2.E3.m1.3.3.3.4.cmml">,</mo><mi id="S2.E3.m1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.cmml">t</mi><mo id="S2.E3.m1.3.3.3.3.3" xref="S2.E3.m1.3.3.3.4.cmml">,</mo><mi class="ltx_mathvariant_bold-italic" id="S2.E3.m1.2.2.2.2" mathvariant="bold-italic" xref="S2.E3.m1.2.2.2.2.cmml">ϵ</mi></mrow></msub><mo id="S2.E3.m1.6.6.1.2" xref="S2.E3.m1.6.6.1.2.cmml">⁢</mo><mrow id="S2.E3.m1.6.6.1.1.1" xref="S2.E3.m1.6.6.1.1.2.cmml"><mo id="S2.E3.m1.6.6.1.1.1.2" maxsize="120%" minsize="120%" xref="S2.E3.m1.6.6.1.1.2.1.cmml">[</mo><msup id="S2.E3.m1.6.6.1.1.1.1" xref="S2.E3.m1.6.6.1.1.1.1.cmml"><mrow id="S2.E3.m1.6.6.1.1.1.1.1.1" xref="S2.E3.m1.6.6.1.1.1.1.1.2.cmml"><mo id="S2.E3.m1.6.6.1.1.1.1.1.1.2" stretchy="false" xref="S2.E3.m1.6.6.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S2.E3.m1.6.6.1.1.1.1.1.1.1" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.E3.m1.6.6.1.1.1.1.1.1.1.3" mathvariant="bold-italic" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.3.cmml">ϵ</mi><mo id="S2.E3.m1.6.6.1.1.1.1.1.1.1.2" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.cmml"><msub id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.2" mathvariant="bold-italic" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.2.cmml">ϵ</mi><mi id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E3.m1.4.4" xref="S2.E3.m1.4.4.cmml">t</mi><mo id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.4" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.E3.m1.5.5" xref="S2.E3.m1.5.5.cmml">c</mi><mo id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.5" stretchy="false" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E3.m1.6.6.1.1.1.1.1.1.3" stretchy="false" xref="S2.E3.m1.6.6.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S2.E3.m1.6.6.1.1.1.1.3" xref="S2.E3.m1.6.6.1.1.1.1.3.cmml">2</mn></msup><mo id="S2.E3.m1.6.6.1.1.1.3" maxsize="120%" minsize="120%" xref="S2.E3.m1.6.6.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.6b"><apply id="S2.E3.m1.6.6.cmml" xref="S2.E3.m1.6.6"><eq id="S2.E3.m1.6.6.2.cmml" xref="S2.E3.m1.6.6.2"></eq><apply id="S2.E3.m1.6.6.3.cmml" xref="S2.E3.m1.6.6.3"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.3.1.cmml" xref="S2.E3.m1.6.6.3">subscript</csymbol><ci id="S2.E3.m1.6.6.3.2.cmml" xref="S2.E3.m1.6.6.3.2">ℒ</ci><ci id="S2.E3.m1.6.6.3.3a.cmml" xref="S2.E3.m1.6.6.3.3"><mtext id="S2.E3.m1.6.6.3.3.cmml" mathsize="70%" xref="S2.E3.m1.6.6.3.3">DDPM</mtext></ci></apply><apply id="S2.E3.m1.6.6.1.cmml" xref="S2.E3.m1.6.6.1"><times id="S2.E3.m1.6.6.1.2.cmml" xref="S2.E3.m1.6.6.1.2"></times><apply id="S2.E3.m1.6.6.1.3.cmml" xref="S2.E3.m1.6.6.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.3.1.cmml" xref="S2.E3.m1.6.6.1.3">subscript</csymbol><ci id="S2.E3.m1.6.6.1.3.2.cmml" xref="S2.E3.m1.6.6.1.3.2">𝔼</ci><list id="S2.E3.m1.3.3.3.4.cmml" xref="S2.E3.m1.3.3.3.3"><apply id="S2.E3.m1.3.3.3.3.1.cmml" xref="S2.E3.m1.3.3.3.3.1"><csymbol cd="ambiguous" id="S2.E3.m1.3.3.3.3.1.1.cmml" xref="S2.E3.m1.3.3.3.3.1">subscript</csymbol><ci id="S2.E3.m1.3.3.3.3.1.2.cmml" xref="S2.E3.m1.3.3.3.3.1.2">𝐱</ci><cn id="S2.E3.m1.3.3.3.3.1.3.cmml" type="integer" xref="S2.E3.m1.3.3.3.3.1.3">0</cn></apply><ci id="S2.E3.m1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1">𝑡</ci><ci id="S2.E3.m1.2.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2">bold-italic-ϵ</ci></list></apply><apply id="S2.E3.m1.6.6.1.1.2.cmml" xref="S2.E3.m1.6.6.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.6.6.1.1.2.1.cmml" xref="S2.E3.m1.6.6.1.1.1.2">delimited-[]</csymbol><apply id="S2.E3.m1.6.6.1.1.1.1.cmml" xref="S2.E3.m1.6.6.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.1.1.1.2.cmml" xref="S2.E3.m1.6.6.1.1.1.1">superscript</csymbol><apply id="S2.E3.m1.6.6.1.1.1.1.1.2.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.E3.m1.6.6.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.2">norm</csymbol><apply id="S2.E3.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1"><minus id="S2.E3.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.2"></minus><ci id="S2.E3.m1.6.6.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.3">bold-italic-ϵ</ci><apply id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1"><times id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.2"></times><apply id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.2">bold-italic-ϵ</ci><ci id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.3.3">𝜃</ci></apply><vector id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1"><apply id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="S2.E3.m1.4.4.cmml" xref="S2.E3.m1.4.4">𝑡</ci><ci id="S2.E3.m1.5.5.cmml" xref="S2.E3.m1.5.5">𝑐</ci></vector></apply></apply></apply><cn id="S2.E3.m1.6.6.1.1.1.1.3.cmml" type="integer" xref="S2.E3.m1.6.6.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.6c">\mathcal{L}_{\text{DDPM}}=\mathbb{E}_{\mathbf{x}_{0},t,\boldsymbol{\epsilon}}%
\big{[}||\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_{t},t%
,c)||^{2}\big{]}</annotation><annotation encoding="application/x-llamapun" id="S2.E3.m1.6d">caligraphic_L start_POSTSUBSCRIPT DDPM end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT bold_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_t , bold_italic_ϵ end_POSTSUBSCRIPT [ | | bold_italic_ϵ - bold_italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , italic_c ) | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Noise Schedule</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px3.p1.4">When creating a noised example <math alttext="\mathbf{x}_{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px3.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px3.p1.1.m1.1a"><msub id="S2.SS2.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.2">𝐱</ci><ci id="S2.SS2.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px3.p1.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.1.m1.1c">\mathbf{x}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px3.p1.1.m1.1d">bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> (Equation <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.E2" title="In Forward Process ‣ 2.2 Diffusion ‣ 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">2</span></a>), <math alttext="\bar{\alpha}_{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px3.p1.2.m2.1"><semantics id="S2.SS2.SSS0.Px3.p1.2.m2.1a"><msub id="S2.SS2.SSS0.Px3.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.cmml"><mover accent="true" id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.2" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.2.cmml">α</mi><mo id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.1" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.1.cmml">¯</mo></mover><mi id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.3" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.2.m2.1b"><apply id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1">subscript</csymbol><apply id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2"><ci id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.1">¯</ci><ci id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.2.2">𝛼</ci></apply><ci id="S2.SS2.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S2.SS2.SSS0.Px3.p1.2.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.2.m2.1c">\bar{\alpha}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px3.p1.2.m2.1d">over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> determines the variance of the noise for timestep <math alttext="t" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px3.p1.3.m3.1"><semantics id="S2.SS2.SSS0.Px3.p1.3.m3.1a"><mi id="S2.SS2.SSS0.Px3.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.3.m3.1b"><ci id="S2.SS2.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px3.p1.3.m3.1d">italic_t</annotation></semantics></math>.
In this work, we adopt the commonly used cosine scheduler <cite class="ltx_cite ltx_citemacro_cite">Nichol and Dhariwal (<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib30" title="">2021</a>)</cite>, which largely follows <math alttext="\sqrt{\bar{\alpha}_{t}}\approx\cos(\frac{t}{T}\cdot\frac{\pi}{2})" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px3.p1.4.m4.2"><semantics id="S2.SS2.SSS0.Px3.p1.4.m4.2a"><mrow id="S2.SS2.SSS0.Px3.p1.4.m4.2.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.cmml"><msqrt id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.cmml"><msub id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.cmml"><mover accent="true" id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.cmml"><mi id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.2.cmml">α</mi><mo id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.1" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.1.cmml">¯</mo></mover><mi id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.3" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.3.cmml">t</mi></msub></msqrt><mo id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.2.cmml">≈</mo><mrow id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.2.cmml"><mi id="S2.SS2.SSS0.Px3.p1.4.m4.1.1" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1.cmml">cos</mi><mo id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1a" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.2.cmml">⁡</mo><mrow id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.2.cmml"><mo id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.2" stretchy="false" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.2.cmml">(</mo><mrow id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.cmml"><mfrac id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.cmml"><mi id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.2.cmml">t</mi><mi id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.3" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.3.cmml">T</mi></mfrac><mo id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.1.cmml">⋅</mo><mfrac id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.2" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.2.cmml">π</mi><mn id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.3" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.3.cmml">2</mn></mfrac></mrow><mo id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.3" stretchy="false" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px3.p1.4.m4.2b"><apply id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2"><approx id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.2"></approx><apply id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3"><root id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3a.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3"></root><apply id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2">subscript</csymbol><apply id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2"><ci id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.1">¯</ci><ci id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.2.2">𝛼</ci></apply><ci id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.3.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.3.2.3">𝑡</ci></apply></apply><apply id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1"><cos id="S2.SS2.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.1.1"></cos><apply id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1"><ci id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.1">⋅</ci><apply id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2"><divide id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2"></divide><ci id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.2">𝑡</ci><ci id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.3.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.2.3">𝑇</ci></apply><apply id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3"><divide id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3"></divide><ci id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.2">𝜋</ci><cn id="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.3.cmml" type="integer" xref="S2.SS2.SSS0.Px3.p1.4.m4.2.2.1.1.1.1.3.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px3.p1.4.m4.2c">\sqrt{\bar{\alpha}_{t}}\approx\cos(\frac{t}{T}\cdot\frac{\pi}{2})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px3.p1.4.m4.2d">square-root start_ARG over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG ≈ roman_cos ( divide start_ARG italic_t end_ARG start_ARG italic_T end_ARG ⋅ divide start_ARG italic_π end_ARG start_ARG 2 end_ARG )</annotation></semantics></math> with some adjustments.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS2.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Inference</h5>
<div class="ltx_para" id="S2.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S2.SS2.SSS0.Px4.p1.6">Decoding is done iteratively, pealing away some of the noise at each step.
Starting with pure Gaussian noise at <math alttext="\mathbf{x}_{T}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px4.p1.1.m1.1"><semantics id="S2.SS2.SSS0.Px4.p1.1.m1.1a"><msub id="S2.SS2.SSS0.Px4.p1.1.m1.1.1" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.cmml"><mi id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.2" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px4.p1.1.m1.1b"><apply id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.2">𝐱</ci><ci id="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3.cmml" xref="S2.SS2.SSS0.Px4.p1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px4.p1.1.m1.1c">\mathbf{x}_{T}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px4.p1.1.m1.1d">bold_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT</annotation></semantics></math>, the model <math alttext="\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_{t},t,c)" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px4.p1.2.m2.3"><semantics id="S2.SS2.SSS0.Px4.p1.2.m2.3a"><mrow id="S2.SS2.SSS0.Px4.p1.2.m2.3.3" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.cmml"><msub id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.2" mathvariant="bold-italic" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.2.cmml">ϵ</mi><mi id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.3" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.3.cmml">θ</mi></msub><mo id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.2" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.2.cmml">⁢</mo><mrow id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.2.cmml"><mo id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.2" stretchy="false" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.2.cmml">(</mo><msub id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.cmml"><mi id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.2" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.3" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.3" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.2.cmml">,</mo><mi id="S2.SS2.SSS0.Px4.p1.2.m2.1.1" xref="S2.SS2.SSS0.Px4.p1.2.m2.1.1.cmml">t</mi><mo id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.4" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.2.cmml">,</mo><mi id="S2.SS2.SSS0.Px4.p1.2.m2.2.2" xref="S2.SS2.SSS0.Px4.p1.2.m2.2.2.cmml">c</mi><mo id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.5" stretchy="false" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px4.p1.2.m2.3b"><apply id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3"><times id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.2.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.2"></times><apply id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.1.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3">subscript</csymbol><ci id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.2.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.2">bold-italic-ϵ</ci><ci id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.3.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.3.3">𝜃</ci></apply><vector id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.2.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1"><apply id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.2.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.2">𝐱</ci><ci id="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.3.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.3.3.1.1.1.3">𝑡</ci></apply><ci id="S2.SS2.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.1.1">𝑡</ci><ci id="S2.SS2.SSS0.Px4.p1.2.m2.2.2.cmml" xref="S2.SS2.SSS0.Px4.p1.2.m2.2.2">𝑐</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px4.p1.2.m2.3c">\boldsymbol{\epsilon}_{\theta}(\mathbf{x}_{t},t,c)</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px4.p1.2.m2.3d">bold_italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t , italic_c )</annotation></semantics></math> predicts the noise accumulated at timestep <math alttext="t" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px4.p1.3.m3.1"><semantics id="S2.SS2.SSS0.Px4.p1.3.m3.1a"><mi id="S2.SS2.SSS0.Px4.p1.3.m3.1.1" xref="S2.SS2.SSS0.Px4.p1.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px4.p1.3.m3.1b"><ci id="S2.SS2.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.3.m3.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px4.p1.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px4.p1.3.m3.1d">italic_t</annotation></semantics></math>.
The predicted noise is then scaled according to the noise schedule, and the proportional amount of predicted noise is removed from <math alttext="\mathbf{x}_{t}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px4.p1.4.m4.1"><semantics id="S2.SS2.SSS0.Px4.p1.4.m4.1a"><msub id="S2.SS2.SSS0.Px4.p1.4.m4.1.1" xref="S2.SS2.SSS0.Px4.p1.4.m4.1.1.cmml"><mi id="S2.SS2.SSS0.Px4.p1.4.m4.1.1.2" xref="S2.SS2.SSS0.Px4.p1.4.m4.1.1.2.cmml">𝐱</mi><mi id="S2.SS2.SSS0.Px4.p1.4.m4.1.1.3" xref="S2.SS2.SSS0.Px4.p1.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px4.p1.4.m4.1b"><apply id="S2.SS2.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px4.p1.4.m4.1.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px4.p1.4.m4.1.1.2.cmml" xref="S2.SS2.SSS0.Px4.p1.4.m4.1.1.2">𝐱</ci><ci id="S2.SS2.SSS0.Px4.p1.4.m4.1.1.3.cmml" xref="S2.SS2.SSS0.Px4.p1.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px4.p1.4.m4.1c">\mathbf{x}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px4.p1.4.m4.1d">bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> to produce <math alttext="\mathbf{x}_{t-1}" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px4.p1.5.m5.1"><semantics id="S2.SS2.SSS0.Px4.p1.5.m5.1a"><msub id="S2.SS2.SSS0.Px4.p1.5.m5.1.1" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.cmml"><mi id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.2" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.2.cmml">𝐱</mi><mrow id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.cmml"><mi id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.2" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.2.cmml">t</mi><mo id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.1" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.1.cmml">−</mo><mn id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.3" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px4.p1.5.m5.1b"><apply id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.2.cmml" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.2">𝐱</ci><apply id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.cmml" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3"><minus id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.1.cmml" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.1"></minus><ci id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.2.cmml" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.2">𝑡</ci><cn id="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.3.cmml" type="integer" xref="S2.SS2.SSS0.Px4.p1.5.m5.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px4.p1.5.m5.1c">\mathbf{x}_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px4.p1.5.m5.1d">bold_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math>.
In practice, inference is done over fewer timesteps than training.
Classifier-free guidance (CFG) <cite class="ltx_cite ltx_citemacro_citep">(Ho and Salimans, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib21" title="">2022</a>)</cite> is often used to improve generation by contrasting the prediction of the model conditioned on the context <math alttext="c" class="ltx_Math" display="inline" id="S2.SS2.SSS0.Px4.p1.6.m6.1"><semantics id="S2.SS2.SSS0.Px4.p1.6.m6.1a"><mi id="S2.SS2.SSS0.Px4.p1.6.m6.1.1" xref="S2.SS2.SSS0.Px4.p1.6.m6.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.SSS0.Px4.p1.6.m6.1b"><ci id="S2.SS2.SSS0.Px4.p1.6.m6.1.1.cmml" xref="S2.SS2.SSS0.Px4.p1.6.m6.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.SSS0.Px4.p1.6.m6.1c">c</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.SSS0.Px4.p1.6.m6.1d">italic_c</annotation></semantics></math> with the unconditioned prediction, at the cost of doubling the computation.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Latent Image Representation</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Early diffusion models worked directly in pixel space <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib22" title="">2020</a>)</cite>, but this proved computationally expensive.
Variational autoencoders (VAEs) <cite class="ltx_cite ltx_citemacro_citep">(Kingma and Welling, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib23" title="">2013</a>)</cite> can save compute by encoding images into a lower-dimensional latent space.
Implemented as deep CNNs, modern VAEs are trained on a combination of reconstruction and regularization losses <cite class="ltx_cite ltx_citemacro_citep">(Esser et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib15" title="">2021</a>)</cite>, allowing downstream models like latent diffusion models (LDMs) <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib37" title="">2022a</a>)</cite> to operate efficiently on compact image patch embeddings; e.g. represent every 8<math alttext="\times" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1"><semantics id="S2.SS3.p1.1.m1.1a"><mo id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><times id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p1.1.m1.1d">×</annotation></semantics></math>8 pixel patch as an 8-dimensional vector.
For autoregressive language modeling approaches <cite class="ltx_cite ltx_citemacro_citep">(Ramesh et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib35" title="">2021</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib50" title="">2022</a>)</cite>, images must be discretized.
Discrete autoencoders, such as vector-quantized VAEs (VQ-VAE) <cite class="ltx_cite ltx_citemacro_citep">(Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib48" title="">2017</a>)</cite>, achieve this by introducing a quantization layer (and related regularization losses) that maps continuous latent embeddings to discrete tokens.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Transfusion</h2>
<figure class="ltx_figure" id="S3.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S3.F4.1" style="width:203.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="905" id="S3.F4.1.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.1.1.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S3.F4.1.2.2" style="font-size:90%;">We convert images to and from latent representations using a pretrained VAE, and then into patch representations with either a simple linear layer or U-Net down blocks.</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S3.F4.2" style="width:203.8pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="786" id="S3.F4.2.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.2.1.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S3.F4.2.2.2" style="font-size:90%;">Expanding on the causal mask, Transfusion allows patches of the same image to condition on each other.</span></figcaption>
</figure>
</div>
</div>
</figure>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Transfusion is a method for training a single unified model to understand and generate both discrete and continuous modalities.
Our main innovation is demonstrating that we can use separate losses for different modalities – language modeling for text, diffusion for images – over shared data and parameters.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates Transfusion.</p>
</div>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Data Representation</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">We experiment with data spanning two modalities: discrete text and continuous images.
Each text string is tokenized into a sequence of discrete tokens from a fixed vocabulary, where each token is represented as an integer.
Each image is encoded as latent patches using a VAE (see §<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S2.SS3" title="2.3 Latent Image Representation ‣ 2 Background ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">2.3</span></a>), where each patch is represented as a continuous vector; the patches are sequenced left-to-right top-to-bottom to create a sequence of patch vectors from each image.<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>While our canonical setting uses a VAE following latent diffusion models, we were also able to demonstrate Transfusion using raw pixel representations in preliminary experiments.</span></span></span>
For mixed-modal examples, we surround each image sequence with special <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.1">beginning of image</span> (BOI) and <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px1.p1.1.2">end of image</span> (EOI) tokens before inserting it to the text sequence;
thus, we arrive at a single sequence potentially containing both discrete elements (integers representing text tokens) and continuous elements (vectors representing image patches).</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Model Architecture</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.2">The vast majority of the model’s parameters belong to a single transformer, which processes every sequence, regardless of modality.<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>We follow Llama’s <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib46" title="">2023a</a>)</cite> flavor of the transformer block, which includes the SwiGLU activation function <cite class="ltx_cite ltx_citemacro_citep">(Shazeer, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib42" title="">2020</a>)</cite> and RoPE <cite class="ltx_cite ltx_citemacro_citep">(Su et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib45" title="">2024</a>)</cite>.</span></span></span><span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>While we use the transformer architecture in this work, Transfusion could potentially work with other architectures too, despite its name.</span></span></span>
The transformer takes a sequence of high-dimensional vectors in <math alttext="\mathbb{R}^{d}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px2.p1.1.m1.1a"><msup id="S3.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml">ℝ</mi><mi id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml">d</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.2">ℝ</ci><ci id="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p1.1.m1.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.1.m1.1c">\mathbb{R}^{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.1.m1.1d">blackboard_R start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT</annotation></semantics></math> as input, and produces similar vectors as output.
To convert our data into this space, we use lightweight modality-specific components with unshared parameters.
For text, these are the embedding matrices, converting each input integer to vector space and each output vector into a discrete distribution over the vocabulary.
For images, we experiment with two alternatives for compressing local windows of <math alttext="k\times k" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px2.p1.2.m2.1"><semantics id="S3.SS0.SSS0.Px2.p1.2.m2.1a"><mrow id="S3.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml"><mi id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.2" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml">k</mi><mo id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml">×</mo><mi id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.3" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px2.p1.2.m2.1b"><apply id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1"><times id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.1"></times><ci id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.2">𝑘</ci><ci id="S3.SS0.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S3.SS0.SSS0.Px2.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px2.p1.2.m2.1c">k\times k</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px2.p1.2.m2.1d">italic_k × italic_k</annotation></semantics></math> patch vectors into a single transformer vector (and vice versa): (1) a simple linear layer,<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>We add an embedding of the timestep <math alttext="t" class="ltx_Math" display="inline" id="footnote4.m1.1"><semantics id="footnote4.m1.1b"><mi id="footnote4.m1.1.1" xref="footnote4.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="footnote4.m1.1c"><ci id="footnote4.m1.1.1.cmml" xref="footnote4.m1.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote4.m1.1d">t</annotation><annotation encoding="application/x-llamapun" id="footnote4.m1.1e">italic_t</annotation></semantics></math> to every patch vector before the linear layer.</span></span></span> and (2) up and down blocks of a U-Net <cite class="ltx_cite ltx_citemacro_citep">(Nichol and Dhariwal, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib30" title="">2021</a>; Saharia et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib39" title="">2022</a>)</cite>.<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>We replace the U-Net’s AdaLayerNorm with regular layer norm in our implementation.</span></span></span>
Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3.F4" title="Figure 4 ‣ 3 Transfusion ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4</span></a> illustrates the overall architecture.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Transfusion Attention</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px3.p1.1">Language models typically use causal masking to efficiently compute the loss and gradients over an entire sequence in a single forward-backward pass without leaking information from future tokens.
While text is naturally sequential, images are not, and are usually modeled with unrestricted (bidirectional) attention.
Transfusion combines both attention patterns by applying causal attention to every element in the sequence, and bidirectional attention within the elements of each individual image.
This allows every image patch to attend to every other patch within the same image, but only attend to text or patches of other images that appeared previously in the sequence.
We find that enabling intra-image attention significantly boosts model performance (see §<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3" title="4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.3</span></a>).
Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3.F4" title="Figure 4 ‣ 3 Transfusion ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4</span></a> shows an example Transfusion attention mask.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Training Objective</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p1.6">To train our model, we apply the language modeling objective <math alttext="\mathcal{L}_{\text{LM}}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px4.p1.1.m1.1a"><msub id="S3.SS0.SSS0.Px4.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.cmml">ℒ</mi><mtext id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3a.cmml">LM</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.2">ℒ</ci><ci id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3a.cmml" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3"><mtext id="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS0.Px4.p1.1.m1.1.1.3">LM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.1.m1.1c">\mathcal{L}_{\text{LM}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p1.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT</annotation></semantics></math> to predictions of text tokens and the diffusion objective <math alttext="\mathcal{L}_{\text{DDPM}}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p1.2.m2.1"><semantics id="S3.SS0.SSS0.Px4.p1.2.m2.1a"><msub id="S3.SS0.SSS0.Px4.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2.cmml">ℒ</mi><mtext id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3a.cmml">DDPM</mtext></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.2.m2.1b"><apply id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.2">ℒ</ci><ci id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3a.cmml" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3"><mtext id="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="S3.SS0.SSS0.Px4.p1.2.m2.1.1.3">DDPM</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.2.m2.1c">\mathcal{L}_{\text{DDPM}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p1.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT DDPM end_POSTSUBSCRIPT</annotation></semantics></math> to predictions of image patches.
LM loss is computed per token,<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>When the input is a BOI token, we do not compute any loss.</span></span></span> while diffusion loss is computed per image, which may span multiple elements (image patches) in the sequence.
Specifically, we add noise <math alttext="\boldsymbol{\epsilon}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p1.3.m3.1"><semantics id="S3.SS0.SSS0.Px4.p1.3.m3.1a"><mi class="ltx_mathvariant_bold-italic" id="S3.SS0.SSS0.Px4.p1.3.m3.1.1" mathvariant="bold-italic" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.3.m3.1b"><ci id="S3.SS0.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.3.m3.1.1">bold-italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.3.m3.1c">\boldsymbol{\epsilon}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p1.3.m3.1d">bold_italic_ϵ</annotation></semantics></math> to each input latent image <math alttext="\mathbf{x}_{0}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p1.4.m4.1"><semantics id="S3.SS0.SSS0.Px4.p1.4.m4.1a"><msub id="S3.SS0.SSS0.Px4.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px4.p1.4.m4.1.1.cmml"><mi id="S3.SS0.SSS0.Px4.p1.4.m4.1.1.2" xref="S3.SS0.SSS0.Px4.p1.4.m4.1.1.2.cmml">𝐱</mi><mn id="S3.SS0.SSS0.Px4.p1.4.m4.1.1.3" xref="S3.SS0.SSS0.Px4.p1.4.m4.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.4.m4.1b"><apply id="S3.SS0.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.4.m4.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px4.p1.4.m4.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.4.m4.1.1.2">𝐱</ci><cn id="S3.SS0.SSS0.Px4.p1.4.m4.1.1.3.cmml" type="integer" xref="S3.SS0.SSS0.Px4.p1.4.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.4.m4.1c">\mathbf{x}_{0}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p1.4.m4.1d">bold_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT</annotation></semantics></math> according to the diffusion process to produce <math alttext="\mathbf{x}_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p1.5.m5.1"><semantics id="S3.SS0.SSS0.Px4.p1.5.m5.1a"><msub id="S3.SS0.SSS0.Px4.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px4.p1.5.m5.1.1.cmml"><mi id="S3.SS0.SSS0.Px4.p1.5.m5.1.1.2" xref="S3.SS0.SSS0.Px4.p1.5.m5.1.1.2.cmml">𝐱</mi><mi id="S3.SS0.SSS0.Px4.p1.5.m5.1.1.3" xref="S3.SS0.SSS0.Px4.p1.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.5.m5.1b"><apply id="S3.SS0.SSS0.Px4.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px4.p1.5.m5.1.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px4.p1.5.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px4.p1.5.m5.1.1.2">𝐱</ci><ci id="S3.SS0.SSS0.Px4.p1.5.m5.1.1.3.cmml" xref="S3.SS0.SSS0.Px4.p1.5.m5.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.5.m5.1c">\mathbf{x}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p1.5.m5.1d">bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> before patchification, and then compute the image-level diffusion loss.<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>Ergo, downstream tokens condition on noisy images during training. See §<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3.SSS4" title="4.3.4 Image Noising ‣ 4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.3.4</span></a> for further discussion.</span></span></span>
We combine the two losses by simply adding the losses computed over each modality with a balancing coefficient <math alttext="\lambda" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px4.p1.6.m6.1"><semantics id="S3.SS0.SSS0.Px4.p1.6.m6.1a"><mi id="S3.SS0.SSS0.Px4.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px4.p1.6.m6.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px4.p1.6.m6.1b"><ci id="S3.SS0.SSS0.Px4.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px4.p1.6.m6.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px4.p1.6.m6.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px4.p1.6.m6.1d">italic_λ</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{Transfusion}}=\mathcal{L}_{\text{LM}}+\lambda\cdot\mathcal{%
L}_{\text{DDPM}}" class="ltx_Math" display="block" id="S3.E4.m1.1"><semantics id="S3.E4.m1.1a"><mrow id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml"><msub id="S3.E4.m1.1.1.2" xref="S3.E4.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.2.2" xref="S3.E4.m1.1.1.2.2.cmml">ℒ</mi><mtext id="S3.E4.m1.1.1.2.3" xref="S3.E4.m1.1.1.2.3a.cmml">Transfusion</mtext></msub><mo id="S3.E4.m1.1.1.1" xref="S3.E4.m1.1.1.1.cmml">=</mo><mrow id="S3.E4.m1.1.1.3" xref="S3.E4.m1.1.1.3.cmml"><msub id="S3.E4.m1.1.1.3.2" xref="S3.E4.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.3.2.2" xref="S3.E4.m1.1.1.3.2.2.cmml">ℒ</mi><mtext id="S3.E4.m1.1.1.3.2.3" xref="S3.E4.m1.1.1.3.2.3a.cmml">LM</mtext></msub><mo id="S3.E4.m1.1.1.3.1" xref="S3.E4.m1.1.1.3.1.cmml">+</mo><mrow id="S3.E4.m1.1.1.3.3" xref="S3.E4.m1.1.1.3.3.cmml"><mi id="S3.E4.m1.1.1.3.3.2" xref="S3.E4.m1.1.1.3.3.2.cmml">λ</mi><mo id="S3.E4.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E4.m1.1.1.3.3.1.cmml">⋅</mo><msub id="S3.E4.m1.1.1.3.3.3" xref="S3.E4.m1.1.1.3.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.3.3.3.2" xref="S3.E4.m1.1.1.3.3.3.2.cmml">ℒ</mi><mtext id="S3.E4.m1.1.1.3.3.3.3" xref="S3.E4.m1.1.1.3.3.3.3a.cmml">DDPM</mtext></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.1b"><apply id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1"><eq id="S3.E4.m1.1.1.1.cmml" xref="S3.E4.m1.1.1.1"></eq><apply id="S3.E4.m1.1.1.2.cmml" xref="S3.E4.m1.1.1.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.2.1.cmml" xref="S3.E4.m1.1.1.2">subscript</csymbol><ci id="S3.E4.m1.1.1.2.2.cmml" xref="S3.E4.m1.1.1.2.2">ℒ</ci><ci id="S3.E4.m1.1.1.2.3a.cmml" xref="S3.E4.m1.1.1.2.3"><mtext id="S3.E4.m1.1.1.2.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.2.3">Transfusion</mtext></ci></apply><apply id="S3.E4.m1.1.1.3.cmml" xref="S3.E4.m1.1.1.3"><plus id="S3.E4.m1.1.1.3.1.cmml" xref="S3.E4.m1.1.1.3.1"></plus><apply id="S3.E4.m1.1.1.3.2.cmml" xref="S3.E4.m1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.2.1.cmml" xref="S3.E4.m1.1.1.3.2">subscript</csymbol><ci id="S3.E4.m1.1.1.3.2.2.cmml" xref="S3.E4.m1.1.1.3.2.2">ℒ</ci><ci id="S3.E4.m1.1.1.3.2.3a.cmml" xref="S3.E4.m1.1.1.3.2.3"><mtext id="S3.E4.m1.1.1.3.2.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.3.2.3">LM</mtext></ci></apply><apply id="S3.E4.m1.1.1.3.3.cmml" xref="S3.E4.m1.1.1.3.3"><ci id="S3.E4.m1.1.1.3.3.1.cmml" xref="S3.E4.m1.1.1.3.3.1">⋅</ci><ci id="S3.E4.m1.1.1.3.3.2.cmml" xref="S3.E4.m1.1.1.3.3.2">𝜆</ci><apply id="S3.E4.m1.1.1.3.3.3.cmml" xref="S3.E4.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="S3.E4.m1.1.1.3.3.3.1.cmml" xref="S3.E4.m1.1.1.3.3.3">subscript</csymbol><ci id="S3.E4.m1.1.1.3.3.3.2.cmml" xref="S3.E4.m1.1.1.3.3.3.2">ℒ</ci><ci id="S3.E4.m1.1.1.3.3.3.3a.cmml" xref="S3.E4.m1.1.1.3.3.3.3"><mtext id="S3.E4.m1.1.1.3.3.3.3.cmml" mathsize="70%" xref="S3.E4.m1.1.1.3.3.3.3">DDPM</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.1c">\mathcal{L}_{\text{Transfusion}}=\mathcal{L}_{\text{LM}}+\lambda\cdot\mathcal{%
L}_{\text{DDPM}}</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.1d">caligraphic_L start_POSTSUBSCRIPT Transfusion end_POSTSUBSCRIPT = caligraphic_L start_POSTSUBSCRIPT LM end_POSTSUBSCRIPT + italic_λ ⋅ caligraphic_L start_POSTSUBSCRIPT DDPM end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px4.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px4.p2.1">This formulation is a specific instantiation of a broader idea: combining a discrete distribution loss with a continuous distribution loss to optimize the same model.
We leave further exploration of this space, such as replacing diffusion with flow matching <cite class="ltx_cite ltx_citemacro_citep">(Lipman et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib27" title="">2022</a>)</cite>), to future work.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">Inference</h5>
<div class="ltx_para" id="S3.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px5.p1.6">Reflecting the training objective, our decoding algorithm also switches between two modes: LM and diffusion.
In <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.6.1">LM mode</span>, we follow the standard practice of sampling token by token from the predicted distribution.
When we sample a BOI token, the decoding algorithm switches to <span class="ltx_text ltx_font_italic" id="S3.SS0.SSS0.Px5.p1.6.2">diffusion mode</span>, where we follow the standard procedure of decoding from diffusion models.
Specifically, we append a pure noise <math alttext="\mathbf{x}_{T}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px5.p1.1.m1.1a"><msub id="S3.SS0.SSS0.Px5.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.2.cmml">𝐱</mi><mi id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.2">𝐱</ci><ci id="S3.SS0.SSS0.Px5.p1.1.m1.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.1.m1.1c">\mathbf{x}_{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px5.p1.1.m1.1d">bold_x start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT</annotation></semantics></math> in the form of <math alttext="n" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.2.m2.1"><semantics id="S3.SS0.SSS0.Px5.p1.2.m2.1a"><mi id="S3.SS0.SSS0.Px5.p1.2.m2.1.1" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.2.m2.1b"><ci id="S3.SS0.SSS0.Px5.p1.2.m2.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.2.m2.1c">n</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px5.p1.2.m2.1d">italic_n</annotation></semantics></math> image patches to the input sequence (depending on the desired image size), and denoise over <math alttext="T" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.3.m3.1"><semantics id="S3.SS0.SSS0.Px5.p1.3.m3.1a"><mi id="S3.SS0.SSS0.Px5.p1.3.m3.1.1" xref="S3.SS0.SSS0.Px5.p1.3.m3.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.3.m3.1b"><ci id="S3.SS0.SSS0.Px5.p1.3.m3.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.3.m3.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.3.m3.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px5.p1.3.m3.1d">italic_T</annotation></semantics></math> steps.
At each step <math alttext="t" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.4.m4.1"><semantics id="S3.SS0.SSS0.Px5.p1.4.m4.1a"><mi id="S3.SS0.SSS0.Px5.p1.4.m4.1.1" xref="S3.SS0.SSS0.Px5.p1.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.4.m4.1b"><ci id="S3.SS0.SSS0.Px5.p1.4.m4.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px5.p1.4.m4.1d">italic_t</annotation></semantics></math>, we take the noise prediction and use it to produce <math alttext="\mathbf{x}_{t-1}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.5.m5.1"><semantics id="S3.SS0.SSS0.Px5.p1.5.m5.1a"><msub id="S3.SS0.SSS0.Px5.p1.5.m5.1.1" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.cmml"><mi id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.2" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.2.cmml">𝐱</mi><mrow id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.cmml"><mi id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.2" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.2.cmml">t</mi><mo id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.1" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.1.cmml">−</mo><mn id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.3" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.5.m5.1b"><apply id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.2">𝐱</ci><apply id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3"><minus id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.1.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.1"></minus><ci id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.2.cmml" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.2">𝑡</ci><cn id="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.3.cmml" type="integer" xref="S3.SS0.SSS0.Px5.p1.5.m5.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.5.m5.1c">\mathbf{x}_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px5.p1.5.m5.1d">bold_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math>, which then overwrites <math alttext="\mathbf{x}_{t}" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px5.p1.6.m6.1"><semantics id="S3.SS0.SSS0.Px5.p1.6.m6.1a"><msub id="S3.SS0.SSS0.Px5.p1.6.m6.1.1" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.cmml"><mi id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.2" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.2.cmml">𝐱</mi><mi id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.3" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px5.p1.6.m6.1b"><apply id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.1.cmml" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.2.cmml" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.2">𝐱</ci><ci id="S3.SS0.SSS0.Px5.p1.6.m6.1.1.3.cmml" xref="S3.SS0.SSS0.Px5.p1.6.m6.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px5.p1.6.m6.1c">\mathbf{x}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px5.p1.6.m6.1d">bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> in the sequence; i.e. the model always conditions on the last timestep of the noised image and cannot attend to previous timesteps.
Once the diffusion process has ended, we append an EOI token to the predicted image, and switch back to LM mode.
This algorithm enables the generation of any mixture of text and image modalities.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">We demonstrate in a series of controlled experiments that Transfusion is a viable, scalable method for training a unified multi-modal model.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Setup</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Evaluation</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">We evaluate model performance on a collection of standard uni-modal and cross-modal benchmarks (Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.T2" title="Table 2 ‣ Evaluation ‣ 4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">2</span></a>).
For text-to-text, we measure perplexity on 20M held-out tokens from Wikipedia and the C4 corpus <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib34" title="">2019</a>)</cite>, as well as accuracy on the pretraining evaluation suite of Llama 2 <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib47" title="">2023b</a>)</cite>.<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>The Llama 2 evaluation suite includes HellaSwag <cite class="ltx_cite ltx_citemacro_citep">(Zellers et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib52" title="">2019</a>)</cite>, PIQA <cite class="ltx_cite ltx_citemacro_citep">(Bisk et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib5" title="">2020</a>)</cite>, SIQA <cite class="ltx_cite ltx_citemacro_citep">(Sap et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib41" title="">2019</a>)</cite>, WinoGrande <cite class="ltx_cite ltx_citemacro_citep">(Sakaguchi et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib40" title="">2021</a>)</cite>, ARC-e and -c <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib10" title="">2018</a>)</cite>, and BoolQ <cite class="ltx_cite ltx_citemacro_citep">(Clark et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib9" title="">2019</a>)</cite>. We report the average 0-shot task accuracy on these benchmarks.</span></span></span>
For text-to-image, we use the MS-COCO benchmark <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib26" title="">2014</a>)</cite>, where we generate images on randomly selected 30k prompts from validation set and measure their photo-realism using zero-shot Frechet Inception Distance (FID) <cite class="ltx_cite ltx_citemacro_citep">(Heusel et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib20" title="">2017</a>)</cite> as well as their alignment with the prompts using CLIP score <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib33" title="">2021</a>)</cite>.<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>We follow common practice for ablations and use only 5k examples to compute FID and CLIP in §<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3" title="4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</span></span></span>
We also evaluate the model’s ability to generate image captions; we report CIDEr <cite class="ltx_cite ltx_citemacro_citep">(Vedantam et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib49" title="">2015</a>)</cite> scores on the Karpathy test split of MS-COCO <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib26" title="">2014</a>)</cite>.
These evaluations provide signal for investigation scaling laws (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS2" title="4.2 Controlled Comparison with Chameleon ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.2</span></a>) and ablations (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3" title="4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.3</span></a>).
To compare with recent literature in diffusion models, we evaluate our largest scale model (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS4" title="4.4 Comparison with Image Generation Literature ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.4</span></a>) also on GenEval <cite class="ltx_cite ltx_citemacro_citep">(Ghosh et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib19" title="">2023</a>)</cite>, a benchmark that examines a model’s ability to generate an accurate depiction of the prompt.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.T2.7" style="width:242.8pt;">
<table class="ltx_tabular ltx_align_middle" id="S4.T2.7.7">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.7.7.8.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.7.7.8.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.1.1" style="font-size:90%;">Input</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.7.7.8.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.2.1" style="font-size:90%;">Output</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T2.7.7.8.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.3.1" style="font-size:90%;">Benchmark</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt" id="S4.T2.7.7.8.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.7.7.8.1.4.1" style="font-size:90%;">Metric</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.1.2" rowspan="3"><span class="ltx_text" id="S4.T2.1.1.1.2.1" style="font-size:90%;">Text</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.1.3" rowspan="3"><span class="ltx_text" id="S4.T2.1.1.1.3.1" style="font-size:90%;">Text</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.1.1.1.4"><span class="ltx_text" id="S4.T2.1.1.1.4.1" style="font-size:90%;">Wikipedia</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T2.1.1.1.1">
<span class="ltx_text" id="S4.T2.1.1.1.1.1" style="font-size:90%;">Perplexity (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.1.1.1.1.m1.1"><semantics id="S4.T2.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T2.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.1.1.1.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T2.1.1.1.1.2" style="font-size:90%;">)</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.2.2.2">
<td class="ltx_td ltx_align_left" id="S4.T2.2.2.2.2"><span class="ltx_text" id="S4.T2.2.2.2.2.1" style="font-size:90%;">C4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.2.2.2.1">
<span class="ltx_text" id="S4.T2.2.2.2.1.1" style="font-size:90%;">Perplexity (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.2.2.2.1.m1.1"><semantics id="S4.T2.2.2.2.1.m1.1a"><mo id="S4.T2.2.2.2.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T2.2.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.1.m1.1b"><ci id="S4.T2.2.2.2.1.m1.1.1.cmml" xref="S4.T2.2.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.2.2.2.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T2.2.2.2.1.2" style="font-size:90%;">)</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.3.3.3">
<td class="ltx_td ltx_align_left" id="S4.T2.3.3.3.2"><span class="ltx_text" id="S4.T2.3.3.3.2.1" style="font-size:90%;">Llama 2 Eval Suite</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T2.3.3.3.1">
<span class="ltx_text" id="S4.T2.3.3.3.1.1" style="font-size:90%;">Accuracy (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.3.3.3.1.m1.1"><semantics id="S4.T2.3.3.3.1.m1.1a"><mo id="S4.T2.3.3.3.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T2.3.3.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.1.m1.1b"><ci id="S4.T2.3.3.3.1.m1.1.1.cmml" xref="S4.T2.3.3.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.3.3.3.1.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T2.3.3.3.1.2" style="font-size:90%;">)</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.4.4.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.4.4.4.2"><span class="ltx_text" id="S4.T2.4.4.4.2.1" style="font-size:90%;">Image</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.4.4.4.3"><span class="ltx_text" id="S4.T2.4.4.4.3.1" style="font-size:90%;">Text</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.4.4.4.4"><span class="ltx_text" id="S4.T2.4.4.4.4.1" style="font-size:90%;">MS-COCO 5k</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T2.4.4.4.1">
<span class="ltx_text" id="S4.T2.4.4.4.1.1" style="font-size:90%;">CIDEr (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.4.4.4.1.m1.1"><semantics id="S4.T2.4.4.4.1.m1.1a"><mo id="S4.T2.4.4.4.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T2.4.4.4.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.4.1.m1.1b"><ci id="S4.T2.4.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.4.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.4.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.4.4.4.1.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T2.4.4.4.1.2" style="font-size:90%;">)</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6.6">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.6.6.6.3" rowspan="2"><span class="ltx_text" id="S4.T2.6.6.6.3.1" style="font-size:90%;">Text</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.6.6.6.4" rowspan="2"><span class="ltx_text" id="S4.T2.6.6.6.4.1" style="font-size:90%;">Image</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.6.6.6.5"><span class="ltx_text" id="S4.T2.6.6.6.5.1" style="font-size:90%;">MS-COCO 30k</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t" id="S4.T2.6.6.6.2">
<span class="ltx_text" id="S4.T2.6.6.6.2.1" style="font-size:90%;">FID (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T2.5.5.5.1.m1.1"><semantics id="S4.T2.5.5.5.1.m1.1a"><mo id="S4.T2.5.5.5.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T2.5.5.5.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.5.1.m1.1b"><ci id="S4.T2.5.5.5.1.m1.1.1.cmml" xref="S4.T2.5.5.5.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.5.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.5.5.5.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T2.6.6.6.2.2" style="font-size:90%;">), CLIP (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.6.6.6.2.m2.1"><semantics id="S4.T2.6.6.6.2.m2.1a"><mo id="S4.T2.6.6.6.2.m2.1.1" mathsize="90%" stretchy="false" xref="S4.T2.6.6.6.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.6.2.m2.1b"><ci id="S4.T2.6.6.6.2.m2.1.1.cmml" xref="S4.T2.6.6.6.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.6.2.m2.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.6.6.6.2.m2.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T2.6.6.6.2.3" style="font-size:90%;">)</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T2.7.7.7">
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.7.7.7.2"><span class="ltx_text" id="S4.T2.7.7.7.2.1" style="font-size:90%;">GenEval</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb" id="S4.T2.7.7.7.1">
<span class="ltx_text" id="S4.T2.7.7.7.1.1" style="font-size:90%;">GenEval score (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T2.7.7.7.1.m1.1"><semantics id="S4.T2.7.7.7.1.m1.1a"><mo id="S4.T2.7.7.7.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T2.7.7.7.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.7.1.m1.1b"><ci id="S4.T2.7.7.7.1.m1.1.1.cmml" xref="S4.T2.7.7.7.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.7.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T2.7.7.7.1.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T2.7.7.7.1.2" style="font-size:90%;">)</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Table 1: </span>An overview of the evaluation suite used in this work.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="S4.T2.fig1" style="width:177.8pt;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.fig1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.fig1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T2.fig1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="S4.T2.fig1.1.1.1.1.1" style="font-size:90%;">Size</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.fig1.1.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T2.fig1.1.1.1.2.1" style="font-size:90%;">Layers</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.fig1.1.1.1.3"><span class="ltx_text ltx_font_bold" id="S4.T2.fig1.1.1.1.3.1" style="font-size:90%;">Emb Dim</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.fig1.1.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T2.fig1.1.1.1.4.1" style="font-size:90%;">Att Heads</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.fig1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T2.fig1.1.2.1.1"><span class="ltx_text" id="S4.T2.fig1.1.2.1.1.1" style="font-size:90%;">0.16B</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.fig1.1.2.1.2"><span class="ltx_text" id="S4.T2.fig1.1.2.1.2.1" style="font-size:90%;">16</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.fig1.1.2.1.3"><span class="ltx_text" id="S4.T2.fig1.1.2.1.3.1" style="font-size:90%;">768</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T2.fig1.1.2.1.4"><span class="ltx_text" id="S4.T2.fig1.1.2.1.4.1" style="font-size:90%;">12</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.fig1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.fig1.1.3.2.1"><span class="ltx_text" id="S4.T2.fig1.1.3.2.1.1" style="font-size:90%;">0.37B</span></th>
<td class="ltx_td ltx_align_right" id="S4.T2.fig1.1.3.2.2"><span class="ltx_text" id="S4.T2.fig1.1.3.2.2.1" style="font-size:90%;">24</span></td>
<td class="ltx_td ltx_align_right" id="S4.T2.fig1.1.3.2.3"><span class="ltx_text" id="S4.T2.fig1.1.3.2.3.1" style="font-size:90%;">1024</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T2.fig1.1.3.2.4"><span class="ltx_text" id="S4.T2.fig1.1.3.2.4.1" style="font-size:90%;">16</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.fig1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.fig1.1.4.3.1"><span class="ltx_text" id="S4.T2.fig1.1.4.3.1.1" style="font-size:90%;">0.76B</span></th>
<td class="ltx_td ltx_align_right" id="S4.T2.fig1.1.4.3.2"><span class="ltx_text" id="S4.T2.fig1.1.4.3.2.1" style="font-size:90%;">24</span></td>
<td class="ltx_td ltx_align_right" id="S4.T2.fig1.1.4.3.3"><span class="ltx_text" id="S4.T2.fig1.1.4.3.3.1" style="font-size:90%;">1536</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T2.fig1.1.4.3.4"><span class="ltx_text" id="S4.T2.fig1.1.4.3.4.1" style="font-size:90%;">24</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.fig1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T2.fig1.1.5.4.1"><span class="ltx_text" id="S4.T2.fig1.1.5.4.1.1" style="font-size:90%;">1.4B</span></th>
<td class="ltx_td ltx_align_right" id="S4.T2.fig1.1.5.4.2"><span class="ltx_text" id="S4.T2.fig1.1.5.4.2.1" style="font-size:90%;">24</span></td>
<td class="ltx_td ltx_align_right" id="S4.T2.fig1.1.5.4.3"><span class="ltx_text" id="S4.T2.fig1.1.5.4.3.1" style="font-size:90%;">2048</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T2.fig1.1.5.4.4"><span class="ltx_text" id="S4.T2.fig1.1.5.4.4.1" style="font-size:90%;">16</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.fig1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T2.fig1.1.6.5.1"><span class="ltx_text" id="S4.T2.fig1.1.6.5.1.1" style="font-size:90%;">7B</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.fig1.1.6.5.2"><span class="ltx_text" id="S4.T2.fig1.1.6.5.2.1" style="font-size:90%;">32</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.fig1.1.6.5.3"><span class="ltx_text" id="S4.T2.fig1.1.6.5.3.1" style="font-size:90%;">4096</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S4.T2.fig1.1.6.5.4"><span class="ltx_text" id="S4.T2.fig1.1.6.5.4.1" style="font-size:90%;">32</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_figure">Table 2: </span>Model sizes and configurations for both Transfusion and baselines.</figcaption>
</figure>
</div>
</div>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Baseline</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">At the time of writing, the prominent open-science method for training a single mixed-modal model that can generate both text and images is to quantize images into discrete tokens, and then model the entire token sequence with a standard language model <cite class="ltx_cite ltx_citemacro_citep">(Ramesh et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib35" title="">2021</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib50" title="">2022</a>, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib51" title="">2023</a>)</cite>.
We follow the recipe of Chameleon <cite class="ltx_cite ltx_citemacro_citep">(Chameleon Team, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib6" title="">2024</a>)</cite> to train a family of data- and compute-controlled baseline models, which we can directly compare to our Transfusion models.
The key difference between Chameleon and Transfusion is that while Chameleon discretizes images and processes them as tokens, Transfusion keeps images in continuous space, removing the quantization information bottleneck.
To further minimize any confounding variables, we train the VAEs for Chameleon and Transfusion using exactly the same data, compute, and architecture, with the only differentiator being the quantization layer and codebook loss of Chameleon’s VQ-VAE (see details below).
Chameleon also deviates from the Llama transformer architecture, adding query-key normalization, post-normalization, denominator loss, and a lower learning rate of 1e-4 to manage training instability, which incur an efficiency cost (see §<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS2" title="4.2 Controlled Comparison with Chameleon ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.2</span></a>).<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>Removing these deviations in preliminary experiments encountered optimization instabilities in Chameleon.</span></span></span></p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Data</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">For almost all of our experiments, we sample 0.5T tokens (patches) from two datasets at a 1:1 token ratio.
For text, we use the Llama 2 tokenizer and corpus <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib47" title="">2023b</a>)</cite>, containing 2T tokens across a diverse distribution of domains.
For images, we use a collection of 380M licensed Shutterstock images and captions.
Each image is center-cropped and resized to produce a 256<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px3.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px3.p1.1.m1.1a"><mo id="S4.SS1.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px3.p1.1.m1.1b"><times id="S4.SS1.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px3.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px3.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px3.p1.1.m1.1d">×</annotation></semantics></math>256 pixel image.<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>Depending on the compression rate of the patch encoder (see Model Architecture in §<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3" title="3 Transfusion ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">3</span></a>), each image will be represented by either 1024, 256, 64, or 16 elements in the sequence. Since the text/image ratio is constant during training, higher compression rates enable training on more images in total, at the cost of less compute per image.</span></span></span>
We randomly order the image and captions, ordering the caption first 80% of the time.</p>
</div>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p2.1">In one experiment (<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS4" title="4.4 Comparison with Image Generation Literature ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.4</span></a>) we scale up the total training data to 2T tokens (1T text tokens and about 3.5B caption-image pairs at 256 patches per image).
To diversify, we add 220M publicly available images with captions, prefiltered to not contain people.
To rebalance the distribution, we upsample 80M Shutterstock images containing people.
We also add data from Conceptual 12M (CC12M) <cite class="ltx_cite ltx_citemacro_citep">(Changpinyo et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib7" title="">2021</a>)</cite>, reaching a total mixture of 692M image-caption pairs per epoch.
Finally, we upweight the portion of high-aesthetic images in the last 1% of the training schedule.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px4">
<h5 class="ltx_title ltx_title_paragraph">Latent Image Representation</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px4.p1.6">We train a 86M parameter VAE following <cite class="ltx_cite ltx_citemacro_citet">Esser et al. (<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib15" title="">2021</a>)</cite>.
We use a CNN encoder and decoder, and latent dimension 8.
The training objective is combines reconstruction and regularization losses.<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>See Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#A1" title="Appendix A Autoencoder Details ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">A</span></a> for details.</span></span></span>
Our implementation reduces an image of 256<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px4.p1.1.m1.1a"><mo id="S4.SS1.SSS0.Px4.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.1.m1.1b"><times id="S4.SS1.SSS0.Px4.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.1.m1.1d">×</annotation></semantics></math>256 pixels to a 32<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.2.m2.1"><semantics id="S4.SS1.SSS0.Px4.p1.2.m2.1a"><mo id="S4.SS1.SSS0.Px4.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.2.m2.1b"><times id="S4.SS1.SSS0.Px4.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.2.m2.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.2.m2.1d">×</annotation></semantics></math>32<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.3.m3.1"><semantics id="S4.SS1.SSS0.Px4.p1.3.m3.1a"><mo id="S4.SS1.SSS0.Px4.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.3.m3.1b"><times id="S4.SS1.SSS0.Px4.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.3.m3.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.3.m3.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.3.m3.1d">×</annotation></semantics></math>8 tensor, where each latent 8-dimensional latent pixel represents (conceptually) an 8<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.4.m4.1"><semantics id="S4.SS1.SSS0.Px4.p1.4.m4.1a"><mo id="S4.SS1.SSS0.Px4.p1.4.m4.1.1" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.4.m4.1b"><times id="S4.SS1.SSS0.Px4.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.4.m4.1d">×</annotation></semantics></math>8 pixel patch in the original image, and trains for 1M steps.
For VQ-VAE training, we follow the same setup described for VAE training, except we replace <math alttext="\mathcal{L}_{\text{KL}}" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.5.m5.1"><semantics id="S4.SS1.SSS0.Px4.p1.5.m5.1a"><msub id="S4.SS1.SSS0.Px4.p1.5.m5.1.1" xref="S4.SS1.SSS0.Px4.p1.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS1.SSS0.Px4.p1.5.m5.1.1.2" xref="S4.SS1.SSS0.Px4.p1.5.m5.1.1.2.cmml">ℒ</mi><mtext id="S4.SS1.SSS0.Px4.p1.5.m5.1.1.3" xref="S4.SS1.SSS0.Px4.p1.5.m5.1.1.3a.cmml">KL</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.5.m5.1b"><apply id="S4.SS1.SSS0.Px4.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px4.p1.5.m5.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.5.m5.1.1">subscript</csymbol><ci id="S4.SS1.SSS0.Px4.p1.5.m5.1.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.5.m5.1.1.2">ℒ</ci><ci id="S4.SS1.SSS0.Px4.p1.5.m5.1.1.3a.cmml" xref="S4.SS1.SSS0.Px4.p1.5.m5.1.1.3"><mtext id="S4.SS1.SSS0.Px4.p1.5.m5.1.1.3.cmml" mathsize="70%" xref="S4.SS1.SSS0.Px4.p1.5.m5.1.1.3">KL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.5.m5.1c">\mathcal{L}_{\text{KL}}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.5.m5.1d">caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT</annotation></semantics></math> with the standard codebook commitment loss with <math alttext="\beta=0.25" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px4.p1.6.m6.1"><semantics id="S4.SS1.SSS0.Px4.p1.6.m6.1a"><mrow id="S4.SS1.SSS0.Px4.p1.6.m6.1.1" xref="S4.SS1.SSS0.Px4.p1.6.m6.1.1.cmml"><mi id="S4.SS1.SSS0.Px4.p1.6.m6.1.1.2" xref="S4.SS1.SSS0.Px4.p1.6.m6.1.1.2.cmml">β</mi><mo id="S4.SS1.SSS0.Px4.p1.6.m6.1.1.1" xref="S4.SS1.SSS0.Px4.p1.6.m6.1.1.1.cmml">=</mo><mn id="S4.SS1.SSS0.Px4.p1.6.m6.1.1.3" xref="S4.SS1.SSS0.Px4.p1.6.m6.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px4.p1.6.m6.1b"><apply id="S4.SS1.SSS0.Px4.p1.6.m6.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.6.m6.1.1"><eq id="S4.SS1.SSS0.Px4.p1.6.m6.1.1.1.cmml" xref="S4.SS1.SSS0.Px4.p1.6.m6.1.1.1"></eq><ci id="S4.SS1.SSS0.Px4.p1.6.m6.1.1.2.cmml" xref="S4.SS1.SSS0.Px4.p1.6.m6.1.1.2">𝛽</ci><cn id="S4.SS1.SSS0.Px4.p1.6.m6.1.1.3.cmml" type="float" xref="S4.SS1.SSS0.Px4.p1.6.m6.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px4.p1.6.m6.1c">\beta=0.25</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px4.p1.6.m6.1d">italic_β = 0.25</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib48" title="">2017</a>)</cite>. We use a codebook of 16,384 token types.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px5">
<h5 class="ltx_title ltx_title_paragraph">Model Configuration</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px5.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px5.p1.1">To investigate scaling trends, we train models at five different sizes – 0.16B, 0.37B, 0.76B, 1.4B, and 7B parameters – following the standard settings from Llama <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib46" title="">2023a</a>)</cite>.
Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.T2" title="Table 2 ‣ Evaluation ‣ 4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">2</span></a> describes each setting in detail.
In configurations that use linear patch encoding (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS2" title="4.2 Controlled Comparison with Chameleon ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.2</span></a> and §<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3" title="4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.3</span></a>), the number of additional parameters is insignificant, accounting for fewer than 0.5% of total parameters in every configuration.
When using U-Net patch encoding (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3" title="4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.3</span></a> and §<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS4" title="4.4 Comparison with Image Generation Literature ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.4</span></a>), these parameters add up to 0.27B additional parameters across all configurations; while this is a substantial addition of parameters to smaller models, these layers amount to only a 3.8% increase of the 7B configuration, almost identical to the number of parameters in the embedding layers.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px6">
<h5 class="ltx_title ltx_title_paragraph">Optimization</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px6.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px6.p1.5">We randomly initialize all model parameters, and optimize them using AdamW (<math alttext="\beta_{1}=" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px6.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px6.p1.1.m1.1a"><mrow id="S4.SS1.SSS0.Px6.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.cmml"><msub id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.cmml"><mi id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.2" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.2.cmml">β</mi><mn id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.3" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.3.cmml">1</mn></msub><mo id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.1" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.1.cmml">=</mo><mi id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.1.m1.1b"><apply id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1"><eq id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.1"></eq><apply id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.2">𝛽</ci><cn id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.3.cmml" type="integer" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.2.3">1</cn></apply><csymbol cd="latexml" id="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.1.m1.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.1.m1.1c">\beta_{1}=</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px6.p1.1.m1.1d">italic_β start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT =</annotation></semantics></math>0.9, <math alttext="\beta_{2}=" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px6.p1.2.m2.1"><semantics id="S4.SS1.SSS0.Px6.p1.2.m2.1a"><mrow id="S4.SS1.SSS0.Px6.p1.2.m2.1.1" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.cmml"><msub id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.cmml"><mi id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.2" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.2.cmml">β</mi><mn id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.3" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.3.cmml">2</mn></msub><mo id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.1" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.1.cmml">=</mo><mi id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.2.m2.1b"><apply id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1"><eq id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.1"></eq><apply id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.1.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2">subscript</csymbol><ci id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.2.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.2">𝛽</ci><cn id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.3.cmml" type="integer" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.2.3">2</cn></apply><csymbol cd="latexml" id="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.2.m2.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.2.m2.1c">\beta_{2}=</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px6.p1.2.m2.1d">italic_β start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT =</annotation></semantics></math>0.95, <math alttext="\epsilon=" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px6.p1.3.m3.1"><semantics id="S4.SS1.SSS0.Px6.p1.3.m3.1a"><mrow id="S4.SS1.SSS0.Px6.p1.3.m3.1.1" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.cmml"><mi id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.2" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.2.cmml">ϵ</mi><mo id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.1" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.1.cmml">=</mo><mi id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.3" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.3.cmml"></mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.3.m3.1b"><apply id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1"><eq id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.1"></eq><ci id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.2.cmml" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.2">italic-ϵ</ci><csymbol cd="latexml" id="S4.SS1.SSS0.Px6.p1.3.m3.1.1.3.cmml" xref="S4.SS1.SSS0.Px6.p1.3.m3.1.1.3">absent</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.3.m3.1c">\epsilon=</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px6.p1.3.m3.1d">italic_ϵ =</annotation></semantics></math>1e-8) with a learning rate of 3e-4, warmed up for 4000 steps and decaying to 1.5e-5 using a cosine scheduler.
We train on sequences of 4096 tokens in batches of 2M tokens for 250k steps, reaching 0.5T tokens in total.
In our large-scale experiment (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS4" title="4.4 Comparison with Image Generation Literature ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.4</span></a>), we train with a batch size of 4M tokens over 500k steps, totalling 2T tokens.
We regularize with weight decay of 0.1 and clip gradients by norm (1.0).
We set the <math alttext="\lambda" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px6.p1.4.m4.1"><semantics id="S4.SS1.SSS0.Px6.p1.4.m4.1a"><mi id="S4.SS1.SSS0.Px6.p1.4.m4.1.1" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.4.m4.1b"><ci id="S4.SS1.SSS0.Px6.p1.4.m4.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.4.m4.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.4.m4.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px6.p1.4.m4.1d">italic_λ</annotation></semantics></math> coefficient in the Transfusion objective (Equation <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S3.E4" title="In Training Objective ‣ 3 Transfusion ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4</span></a>) to 5 following preliminary experiments;
we leave further tuning of <math alttext="\lambda" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px6.p1.5.m5.1"><semantics id="S4.SS1.SSS0.Px6.p1.5.m5.1a"><mi id="S4.SS1.SSS0.Px6.p1.5.m5.1.1" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px6.p1.5.m5.1b"><ci id="S4.SS1.SSS0.Px6.p1.5.m5.1.1.cmml" xref="S4.SS1.SSS0.Px6.p1.5.m5.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px6.p1.5.m5.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px6.p1.5.m5.1d">italic_λ</annotation></semantics></math> to future work.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px7">
<h5 class="ltx_title ltx_title_paragraph">Inference</h5>
<div class="ltx_para" id="S4.SS1.SSS0.Px7.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px7.p1.1">In text mode, we use greedy decoding for generating text.
Ranked classification is used for the Llama evaluation suite.
For image generation, we follow the standard of 250 diffusion steps (the model is trained on 1,000 timesteps).
We follow Chameleon and use CFG with a coefficient of 5 in the controlled comparison experiments (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS2" title="4.2 Controlled Comparison with Chameleon ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.2</span></a>).
This value is suboptimal for Transfusion, and so we use a CFG coefficient of 3 throughout the ablation experiments (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS3" title="4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.3</span></a>), and follow the standard practice of tuning the coefficient for each benchmark in our large scale experiment (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS4" title="4.4 Comparison with Image Generation Literature ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.4</span></a>).</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Controlled Comparison with Chameleon</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.4">We run a series of controlled experiments to compare Transfusion with Chameleon at different model sizes (<math alttext="N" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mi id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><ci id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">N</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">italic_N</annotation></semantics></math>) and token counts (<math alttext="D" class="ltx_Math" display="inline" id="S4.SS2.p1.2.m2.1"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.2.m2.1d">italic_D</annotation></semantics></math>), using the combination of both as a proxy for FLOPs (<math alttext="6ND" class="ltx_Math" display="inline" id="S4.SS2.p1.3.m3.1"><semantics id="S4.SS2.p1.3.m3.1a"><mrow id="S4.SS2.p1.3.m3.1.1" xref="S4.SS2.p1.3.m3.1.1.cmml"><mn id="S4.SS2.p1.3.m3.1.1.2" xref="S4.SS2.p1.3.m3.1.1.2.cmml">6</mn><mo id="S4.SS2.p1.3.m3.1.1.1" xref="S4.SS2.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.3.m3.1.1.3" xref="S4.SS2.p1.3.m3.1.1.3.cmml">N</mi><mo id="S4.SS2.p1.3.m3.1.1.1a" xref="S4.SS2.p1.3.m3.1.1.1.cmml">⁢</mo><mi id="S4.SS2.p1.3.m3.1.1.4" xref="S4.SS2.p1.3.m3.1.1.4.cmml">D</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.3.m3.1b"><apply id="S4.SS2.p1.3.m3.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1"><times id="S4.SS2.p1.3.m3.1.1.1.cmml" xref="S4.SS2.p1.3.m3.1.1.1"></times><cn id="S4.SS2.p1.3.m3.1.1.2.cmml" type="integer" xref="S4.SS2.p1.3.m3.1.1.2">6</cn><ci id="S4.SS2.p1.3.m3.1.1.3.cmml" xref="S4.SS2.p1.3.m3.1.1.3">𝑁</ci><ci id="S4.SS2.p1.3.m3.1.1.4.cmml" xref="S4.SS2.p1.3.m3.1.1.4">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.3.m3.1c">6ND</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.3.m3.1d">6 italic_N italic_D</annotation></semantics></math>).<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>Since Transfusion uses continuous representations of images, it can express a single image with significantly fewer tokens, shortening the average document length and thus the overall quadratic price of attention. Since this fact favors Transfusion, we remove this confounder by using the theoretical FLOP calculation.</span></span></span>
For simplicity and parameter control, the Transfusion variant in these experiments uses simple linear image encoder/decoder with patch size 2<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS2.p1.4.m4.1"><semantics id="S4.SS2.p1.4.m4.1a"><mo id="S4.SS2.p1.4.m4.1.1" xref="S4.SS2.p1.4.m4.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.4.m4.1b"><times id="S4.SS2.p1.4.m4.1.1.cmml" xref="S4.SS2.p1.4.m4.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.4.m4.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.4.m4.1d">×</annotation></semantics></math>2, as well as bidirectional attention.
For each benchmark, we plot all results on a log-metric over log-FLOPs curve and regress linear trendlines.<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>The smaller Chameleon models perform poorly on image generation and understanding tasks, leading to outlier results that do not correlate with the emerging scaling law of larger Chameleon models. We therefore define minimal performance thresholds below which we remove datapoints: <math alttext="\leq" class="ltx_Math" display="inline" id="footnote14.m1.1"><semantics id="footnote14.m1.1b"><mo id="footnote14.m1.1.1" xref="footnote14.m1.1.1.cmml">≤</mo><annotation-xml encoding="MathML-Content" id="footnote14.m1.1c"><leq id="footnote14.m1.1.1.cmml" xref="footnote14.m1.1.1"></leq></annotation-xml><annotation encoding="application/x-tex" id="footnote14.m1.1d">\leq</annotation><annotation encoding="application/x-llamapun" id="footnote14.m1.1e">≤</annotation></semantics></math>100 FID, <math alttext="\geq" class="ltx_Math" display="inline" id="footnote14.m2.1"><semantics id="footnote14.m2.1b"><mo id="footnote14.m2.1.1" xref="footnote14.m2.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="footnote14.m2.1c"><geq id="footnote14.m2.1.1.cmml" xref="footnote14.m2.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="footnote14.m2.1d">\geq</annotation><annotation encoding="application/x-llamapun" id="footnote14.m2.1e">≥</annotation></semantics></math>17 CLIP, <math alttext="\geq" class="ltx_Math" display="inline" id="footnote14.m3.1"><semantics id="footnote14.m3.1b"><mo id="footnote14.m3.1.1" xref="footnote14.m3.1.1.cmml">≥</mo><annotation-xml encoding="MathML-Content" id="footnote14.m3.1c"><geq id="footnote14.m3.1.1.cmml" xref="footnote14.m3.1.1"></geq></annotation-xml><annotation encoding="application/x-tex" id="footnote14.m3.1d">\geq</annotation><annotation encoding="application/x-llamapun" id="footnote14.m3.1e">≥</annotation></semantics></math>4 CIDEr.</span></span></span>
We also estimate relative compute efficiency by measuring the parity FLOP ratio: the ratio between the number of FLOPs required by Transfusion and Chameleon to reach the same level of performance.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.F5" title="Figure 5 ‣ 4.2 Controlled Comparison with Chameleon ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">5</span></a> visualizes the scaling trends,
and Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.T3" title="Table 3 ‣ 4.2 Controlled Comparison with Chameleon ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">3</span></a> shows the results of the largest models in this controlled setting and their estimated parity FLOP ratio.
In every benchmark, Transfusion consistently exhibits better scaling laws than Chameleon.
While the lines are close to parallel, there is a significant gap in Transfusion’s favor.
The difference in compute efficiency is particularly striking in image generation, where FID Transfusion achieves parity with Chameleon using 34<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS2.p2.1.m1.1"><semantics id="S4.SS2.p2.1.m1.1a"><mo id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><times id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p2.1.m1.1d">×</annotation></semantics></math> less compute.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">Surprisingly, text-only benchmarks also reveal better performance with Transfusion, even though both Transfusion and Chameleon model text in the same way.
We investigate this phenomenon by ablating the various changes leading up to Transfusion and Chameleon from the original Llama 2 recipe.
Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.T4" title="Table 4 ‣ 4.2 Controlled Comparison with Chameleon ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4</span></a> shows that while Transfusion does come at a non-zero cost to text performance, the Chameleon recipe suffers from both the stability modifications made to the architecture and from the introduction of image tokens.
Training on quantized image tokens degrades text performance more than diffusion on all three benchmarks.
One hypothesis is that this stems from the competition between text and image tokens in the output distribution;
alternatively, it is possible that diffusion is more efficient at image generation and requires fewer parameters, allowing Transfusion models to use more capacity than Chameleon to model text.
We leave further investigation of this phenomenon to future research.</p>
</div>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="487" id="S4.F5.sf1.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf1.2.1.1" style="font-size:90%;">((a))</span> </span><span class="ltx_text" id="S4.F5.sf1.3.2" style="font-size:90%;">C4 Perplexity</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="495" id="S4.F5.sf2.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf2.2.1.1" style="font-size:90%;">((b))</span> </span><span class="ltx_text" id="S4.F5.sf2.3.2" style="font-size:90%;">Wikipedia Perplexity</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="495" id="S4.F5.sf3.g1" src="x6.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf3.2.1.1" style="font-size:90%;">((c))</span> </span><span class="ltx_text" id="S4.F5.sf3.3.2" style="font-size:90%;">Llama 2 Eval Suite Accuracy</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="487" id="S4.F5.sf4.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf4.2.1.1" style="font-size:90%;">((d))</span> </span><span class="ltx_text" id="S4.F5.sf4.3.2" style="font-size:90%;">MS-COCO 5k CIDEr</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="480" id="S4.F5.sf5.g1" src="x8.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf5.2.1.1" style="font-size:90%;">((e))</span> </span><span class="ltx_text" id="S4.F5.sf5.3.2" style="font-size:90%;">MS-COCO 30k FID</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F5.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="487" id="S4.F5.sf6.g1" src="x9.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.sf6.2.1.1" style="font-size:90%;">((f))</span> </span><span class="ltx_text" id="S4.F5.sf6.3.2" style="font-size:90%;">MS-COCO 30k CLIP</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S4.F5.3.2" style="font-size:90%;">Performance of Transfusion and Chameleon models at different scales, controlled for parameters, data, and compute. All axes are logarithmic.</span></figcaption>
</figure>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T3.6.7.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.6.7.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.2.1" style="font-size:90%;">C4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.6.7.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.3.1" style="font-size:90%;">Wiki</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T3.6.7.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.4.1" style="font-size:90%;">Llama</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T3.6.7.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.6.7.1.5.1" style="font-size:90%;">MS-COCO</span></th>
</tr>
<tr class="ltx_tr" id="S4.T3.6.6">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.1.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T3.1.1.1.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T3.1.1.1.m1.1"><semantics id="S4.T3.1.1.1.m1.1a"><mo id="S4.T3.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T3.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.1.1.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T3.1.1.1.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T3.2.2.2.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T3.2.2.2.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T3.2.2.2.m1.1"><semantics id="S4.T3.2.2.2.m1.1a"><mo id="S4.T3.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T3.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.2.2.2.m1.1b"><ci id="S4.T3.2.2.2.m1.1.1.cmml" xref="S4.T3.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.2.2.2.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T3.2.2.2.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T3.3.3.3.1" style="font-size:90%;">Acc</span><span class="ltx_text" id="S4.T3.3.3.3.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.3.3.3.m1.1"><semantics id="S4.T3.3.3.3.m1.1a"><mo id="S4.T3.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T3.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.3.3.3.m1.1b"><ci id="S4.T3.3.3.3.m1.1.1.cmml" xref="S4.T3.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.3.3.3.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T3.3.3.3.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.4.4.4">
<span class="ltx_text ltx_font_bold" id="S4.T3.4.4.4.1" style="font-size:90%;">CDr</span><span class="ltx_text" id="S4.T3.4.4.4.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.4.4.4.m1.1"><semantics id="S4.T3.4.4.4.m1.1a"><mo id="S4.T3.4.4.4.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T3.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.4.4.4.m1.1b"><ci id="S4.T3.4.4.4.m1.1.1.cmml" xref="S4.T3.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.4.4.4.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T3.4.4.4.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T3.5.5.5">
<span class="ltx_text ltx_font_bold" id="S4.T3.5.5.5.1" style="font-size:90%;">FID</span><span class="ltx_text" id="S4.T3.5.5.5.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T3.5.5.5.m1.1"><semantics id="S4.T3.5.5.5.m1.1a"><mo id="S4.T3.5.5.5.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T3.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T3.5.5.5.m1.1b"><ci id="S4.T3.5.5.5.m1.1.1.cmml" xref="S4.T3.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.5.5.5.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T3.5.5.5.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column" id="S4.T3.6.6.6">
<span class="ltx_text ltx_font_bold" id="S4.T3.6.6.6.1" style="font-size:90%;">CLIP</span><span class="ltx_text" id="S4.T3.6.6.6.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T3.6.6.6.m1.1"><semantics id="S4.T3.6.6.6.m1.1a"><mo id="S4.T3.6.6.6.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T3.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T3.6.6.6.m1.1b"><ci id="S4.T3.6.6.6.m1.1.1.cmml" xref="S4.T3.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.6.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T3.6.6.6.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T3.6.6.6.3" style="font-size:90%;">)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.6.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T3.6.8.1.1"><span class="ltx_text" id="S4.T3.6.8.1.1.1" style="font-size:90%;">Transfusion</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.8.1.2"><span class="ltx_text ltx_font_bold" id="S4.T3.6.8.1.2.1" style="font-size:90%;">7.72</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.8.1.3"><span class="ltx_text ltx_font_bold" id="S4.T3.6.8.1.3.1" style="font-size:90%;">4.28</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.8.1.4"><span class="ltx_text ltx_font_bold" id="S4.T3.6.8.1.4.1" style="font-size:90%;">61.5</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.8.1.5"><span class="ltx_text ltx_font_bold" id="S4.T3.6.8.1.5.1" style="font-size:90%;">27.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T3.6.8.1.6"><span class="ltx_text ltx_font_bold" id="S4.T3.6.8.1.6.1" style="font-size:90%;">16.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T3.6.8.1.7"><span class="ltx_text ltx_font_bold" id="S4.T3.6.8.1.7.1" style="font-size:90%;">25.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.9.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T3.6.9.2.1"><span class="ltx_text" id="S4.T3.6.9.2.1.1" style="font-size:90%;">Chameleon</span></th>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.2.2"><span class="ltx_text" id="S4.T3.6.9.2.2.1" style="font-size:90%;">8.41</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.2.3"><span class="ltx_text" id="S4.T3.6.9.2.3.1" style="font-size:90%;">4.69</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.2.4"><span class="ltx_text" id="S4.T3.6.9.2.4.1" style="font-size:90%;">59.1</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.2.5"><span class="ltx_text" id="S4.T3.6.9.2.5.1" style="font-size:90%;">18.0</span></td>
<td class="ltx_td ltx_align_right" id="S4.T3.6.9.2.6"><span class="ltx_text" id="S4.T3.6.9.2.6.1" style="font-size:90%;">29.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T3.6.9.2.7"><span class="ltx_text" id="S4.T3.6.9.2.7.1" style="font-size:90%;">24.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T3.6.10.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T3.6.10.3.1"><span class="ltx_text" id="S4.T3.6.10.3.1.1" style="font-size:90%;">Parity FLOP Ratio</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S4.T3.6.10.3.2"><span class="ltx_text" id="S4.T3.6.10.3.2.1" style="font-size:90%;">0.489</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S4.T3.6.10.3.3"><span class="ltx_text" id="S4.T3.6.10.3.3.1" style="font-size:90%;">0.526</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S4.T3.6.10.3.4"><span class="ltx_text" id="S4.T3.6.10.3.4.1" style="font-size:90%;">0.600</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S4.T3.6.10.3.5"><span class="ltx_text" id="S4.T3.6.10.3.5.1" style="font-size:90%;">0.218</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb ltx_border_t" id="S4.T3.6.10.3.6"><span class="ltx_text" id="S4.T3.6.10.3.6.1" style="font-size:90%;">0.029</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb ltx_border_t" id="S4.T3.6.10.3.7"><span class="ltx_text" id="S4.T3.6.10.3.7.1" style="font-size:90%;">0.319</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Performance of the largest (7B) Transfusion and Chameleon models in a controlled setting. Both models were trained on 0.5T tokens. <span class="ltx_text ltx_font_bold" id="S4.T3.12.1">Parity FLOP Ratio</span> is the relative amount of Transfusion FLOPs needed to match the results of Chameleon 7B.</figcaption>
</figure>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T4.3">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.3.4.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T4.3.4.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.4.1.1.1" style="font-size:90%;">Model</span></td>
<td class="ltx_td ltx_border_tt" id="S4.T4.3.4.1.2"></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T4.3.4.1.3" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T4.3.4.1.3.1" style="font-size:90%;">Batch</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.4.1.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.4.1.4.1" style="font-size:90%;">C4</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T4.3.4.1.5"><span class="ltx_text ltx_font_bold" id="S4.T4.3.4.1.5.1" style="font-size:90%;">Wiki</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_tt" id="S4.T4.3.4.1.6"><span class="ltx_text ltx_font_bold" id="S4.T4.3.4.1.6.1" style="font-size:90%;">Llama</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3">
<td class="ltx_td" id="S4.T4.3.3.4"></td>
<td class="ltx_td ltx_align_right" id="S4.T4.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T4.1.1.1.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T4.1.1.1.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.1.1.1.m1.1"><semantics id="S4.T4.1.1.1.m1.1a"><mo id="S4.T4.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T4.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.1.1.1.m1.1b"><ci id="S4.T4.1.1.1.m1.1.1.cmml" xref="S4.T4.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.1.1.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T4.1.1.1.3" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_right" id="S4.T4.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T4.2.2.2.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T4.2.2.2.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T4.2.2.2.m1.1"><semantics id="S4.T4.2.2.2.m1.1a"><mo id="S4.T4.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T4.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.2.2.m1.1b"><ci id="S4.T4.2.2.2.m1.1.1.cmml" xref="S4.T4.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.2.2.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T4.2.2.2.3" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T4.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T4.3.3.3.1" style="font-size:90%;">Acc</span><span class="ltx_text" id="S4.T4.3.3.3.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T4.3.3.3.m1.1"><semantics id="S4.T4.3.3.3.m1.1a"><mo id="S4.T4.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T4.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T4.3.3.3.m1.1b"><ci id="S4.T4.3.3.3.m1.1.1.cmml" xref="S4.T4.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T4.3.3.3.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T4.3.3.3.3" style="font-size:90%;">)</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.5.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.3.5.2.1"><span class="ltx_text" id="S4.T4.3.5.2.1.1" style="font-size:90%;">Llama 2</span></td>
<td class="ltx_td ltx_border_t" id="S4.T4.3.5.2.2"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.3.5.2.3"><span class="ltx_text" id="S4.T4.3.5.2.3.1" style="font-size:90%;">1M Text Tokens</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.3.5.2.4"><span class="ltx_text" id="S4.T4.3.5.2.4.1" style="font-size:90%;">10.1</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.3.5.2.5"><span class="ltx_text" id="S4.T4.3.5.2.5.1" style="font-size:90%;">5.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T4.3.5.2.6"><span class="ltx_text" id="S4.T4.3.5.2.6.1" style="font-size:90%;">53.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.6.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.3.6.3.1"><span class="ltx_text" id="S4.T4.3.6.3.1.1" style="font-size:90%;">Transfusion</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.3.6.3.2"><span class="ltx_text" id="S4.T4.3.6.3.2.1" style="font-size:90%;">+ Diffusion</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.3.6.3.3"><span class="ltx_text" id="S4.T4.3.6.3.3.1" style="font-size:90%;">+ 1M Image Patches</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.3.6.3.4"><span class="ltx_text" id="S4.T4.3.6.3.4.1" style="font-size:90%;">(+0.3) 10.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.3.6.3.5"><span class="ltx_text" id="S4.T4.3.6.3.5.1" style="font-size:90%;">(+0.2) 6.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T4.3.6.3.6"><span class="ltx_text" id="S4.T4.3.6.3.6.1" style="font-size:90%;">(-2.0) 51.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.7.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.3.7.4.1"><span class="ltx_text" id="S4.T4.3.7.4.1.1" style="font-size:90%;">Chameleon</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.3.7.4.2"><span class="ltx_text" id="S4.T4.3.7.4.2.1" style="font-size:90%;">+ Stability Modifications</span></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T4.3.7.4.3"><span class="ltx_text" id="S4.T4.3.7.4.3.1" style="font-size:90%;">1M Text Tokens</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.3.7.4.4"><span class="ltx_text" id="S4.T4.3.7.4.4.1" style="font-size:90%;">(+0.9) 11.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T4.3.7.4.5"><span class="ltx_text" id="S4.T4.3.7.4.5.1" style="font-size:90%;">(+0.5) 6.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T4.3.7.4.6"><span class="ltx_text" id="S4.T4.3.7.4.6.1" style="font-size:90%;">(-1.8) 51.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.8.5">
<td class="ltx_td ltx_border_bb" id="S4.T4.3.8.5.1"></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.3.8.5.2"><span class="ltx_text" id="S4.T4.3.8.5.2.1" style="font-size:90%;">+ LM Loss on Image Tokens</span></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T4.3.8.5.3"><span class="ltx_text" id="S4.T4.3.8.5.3.1" style="font-size:90%;">+ 1M Image Tokens</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T4.3.8.5.4"><span class="ltx_text" id="S4.T4.3.8.5.4.1" style="font-size:90%;">(+0.8) 11.8</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T4.3.8.5.5"><span class="ltx_text" id="S4.T4.3.8.5.5.1" style="font-size:90%;">(+0.5) 6.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S4.T4.3.8.5.6"><span class="ltx_text" id="S4.T4.3.8.5.6.1" style="font-size:90%;">(-3.0) 48.9</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance of the 0.76B Transfusion and Chameleon models on text-only benchmarks, compared to the original Llama 2 recipe.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Architecture Ablations</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">Now that we have established that Transfusion is a viable, scalable approach to multi-modal modeling in a controlled environment, we can explore improvements and extensions that are applicable to Transfusion alone.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1 </span>Attention Masking</h4>
<div class="ltx_para" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">We first examine the necessity of intra-image bidirectional attention.
Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.T5" title="Table 5 ‣ 4.3.1 Attention Masking ‣ 4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">5</span></a> shows that enabling this attention pattern beyond the standard causal attention is advantageous throughout all benchmarks, and using both image encoding/decoding architectures.
In particular, we notice a significant improvement in FID when using linear encoding layers (61.3<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS3.SSS1.p1.1.m1.1"><semantics id="S4.SS3.SSS1.p1.1.m1.1a"><mo id="S4.SS3.SSS1.p1.1.m1.1.1" stretchy="false" xref="S4.SS3.SSS1.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS1.p1.1.m1.1b"><ci id="S4.SS3.SSS1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS1.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS1.p1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS1.p1.1.m1.1d">→</annotation></semantics></math>20.3).
In the causal-only version of this architecture, there is no flow of information from patches that appear later in the sequence to those before;
since U-Net blocks contain bidirectional attention within, independent of the transformer’s attention mask, this gap is less pronounced when they are applied.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.6.7.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T5.6.7.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T5.6.7.1.1.1" style="font-size:90%;">Enc/Dec</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T5.6.7.1.2" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T5.6.7.1.2.1" style="font-size:90%;">Attention</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.6.7.1.3"><span class="ltx_text ltx_font_bold" id="S4.T5.6.7.1.3.1" style="font-size:90%;">C4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.6.7.1.4"><span class="ltx_text ltx_font_bold" id="S4.T5.6.7.1.4.1" style="font-size:90%;">Wiki</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.6.7.1.5"><span class="ltx_text ltx_font_bold" id="S4.T5.6.7.1.5.1" style="font-size:90%;">Llama</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T5.6.7.1.6"><span class="ltx_text ltx_font_bold" id="S4.T5.6.7.1.6.1" style="font-size:90%;">MS-COCO</span></th>
</tr>
<tr class="ltx_tr" id="S4.T5.6.6">
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T5.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T5.1.1.1.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T5.1.1.1.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.1.1.1.m1.1"><semantics id="S4.T5.1.1.1.m1.1a"><mo id="S4.T5.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T5.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.m1.1b"><ci id="S4.T5.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.1.1.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T5.1.1.1.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T5.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T5.2.2.2.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T5.2.2.2.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.2.2.2.m1.1"><semantics id="S4.T5.2.2.2.m1.1a"><mo id="S4.T5.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T5.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.m1.1b"><ci id="S4.T5.2.2.2.m1.1.1.cmml" xref="S4.T5.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.2.2.2.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T5.2.2.2.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T5.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T5.3.3.3.1" style="font-size:90%;">Acc</span><span class="ltx_text" id="S4.T5.3.3.3.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.3.3.3.m1.1"><semantics id="S4.T5.3.3.3.m1.1a"><mo id="S4.T5.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T5.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.m1.1b"><ci id="S4.T5.3.3.3.m1.1.1.cmml" xref="S4.T5.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.3.3.3.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T5.3.3.3.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T5.4.4.4">
<span class="ltx_text ltx_font_bold" id="S4.T5.4.4.4.1" style="font-size:90%;">CDr</span><span class="ltx_text" id="S4.T5.4.4.4.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.4.4.4.m1.1"><semantics id="S4.T5.4.4.4.m1.1a"><mo id="S4.T5.4.4.4.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T5.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.4.m1.1b"><ci id="S4.T5.4.4.4.m1.1.1.cmml" xref="S4.T5.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.4.4.4.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T5.4.4.4.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T5.5.5.5">
<span class="ltx_text ltx_font_bold" id="S4.T5.5.5.5.1" style="font-size:90%;">FID</span><span class="ltx_text" id="S4.T5.5.5.5.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.5.5.5.m1.1"><semantics id="S4.T5.5.5.5.m1.1a"><mo id="S4.T5.5.5.5.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T5.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.5.5.5.m1.1b"><ci id="S4.T5.5.5.5.m1.1.1.cmml" xref="S4.T5.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.5.5.5.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T5.5.5.5.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column" id="S4.T5.6.6.6">
<span class="ltx_text ltx_font_bold" id="S4.T5.6.6.6.1" style="font-size:90%;">CLIP</span><span class="ltx_text" id="S4.T5.6.6.6.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.6.6.6.m1.1"><semantics id="S4.T5.6.6.6.m1.1a"><mo id="S4.T5.6.6.6.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T5.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.6.6.m1.1b"><ci id="S4.T5.6.6.6.m1.1.1.cmml" xref="S4.T5.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.6.6.6.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T5.6.6.6.3" style="font-size:90%;">)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.6.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.6.8.1.1" rowspan="2"><span class="ltx_text" id="S4.T5.6.8.1.1.1" style="font-size:90%;">Linear</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.6.8.1.2"><span class="ltx_text" id="S4.T5.6.8.1.2.1" style="font-size:90%;">Causal</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.8.1.3"><span class="ltx_text" id="S4.T5.6.8.1.3.1" style="font-size:90%;">10.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.8.1.4"><span class="ltx_text" id="S4.T5.6.8.1.4.1" style="font-size:90%;">6.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.8.1.5"><span class="ltx_text" id="S4.T5.6.8.1.5.1" style="font-size:90%;">51.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.8.1.6"><span class="ltx_text" id="S4.T5.6.8.1.6.1" style="font-size:90%;">12.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.8.1.7"><span class="ltx_text" id="S4.T5.6.8.1.7.1" style="font-size:90%;">61.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T5.6.8.1.8"><span class="ltx_text" id="S4.T5.6.8.1.8.1" style="font-size:90%;">23.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.9.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T5.6.9.2.1"><span class="ltx_text" id="S4.T5.6.9.2.1.1" style="font-size:90%;">Bidirectional</span></th>
<td class="ltx_td ltx_align_right" id="S4.T5.6.9.2.2"><span class="ltx_text" id="S4.T5.6.9.2.2.1" style="font-size:90%;">10.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.6.9.2.3"><span class="ltx_text" id="S4.T5.6.9.2.3.1" style="font-size:90%;">6.0</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.6.9.2.4"><span class="ltx_text" id="S4.T5.6.9.2.4.1" style="font-size:90%;">51.7</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.6.9.2.5"><span class="ltx_text" id="S4.T5.6.9.2.5.1" style="font-size:90%;">16.0</span></td>
<td class="ltx_td ltx_align_right" id="S4.T5.6.9.2.6"><span class="ltx_text" id="S4.T5.6.9.2.6.1" style="font-size:90%;">20.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T5.6.9.2.7"><span class="ltx_text" id="S4.T5.6.9.2.7.1" style="font-size:90%;">24.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.10.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T5.6.10.3.1" rowspan="2"><span class="ltx_text" id="S4.T5.6.10.3.1.1" style="font-size:90%;">U-Net</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T5.6.10.3.2"><span class="ltx_text" id="S4.T5.6.10.3.2.1" style="font-size:90%;">Causal</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.10.3.3"><span class="ltx_text" id="S4.T5.6.10.3.3.1" style="font-size:90%;">10.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.10.3.4"><span class="ltx_text" id="S4.T5.6.10.3.4.1" style="font-size:90%;">5.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.10.3.5"><span class="ltx_text" id="S4.T5.6.10.3.5.1" style="font-size:90%;">52.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.10.3.6"><span class="ltx_text" id="S4.T5.6.10.3.6.1" style="font-size:90%;">23.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T5.6.10.3.7"><span class="ltx_text" id="S4.T5.6.10.3.7.1" style="font-size:90%;">16.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T5.6.10.3.8"><span class="ltx_text" id="S4.T5.6.10.3.8.1" style="font-size:90%;">25.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T5.6.11.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T5.6.11.4.1"><span class="ltx_text" id="S4.T5.6.11.4.1.1" style="font-size:90%;">Bidirectional</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.6.11.4.2"><span class="ltx_text" id="S4.T5.6.11.4.2.1" style="font-size:90%;">10.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.6.11.4.3"><span class="ltx_text" id="S4.T5.6.11.4.3.1" style="font-size:90%;">5.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.6.11.4.4"><span class="ltx_text" id="S4.T5.6.11.4.4.1" style="font-size:90%;">51.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.6.11.4.5"><span class="ltx_text" id="S4.T5.6.11.4.5.1" style="font-size:90%;">25.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T5.6.11.4.6"><span class="ltx_text" id="S4.T5.6.11.4.6.1" style="font-size:90%;">16.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S4.T5.6.11.4.7"><span class="ltx_text" id="S4.T5.6.11.4.7.1" style="font-size:90%;">25.4</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance of 0.76B Transfusion models with and without intra-image bidirectional attention. Patch size is set at 2<math alttext="\times" class="ltx_Math" display="inline" id="S4.T5.8.m1.1"><semantics id="S4.T5.8.m1.1b"><mo id="S4.T5.8.m1.1.1" xref="S4.T5.8.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T5.8.m1.1c"><times id="S4.T5.8.m1.1.1.cmml" xref="S4.T5.8.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.m1.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T5.8.m1.1e">×</annotation></semantics></math>2 latent pixels.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2 </span>Patch Size</h4>
<div class="ltx_para" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">Transfusion models can be defined over different sizes of latent pixel patches.
Larger patch sizes allow the model to pack more images in each training batch and dramatically reduce inference compute, but may come at a performance cost.
Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.T6" title="Table 6 ‣ 4.3.2 Patch Size ‣ 4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">6</span></a> sheds light on these performance trade-offs.
While performance does decrease consistently as each image is represented by fewer patches with linear encoding, models with U-Net encoding benefit from larger patches on tasks involving the image modality.
We posit that this is due to the greater amount of total images (and diffusion noise) seen during training.
We also observe that text performance deteriorates with larger patches, perhaps because transfusion needs to exert more resources (i.e. parameters) to learn how to process images with fewer patches and thus less inference compute.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T6.20">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.20.21.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="S4.T6.20.21.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T6.20.21.1.1.1" style="font-size:90%;">Enc/Dec</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.20.21.1.2"><span class="ltx_text ltx_font_bold" id="S4.T6.20.21.1.2.1" style="font-size:90%;">Latent/</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.20.21.1.3"><span class="ltx_text ltx_font_bold" id="S4.T6.20.21.1.3.1" style="font-size:90%;">Pixel/</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.20.21.1.4"><span class="ltx_text ltx_font_bold" id="S4.T6.20.21.1.4.1" style="font-size:90%;">Patch/</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.20.21.1.5"><span class="ltx_text ltx_font_bold" id="S4.T6.20.21.1.5.1" style="font-size:90%;">C4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.20.21.1.6"><span class="ltx_text ltx_font_bold" id="S4.T6.20.21.1.6.1" style="font-size:90%;">Wiki</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.20.21.1.7"><span class="ltx_text ltx_font_bold" id="S4.T6.20.21.1.7.1" style="font-size:90%;">Llama</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T6.20.21.1.8"><span class="ltx_text ltx_font_bold" id="S4.T6.20.21.1.8.1" style="font-size:90%;">MS-COCO</span></th>
</tr>
<tr class="ltx_tr" id="S4.T6.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T6.6.6.7"><span class="ltx_text ltx_font_bold" id="S4.T6.6.6.7.1" style="font-size:90%;">Patch</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T6.6.6.8"><span class="ltx_text ltx_font_bold" id="S4.T6.6.6.8.1" style="font-size:90%;">Patch</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T6.6.6.9"><span class="ltx_text ltx_font_bold" id="S4.T6.6.6.9.1" style="font-size:90%;">Image</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T6.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T6.1.1.1.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T6.1.1.1.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T6.1.1.1.m1.1"><semantics id="S4.T6.1.1.1.m1.1a"><mo id="S4.T6.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T6.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.1.1.1.m1.1b"><ci id="S4.T6.1.1.1.m1.1.1.cmml" xref="S4.T6.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.1.1.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T6.1.1.1.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T6.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T6.2.2.2.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T6.2.2.2.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T6.2.2.2.m1.1"><semantics id="S4.T6.2.2.2.m1.1a"><mo id="S4.T6.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T6.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.2.2.2.m1.1b"><ci id="S4.T6.2.2.2.m1.1.1.cmml" xref="S4.T6.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.2.2.2.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T6.2.2.2.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T6.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T6.3.3.3.1" style="font-size:90%;">Acc</span><span class="ltx_text" id="S4.T6.3.3.3.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T6.3.3.3.m1.1"><semantics id="S4.T6.3.3.3.m1.1a"><mo id="S4.T6.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T6.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.3.3.3.m1.1b"><ci id="S4.T6.3.3.3.m1.1.1.cmml" xref="S4.T6.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.3.3.3.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T6.3.3.3.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T6.4.4.4">
<span class="ltx_text ltx_font_bold" id="S4.T6.4.4.4.1" style="font-size:90%;">CDr</span><span class="ltx_text" id="S4.T6.4.4.4.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T6.4.4.4.m1.1"><semantics id="S4.T6.4.4.4.m1.1a"><mo id="S4.T6.4.4.4.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T6.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.4.4.4.m1.1b"><ci id="S4.T6.4.4.4.m1.1.1.cmml" xref="S4.T6.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.4.4.4.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T6.4.4.4.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T6.5.5.5">
<span class="ltx_text ltx_font_bold" id="S4.T6.5.5.5.1" style="font-size:90%;">FID</span><span class="ltx_text" id="S4.T6.5.5.5.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T6.5.5.5.m1.1"><semantics id="S4.T6.5.5.5.m1.1a"><mo id="S4.T6.5.5.5.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T6.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T6.5.5.5.m1.1b"><ci id="S4.T6.5.5.5.m1.1.1.cmml" xref="S4.T6.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.5.5.5.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T6.5.5.5.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column" id="S4.T6.6.6.6">
<span class="ltx_text ltx_font_bold" id="S4.T6.6.6.6.1" style="font-size:90%;">CLIP</span><span class="ltx_text" id="S4.T6.6.6.6.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T6.6.6.6.m1.1"><semantics id="S4.T6.6.6.6.m1.1a"><mo id="S4.T6.6.6.6.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T6.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T6.6.6.6.m1.1b"><ci id="S4.T6.6.6.6.m1.1.1.cmml" xref="S4.T6.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.6.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T6.6.6.6.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T6.6.6.6.3" style="font-size:90%;">)</span>
</th>
</tr>
<tr class="ltx_tr" id="S4.T6.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T6.8.8.3"><span class="ltx_text" id="S4.T6.8.8.3.1" style="font-size:90%;">None</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.7.7.1">
<span class="ltx_text" id="S4.T6.7.7.1.1" style="font-size:90%;">1</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.7.7.1.m1.1"><semantics id="S4.T6.7.7.1.m1.1a"><mo id="S4.T6.7.7.1.m1.1.1" mathsize="90%" xref="S4.T6.7.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.7.7.1.m1.1b"><times id="S4.T6.7.7.1.m1.1.1.cmml" xref="S4.T6.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.7.7.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.7.7.1.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.7.7.1.2" style="font-size:90%;">1</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.8.8.2">
<span class="ltx_text" id="S4.T6.8.8.2.1" style="font-size:90%;">8</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.8.8.2.m1.1"><semantics id="S4.T6.8.8.2.m1.1a"><mo id="S4.T6.8.8.2.m1.1.1" mathsize="90%" xref="S4.T6.8.8.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.8.8.2.m1.1b"><times id="S4.T6.8.8.2.m1.1.1.cmml" xref="S4.T6.8.8.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.8.8.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.8.8.2.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.8.8.2.2" style="font-size:90%;">8</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T6.8.8.4"><span class="ltx_text" id="S4.T6.8.8.4.1" style="font-size:90%;">1024</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T6.8.8.5"><span class="ltx_text ltx_font_bold" id="S4.T6.8.8.5.1" style="font-size:90%;">10.3</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T6.8.8.6"><span class="ltx_text ltx_font_bold" id="S4.T6.8.8.6.1" style="font-size:90%;">5.9</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T6.8.8.7"><span class="ltx_text ltx_font_bold" id="S4.T6.8.8.7.1" style="font-size:90%;">52.2</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T6.8.8.8"><span class="ltx_text" id="S4.T6.8.8.8.1" style="font-size:90%;">12.0</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T6.8.8.9"><span class="ltx_text" id="S4.T6.8.8.9.1" style="font-size:90%;">21.0</span></th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T6.8.8.10"><span class="ltx_text" id="S4.T6.8.8.10.1" style="font-size:90%;">24.0</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.10.10">
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.10.10.3" rowspan="3"><span class="ltx_text" id="S4.T6.10.10.3.1" style="font-size:90%;">Linear</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.9.9.1">
<span class="ltx_text" id="S4.T6.9.9.1.1" style="font-size:90%;">2</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.9.9.1.m1.1"><semantics id="S4.T6.9.9.1.m1.1a"><mo id="S4.T6.9.9.1.m1.1.1" mathsize="90%" xref="S4.T6.9.9.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.9.9.1.m1.1b"><times id="S4.T6.9.9.1.m1.1.1.cmml" xref="S4.T6.9.9.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.9.9.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.9.9.1.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.9.9.1.2" style="font-size:90%;">2</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.10.10.2">
<span class="ltx_text" id="S4.T6.10.10.2.1" style="font-size:90%;">16</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.10.10.2.m1.1"><semantics id="S4.T6.10.10.2.m1.1a"><mo id="S4.T6.10.10.2.m1.1.1" mathsize="90%" xref="S4.T6.10.10.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.10.10.2.m1.1b"><times id="S4.T6.10.10.2.m1.1.1.cmml" xref="S4.T6.10.10.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.10.10.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.10.10.2.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.10.10.2.2" style="font-size:90%;">16</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.10.10.4"><span class="ltx_text" id="S4.T6.10.10.4.1" style="font-size:90%;">  256</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.10.10.5"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T6.10.10.5.1" style="font-size:90%;">10.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.10.10.6"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T6.10.10.6.1" style="font-size:90%;">6.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.10.10.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T6.10.10.7.1" style="font-size:90%;">51.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.10.10.8"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T6.10.10.8.1" style="font-size:90%;">16.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.10.10.9"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T6.10.10.9.1" style="font-size:90%;">20.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T6.10.10.10"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T6.10.10.10.1" style="font-size:90%;">24.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.12.12">
<td class="ltx_td ltx_align_center" id="S4.T6.11.11.1">
<span class="ltx_text" id="S4.T6.11.11.1.1" style="font-size:90%;">4</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.11.11.1.m1.1"><semantics id="S4.T6.11.11.1.m1.1a"><mo id="S4.T6.11.11.1.m1.1.1" mathsize="90%" xref="S4.T6.11.11.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.11.11.1.m1.1b"><times id="S4.T6.11.11.1.m1.1.1.cmml" xref="S4.T6.11.11.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.11.11.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.11.11.1.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.11.11.1.2" style="font-size:90%;">4</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T6.12.12.2">
<span class="ltx_text" id="S4.T6.12.12.2.1" style="font-size:90%;">32</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.12.12.2.m1.1"><semantics id="S4.T6.12.12.2.m1.1a"><mo id="S4.T6.12.12.2.m1.1.1" mathsize="90%" xref="S4.T6.12.12.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.12.12.2.m1.1b"><times id="S4.T6.12.12.2.m1.1.1.cmml" xref="S4.T6.12.12.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.12.12.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.12.12.2.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.12.12.2.2" style="font-size:90%;">32</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T6.12.12.3"><span class="ltx_text" id="S4.T6.12.12.3.1" style="font-size:90%;">    64</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.12.12.4"><span class="ltx_text" id="S4.T6.12.12.4.1" style="font-size:90%;">10.9</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.12.12.5"><span class="ltx_text" id="S4.T6.12.12.5.1" style="font-size:90%;">6.3</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.12.12.6"><span class="ltx_text" id="S4.T6.12.12.6.1" style="font-size:90%;">49.8</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.12.12.7"><span class="ltx_text" id="S4.T6.12.12.7.1" style="font-size:90%;">14.3</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.12.12.8"><span class="ltx_text" id="S4.T6.12.12.8.1" style="font-size:90%;">25.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T6.12.12.9"><span class="ltx_text" id="S4.T6.12.12.9.1" style="font-size:90%;">22.6</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.14.14">
<td class="ltx_td ltx_align_center" id="S4.T6.13.13.1">
<span class="ltx_text" id="S4.T6.13.13.1.1" style="font-size:90%;">8</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.13.13.1.m1.1"><semantics id="S4.T6.13.13.1.m1.1a"><mo id="S4.T6.13.13.1.m1.1.1" mathsize="90%" xref="S4.T6.13.13.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.13.13.1.m1.1b"><times id="S4.T6.13.13.1.m1.1.1.cmml" xref="S4.T6.13.13.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.13.13.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.13.13.1.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.13.13.1.2" style="font-size:90%;">8</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T6.14.14.2">
<span class="ltx_text" id="S4.T6.14.14.2.1" style="font-size:90%;">64</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.14.14.2.m1.1"><semantics id="S4.T6.14.14.2.m1.1a"><mo id="S4.T6.14.14.2.m1.1.1" mathsize="90%" xref="S4.T6.14.14.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.14.14.2.m1.1b"><times id="S4.T6.14.14.2.m1.1.1.cmml" xref="S4.T6.14.14.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.14.14.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.14.14.2.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.14.14.2.2" style="font-size:90%;">64</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T6.14.14.3"><span class="ltx_text" id="S4.T6.14.14.3.1" style="font-size:90%;">    16</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.14.14.4"><span class="ltx_text" id="S4.T6.14.14.4.1" style="font-size:90%;">11.7</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.14.14.5"><span class="ltx_text" id="S4.T6.14.14.5.1" style="font-size:90%;">6.9</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.14.14.6"><span class="ltx_text" id="S4.T6.14.14.6.1" style="font-size:90%;">47.7</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.14.14.7"><span class="ltx_text" id="S4.T6.14.14.7.1" style="font-size:90%;">11.3</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.14.14.8"><span class="ltx_text" id="S4.T6.14.14.8.1" style="font-size:90%;">43.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T6.14.14.9"><span class="ltx_text" id="S4.T6.14.14.9.1" style="font-size:90%;">18.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.16.16">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T6.16.16.3" rowspan="3"><span class="ltx_text" id="S4.T6.16.16.3.1" style="font-size:90%;">U-Net</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.15.15.1">
<span class="ltx_text" id="S4.T6.15.15.1.1" style="font-size:90%;">2</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.15.15.1.m1.1"><semantics id="S4.T6.15.15.1.m1.1a"><mo id="S4.T6.15.15.1.m1.1.1" mathsize="90%" xref="S4.T6.15.15.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.15.15.1.m1.1b"><times id="S4.T6.15.15.1.m1.1.1.cmml" xref="S4.T6.15.15.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.15.15.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.15.15.1.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.15.15.1.2" style="font-size:90%;">2</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.16.16.2">
<span class="ltx_text" id="S4.T6.16.16.2.1" style="font-size:90%;">16</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.16.16.2.m1.1"><semantics id="S4.T6.16.16.2.m1.1a"><mo id="S4.T6.16.16.2.m1.1.1" mathsize="90%" xref="S4.T6.16.16.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.16.16.2.m1.1b"><times id="S4.T6.16.16.2.m1.1.1.cmml" xref="S4.T6.16.16.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.16.16.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.16.16.2.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.16.16.2.2" style="font-size:90%;">16</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.16.16.4"><span class="ltx_text" id="S4.T6.16.16.4.1" style="font-size:90%;">  256</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.16.16.5"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T6.16.16.5.1" style="font-size:90%;">10.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.16.16.6"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T6.16.16.6.1" style="font-size:90%;">5.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.16.16.7"><span class="ltx_text ltx_framed ltx_framed_underline" id="S4.T6.16.16.7.1" style="font-size:90%;">51.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.16.16.8"><span class="ltx_text" id="S4.T6.16.16.8.1" style="font-size:90%;">25.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T6.16.16.9"><span class="ltx_text" id="S4.T6.16.16.9.1" style="font-size:90%;">16.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T6.16.16.10"><span class="ltx_text" id="S4.T6.16.16.10.1" style="font-size:90%;">25.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.18.18">
<td class="ltx_td ltx_align_center" id="S4.T6.17.17.1">
<span class="ltx_text" id="S4.T6.17.17.1.1" style="font-size:90%;">4</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.17.17.1.m1.1"><semantics id="S4.T6.17.17.1.m1.1a"><mo id="S4.T6.17.17.1.m1.1.1" mathsize="90%" xref="S4.T6.17.17.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.17.17.1.m1.1b"><times id="S4.T6.17.17.1.m1.1.1.cmml" xref="S4.T6.17.17.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.17.17.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.17.17.1.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.17.17.1.2" style="font-size:90%;">4</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T6.18.18.2">
<span class="ltx_text" id="S4.T6.18.18.2.1" style="font-size:90%;">32</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.18.18.2.m1.1"><semantics id="S4.T6.18.18.2.m1.1a"><mo id="S4.T6.18.18.2.m1.1.1" mathsize="90%" xref="S4.T6.18.18.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.18.18.2.m1.1b"><times id="S4.T6.18.18.2.m1.1.1.cmml" xref="S4.T6.18.18.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.18.18.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.18.18.2.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.18.18.2.2" style="font-size:90%;">32</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T6.18.18.3"><span class="ltx_text" id="S4.T6.18.18.3.1" style="font-size:90%;">    64</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.18.18.4"><span class="ltx_text" id="S4.T6.18.18.4.1" style="font-size:90%;">10.7</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.18.18.5"><span class="ltx_text" id="S4.T6.18.18.5.1" style="font-size:90%;">6.2</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.18.18.6"><span class="ltx_text" id="S4.T6.18.18.6.1" style="font-size:90%;">50.7</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.18.18.7"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T6.18.18.7.1" style="font-size:90%;">29.9</span></td>
<td class="ltx_td ltx_align_right" id="S4.T6.18.18.8"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T6.18.18.8.1" style="font-size:90%;">16.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T6.18.18.9"><span class="ltx_text ltx_font_bold ltx_framed ltx_framed_underline" id="S4.T6.18.18.9.1" style="font-size:90%;">25.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T6.20.20">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.19.19.1">
<span class="ltx_text" id="S4.T6.19.19.1.1" style="font-size:90%;">8</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.19.19.1.m1.1"><semantics id="S4.T6.19.19.1.m1.1a"><mo id="S4.T6.19.19.1.m1.1.1" mathsize="90%" xref="S4.T6.19.19.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.19.19.1.m1.1b"><times id="S4.T6.19.19.1.m1.1.1.cmml" xref="S4.T6.19.19.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.19.19.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.19.19.1.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.19.19.1.2" style="font-size:90%;">8</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.20.20.2">
<span class="ltx_text" id="S4.T6.20.20.2.1" style="font-size:90%;">64</span><math alttext="\times" class="ltx_Math" display="inline" id="S4.T6.20.20.2.m1.1"><semantics id="S4.T6.20.20.2.m1.1a"><mo id="S4.T6.20.20.2.m1.1.1" mathsize="90%" xref="S4.T6.20.20.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T6.20.20.2.m1.1b"><times id="S4.T6.20.20.2.m1.1.1.cmml" xref="S4.T6.20.20.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.20.20.2.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T6.20.20.2.m1.1d">×</annotation></semantics></math><span class="ltx_text" id="S4.T6.20.20.2.2" style="font-size:90%;">64</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.20.20.3"><span class="ltx_text" id="S4.T6.20.20.3.1" style="font-size:90%;">    16</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T6.20.20.4"><span class="ltx_text" id="S4.T6.20.20.4.1" style="font-size:90%;">11.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T6.20.20.5"><span class="ltx_text" id="S4.T6.20.20.5.1" style="font-size:90%;">6.6</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T6.20.20.6"><span class="ltx_text" id="S4.T6.20.20.6.1" style="font-size:90%;">49.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T6.20.20.7"><span class="ltx_text" id="S4.T6.20.20.7.1" style="font-size:90%;">29.5</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T6.20.20.8"><span class="ltx_text" id="S4.T6.20.20.8.1" style="font-size:90%;">16.1</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S4.T6.20.20.9"><span class="ltx_text" id="S4.T6.20.20.9.1" style="font-size:90%;">25.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance of 0.76B Transfusion models with different patch sizes. Bolded figures indicate global best, underlines indicate best within architecture.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3 </span>Patch Encoding/Decoding Architecture</h4>
<div class="ltx_para" id="S4.SS3.SSS3.p1">
<p class="ltx_p" id="S4.SS3.SSS3.p1.1">Our experiments so far indicate an advantage to using the U-Net up and down blocks instead of a simple linear layer.
One possible reason is that the model benefits from the inductive biases of the U-Net architecure;
an alternative hypothesis is that this advantage stems from the significant increase in overall model parameters introduced by the U-Net layers.
To decouple these two confounders, we scale up the core transformer to 7B parameters, while keeping the amount of U-Net parameters (almost) constant;<span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>While we do not scale the U-Net layers with the transformer in these experiments, this is a potentially fruitful avenue for future research.</span></span></span>
in this setting, the additional encoder/decoder parameters account for only a 3.8% increase of total model parameters, equivalent to the amount of token embedding parameters.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS3.p2">
<p class="ltx_p" id="S4.SS3.SSS3.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.T7" title="Table 7 ‣ 4.3.3 Patch Encoding/Decoding Architecture ‣ 4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">7</span></a> shows that even though the relative benefit of U-Net layers shrinks as the transformer grows, it does not diminish.
In image generation, for example, the U-Net encoder/decoder allows much smaller models to obtain better FID scores than the 7B model with linear patchification layers.
We observe a similar trend in image captioning, where adding U-Net layers boosts the CIDEr score of a 1.4B transformer (1.67B combined) beyond the performance of the linear 7B model.
Overall, it appears that there are indeed inductive bias benefits to U-Net encoding and decoding of images beyond the mere addition of parameters.</p>
</div>
<figure class="ltx_table" id="S4.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T7.7">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T7.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T7.1.1.2"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.2.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T7.1.1.3" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.3.1" style="font-size:90%;">Enc/Dec</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T7.1.1.1">
<math alttext="\Delta" class="ltx_Math" display="inline" id="S4.T7.1.1.1.m1.1"><semantics id="S4.T7.1.1.1.m1.1a"><mi id="S4.T7.1.1.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T7.1.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="S4.T7.1.1.1.m1.1b"><ci id="S4.T7.1.1.1.m1.1.1.cmml" xref="S4.T7.1.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.1.1.1.m1.1c">\Delta</annotation><annotation encoding="application/x-llamapun" id="S4.T7.1.1.1.m1.1d">roman_Δ</annotation></semantics></math><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.1.1" style="font-size:90%;"> Enc/Dec</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T7.1.1.4"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.4.1" style="font-size:90%;">C4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T7.1.1.5"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.5.1" style="font-size:90%;">Wiki</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T7.1.1.6"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.6.1" style="font-size:90%;">Llama</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T7.1.1.7"><span class="ltx_text ltx_font_bold" id="S4.T7.1.1.7.1" style="font-size:90%;">MS-COCO</span></th>
</tr>
<tr class="ltx_tr" id="S4.T7.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T7.7.7.7"><span class="ltx_text ltx_font_bold" id="S4.T7.7.7.7.1" style="font-size:90%;">Params</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="S4.T7.7.7.8"><span class="ltx_text ltx_font_bold" id="S4.T7.7.7.8.1" style="font-size:90%;">Params</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T7.2.2.1">
<span class="ltx_text ltx_font_bold" id="S4.T7.2.2.1.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T7.2.2.1.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T7.2.2.1.m1.1"><semantics id="S4.T7.2.2.1.m1.1a"><mo id="S4.T7.2.2.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T7.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.2.2.1.m1.1b"><ci id="S4.T7.2.2.1.m1.1.1.cmml" xref="S4.T7.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.2.2.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.2.2.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T7.2.2.1.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T7.3.3.2">
<span class="ltx_text ltx_font_bold" id="S4.T7.3.3.2.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T7.3.3.2.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T7.3.3.2.m1.1"><semantics id="S4.T7.3.3.2.m1.1a"><mo id="S4.T7.3.3.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T7.3.3.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.3.3.2.m1.1b"><ci id="S4.T7.3.3.2.m1.1.1.cmml" xref="S4.T7.3.3.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.3.3.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.3.3.2.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T7.3.3.2.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T7.4.4.3">
<span class="ltx_text ltx_font_bold" id="S4.T7.4.4.3.1" style="font-size:90%;">Acc</span><span class="ltx_text" id="S4.T7.4.4.3.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.4.4.3.m1.1"><semantics id="S4.T7.4.4.3.m1.1a"><mo id="S4.T7.4.4.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T7.4.4.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.4.4.3.m1.1b"><ci id="S4.T7.4.4.3.m1.1.1.cmml" xref="S4.T7.4.4.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.4.4.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.4.4.3.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T7.4.4.3.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T7.5.5.4">
<span class="ltx_text ltx_font_bold" id="S4.T7.5.5.4.1" style="font-size:90%;">CDr</span><span class="ltx_text" id="S4.T7.5.5.4.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.5.5.4.m1.1"><semantics id="S4.T7.5.5.4.m1.1a"><mo id="S4.T7.5.5.4.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T7.5.5.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.5.5.4.m1.1b"><ci id="S4.T7.5.5.4.m1.1.1.cmml" xref="S4.T7.5.5.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.5.5.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.5.5.4.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T7.5.5.4.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T7.6.6.5">
<span class="ltx_text ltx_font_bold" id="S4.T7.6.6.5.1" style="font-size:90%;">FID</span><span class="ltx_text" id="S4.T7.6.6.5.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T7.6.6.5.m1.1"><semantics id="S4.T7.6.6.5.m1.1a"><mo id="S4.T7.6.6.5.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T7.6.6.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T7.6.6.5.m1.1b"><ci id="S4.T7.6.6.5.m1.1.1.cmml" xref="S4.T7.6.6.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.6.6.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.6.6.5.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T7.6.6.5.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column" id="S4.T7.7.7.6">
<span class="ltx_text ltx_font_bold" id="S4.T7.7.7.6.1" style="font-size:90%;">CLIP</span><span class="ltx_text" id="S4.T7.7.7.6.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T7.7.7.6.m1.1"><semantics id="S4.T7.7.7.6.m1.1a"><mo id="S4.T7.7.7.6.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T7.7.7.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T7.7.7.6.m1.1b"><ci id="S4.T7.7.7.6.m1.1.1.cmml" xref="S4.T7.7.7.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.7.7.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T7.7.7.6.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T7.7.7.6.3" style="font-size:90%;">)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.7.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.8.1.1" rowspan="2"><span class="ltx_text" id="S4.T7.7.8.1.1.1" style="font-size:90%;">0.16B</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.8.1.2"><span class="ltx_text" id="S4.T7.7.8.1.2.1" style="font-size:90%;">Linear</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.8.1.3"><span class="ltx_text" id="S4.T7.7.8.1.3.1" style="font-size:90%;">    0.5%</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.8.1.4"><span class="ltx_text" id="S4.T7.7.8.1.4.1" style="font-size:90%;">14.8</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.8.1.5"><span class="ltx_text" id="S4.T7.7.8.1.5.1" style="font-size:90%;">8.8</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.8.1.6"><span class="ltx_text" id="S4.T7.7.8.1.6.1" style="font-size:90%;">44.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.8.1.7"><span class="ltx_text" id="S4.T7.7.8.1.7.1" style="font-size:90%;">6.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.8.1.8"><span class="ltx_text" id="S4.T7.7.8.1.8.1" style="font-size:90%;">37.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T7.7.8.1.9"><span class="ltx_text" id="S4.T7.7.8.1.9.1" style="font-size:90%;">20.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.9.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.7.9.2.1"><span class="ltx_text" id="S4.T7.7.9.2.1.1" style="font-size:90%;">U-Net</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T7.7.9.2.2"><span class="ltx_text" id="S4.T7.7.9.2.2.1" style="font-size:90%;">106.1%</span></th>
<td class="ltx_td ltx_align_right" id="S4.T7.7.9.2.3"><span class="ltx_text" id="S4.T7.7.9.2.3.1" style="font-size:90%;">14.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.9.2.4"><span class="ltx_text" id="S4.T7.7.9.2.4.1" style="font-size:90%;">8.5</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.9.2.5"><span class="ltx_text" id="S4.T7.7.9.2.5.1" style="font-size:90%;">45.7</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.9.2.6"><span class="ltx_text" id="S4.T7.7.9.2.6.1" style="font-size:90%;">15.3</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.9.2.7"><span class="ltx_text" id="S4.T7.7.9.2.7.1" style="font-size:90%;">18.8</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T7.7.9.2.8"><span class="ltx_text" id="S4.T7.7.9.2.8.1" style="font-size:90%;">23.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.10.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.10.3.1" rowspan="2"><span class="ltx_text" id="S4.T7.7.10.3.1.1" style="font-size:90%;">0.37B</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.10.3.2"><span class="ltx_text" id="S4.T7.7.10.3.2.1" style="font-size:90%;">Linear</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.10.3.3"><span class="ltx_text" id="S4.T7.7.10.3.3.1" style="font-size:90%;">    0.4%</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.10.3.4"><span class="ltx_text" id="S4.T7.7.10.3.4.1" style="font-size:90%;">12.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.10.3.5"><span class="ltx_text" id="S4.T7.7.10.3.5.1" style="font-size:90%;">7.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.10.3.6"><span class="ltx_text" id="S4.T7.7.10.3.6.1" style="font-size:90%;">47.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.10.3.7"><span class="ltx_text" id="S4.T7.7.10.3.7.1" style="font-size:90%;">11.1</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.10.3.8"><span class="ltx_text" id="S4.T7.7.10.3.8.1" style="font-size:90%;">21.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T7.7.10.3.9"><span class="ltx_text" id="S4.T7.7.10.3.9.1" style="font-size:90%;">22.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.11.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.7.11.4.1"><span class="ltx_text" id="S4.T7.7.11.4.1.1" style="font-size:90%;">U-Net</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T7.7.11.4.2"><span class="ltx_text" id="S4.T7.7.11.4.2.1" style="font-size:90%;">  71.3%</span></th>
<td class="ltx_td ltx_align_right" id="S4.T7.7.11.4.3"><span class="ltx_text" id="S4.T7.7.11.4.3.1" style="font-size:90%;">11.8</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.11.4.4"><span class="ltx_text" id="S4.T7.7.11.4.4.1" style="font-size:90%;">6.9</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.11.4.5"><span class="ltx_text" id="S4.T7.7.11.4.5.1" style="font-size:90%;">48.8</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.11.4.6"><span class="ltx_text" id="S4.T7.7.11.4.6.1" style="font-size:90%;">21.1</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.11.4.7"><span class="ltx_text" id="S4.T7.7.11.4.7.1" style="font-size:90%;">18.1</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T7.7.11.4.8"><span class="ltx_text" id="S4.T7.7.11.4.8.1" style="font-size:90%;">24.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.12.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.12.5.1" rowspan="2"><span class="ltx_text" id="S4.T7.7.12.5.1.1" style="font-size:90%;">0.76B</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.12.5.2"><span class="ltx_text" id="S4.T7.7.12.5.2.1" style="font-size:90%;">Linear</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.12.5.3"><span class="ltx_text" id="S4.T7.7.12.5.3.1" style="font-size:90%;">    0.4%</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.12.5.4"><span class="ltx_text" id="S4.T7.7.12.5.4.1" style="font-size:90%;">10.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.12.5.5"><span class="ltx_text" id="S4.T7.7.12.5.5.1" style="font-size:90%;">6.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.12.5.6"><span class="ltx_text" id="S4.T7.7.12.5.6.1" style="font-size:90%;">51.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.12.5.7"><span class="ltx_text" id="S4.T7.7.12.5.7.1" style="font-size:90%;">16.0</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.12.5.8"><span class="ltx_text" id="S4.T7.7.12.5.8.1" style="font-size:90%;">20.3</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T7.7.12.5.9"><span class="ltx_text" id="S4.T7.7.12.5.9.1" style="font-size:90%;">24.0</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.13.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.7.13.6.1"><span class="ltx_text" id="S4.T7.7.13.6.1.1" style="font-size:90%;">U-Net</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T7.7.13.6.2"><span class="ltx_text" id="S4.T7.7.13.6.2.1" style="font-size:90%;">  35.5%</span></th>
<td class="ltx_td ltx_align_right" id="S4.T7.7.13.6.3"><span class="ltx_text" id="S4.T7.7.13.6.3.1" style="font-size:90%;">10.3</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.13.6.4"><span class="ltx_text" id="S4.T7.7.13.6.4.1" style="font-size:90%;">5.9</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.13.6.5"><span class="ltx_text" id="S4.T7.7.13.6.5.1" style="font-size:90%;">51.9</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.13.6.6"><span class="ltx_text" id="S4.T7.7.13.6.6.1" style="font-size:90%;">25.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.13.6.7"><span class="ltx_text" id="S4.T7.7.13.6.7.1" style="font-size:90%;">16.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T7.7.13.6.8"><span class="ltx_text" id="S4.T7.7.13.6.8.1" style="font-size:90%;">25.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.14.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.14.7.1" rowspan="2"><span class="ltx_text" id="S4.T7.7.14.7.1.1" style="font-size:90%;">1.4B</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.14.7.2"><span class="ltx_text" id="S4.T7.7.14.7.2.1" style="font-size:90%;">Linear</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.14.7.3"><span class="ltx_text" id="S4.T7.7.14.7.3.1" style="font-size:90%;">    0.4%</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.14.7.4"><span class="ltx_text" id="S4.T7.7.14.7.4.1" style="font-size:90%;">9.5</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.14.7.5"><span class="ltx_text" id="S4.T7.7.14.7.5.1" style="font-size:90%;">5.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.14.7.6"><span class="ltx_text" id="S4.T7.7.14.7.6.1" style="font-size:90%;">53.8</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.14.7.7"><span class="ltx_text" id="S4.T7.7.14.7.7.1" style="font-size:90%;">19.1</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.14.7.8"><span class="ltx_text" id="S4.T7.7.14.7.8.1" style="font-size:90%;">19.4</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T7.7.14.7.9"><span class="ltx_text" id="S4.T7.7.14.7.9.1" style="font-size:90%;">24.3</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.15.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T7.7.15.8.1"><span class="ltx_text" id="S4.T7.7.15.8.1.1" style="font-size:90%;">U-Net</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T7.7.15.8.2"><span class="ltx_text" id="S4.T7.7.15.8.2.1" style="font-size:90%;">  19.3%</span></th>
<td class="ltx_td ltx_align_right" id="S4.T7.7.15.8.3"><span class="ltx_text" id="S4.T7.7.15.8.3.1" style="font-size:90%;">9.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.15.8.4"><span class="ltx_text" id="S4.T7.7.15.8.4.1" style="font-size:90%;">5.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.15.8.5"><span class="ltx_text" id="S4.T7.7.15.8.5.1" style="font-size:90%;">53.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.15.8.6"><span class="ltx_text" id="S4.T7.7.15.8.6.1" style="font-size:90%;">28.1</span></td>
<td class="ltx_td ltx_align_right" id="S4.T7.7.15.8.7"><span class="ltx_text" id="S4.T7.7.15.8.7.1" style="font-size:90%;">16.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T7.7.15.8.8"><span class="ltx_text" id="S4.T7.7.15.8.8.1" style="font-size:90%;">25.7</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.16.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T7.7.16.9.1" rowspan="2"><span class="ltx_text" id="S4.T7.7.16.9.1.1" style="font-size:90%;">7B</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.16.9.2"><span class="ltx_text" id="S4.T7.7.16.9.2.1" style="font-size:90%;">Linear</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t" id="S4.T7.7.16.9.3"><span class="ltx_text" id="S4.T7.7.16.9.3.1" style="font-size:90%;">    0.3%</span></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.16.9.4"><span class="ltx_text" id="S4.T7.7.16.9.4.1" style="font-size:90%;">7.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.16.9.5"><span class="ltx_text" id="S4.T7.7.16.9.5.1" style="font-size:90%;">4.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.16.9.6"><span class="ltx_text" id="S4.T7.7.16.9.6.1" style="font-size:90%;">61.5</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.16.9.7"><span class="ltx_text" id="S4.T7.7.16.9.7.1" style="font-size:90%;">27.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T7.7.16.9.8"><span class="ltx_text" id="S4.T7.7.16.9.8.1" style="font-size:90%;">18.6</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T7.7.16.9.9"><span class="ltx_text" id="S4.T7.7.16.9.9.1" style="font-size:90%;">25.9</span></td>
</tr>
<tr class="ltx_tr" id="S4.T7.7.17.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T7.7.17.10.1"><span class="ltx_text" id="S4.T7.7.17.10.1.1" style="font-size:90%;">U-Net</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T7.7.17.10.2"><span class="ltx_text" id="S4.T7.7.17.10.2.1" style="font-size:90%;">    3.8%</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.7.17.10.3"><span class="ltx_text" id="S4.T7.7.17.10.3.1" style="font-size:90%;">7.8</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.7.17.10.4"><span class="ltx_text" id="S4.T7.7.17.10.4.1" style="font-size:90%;">4.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.7.17.10.5"><span class="ltx_text" id="S4.T7.7.17.10.5.1" style="font-size:90%;">61.1</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.7.17.10.6"><span class="ltx_text" id="S4.T7.7.17.10.6.1" style="font-size:90%;">33.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T7.7.17.10.7"><span class="ltx_text" id="S4.T7.7.17.10.7.1" style="font-size:90%;">16.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S4.T7.7.17.10.8"><span class="ltx_text" id="S4.T7.7.17.10.8.1" style="font-size:90%;">26.5</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 7: </span>Performance of linear and U-Net variants of Transfusion across different model sizes. Patch size is set at 2<math alttext="\times" class="ltx_Math" display="inline" id="S4.T7.9.m1.1"><semantics id="S4.T7.9.m1.1b"><mo id="S4.T7.9.m1.1.1" xref="S4.T7.9.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T7.9.m1.1c"><times id="S4.T7.9.m1.1.1.cmml" xref="S4.T7.9.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T7.9.m1.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T7.9.m1.1e">×</annotation></semantics></math>2 latent pixels. Model parameters refers to the transformer alone.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4 </span>Image Noising</h4>
<div class="ltx_para" id="S4.SS3.SSS4.p1">
<p class="ltx_p" id="S4.SS3.SSS4.p1.1">Our experiments order 80% of image-caption pairs with the caption first, and the image conditioning on the caption, following the intuition that image generation may be a more data-hungry task than image understanding.
The remaining 20% of the pairs condition the caption on the image.
However, these images are noised as part of the diffusion objective.
We thus measure the effect of limiting the diffusion noise to a maximum of <math alttext="t=500" class="ltx_Math" display="inline" id="S4.SS3.SSS4.p1.1.m1.1"><semantics id="S4.SS3.SSS4.p1.1.m1.1a"><mrow id="S4.SS3.SSS4.p1.1.m1.1.1" xref="S4.SS3.SSS4.p1.1.m1.1.1.cmml"><mi id="S4.SS3.SSS4.p1.1.m1.1.1.2" xref="S4.SS3.SSS4.p1.1.m1.1.1.2.cmml">t</mi><mo id="S4.SS3.SSS4.p1.1.m1.1.1.1" xref="S4.SS3.SSS4.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS3.SSS4.p1.1.m1.1.1.3" xref="S4.SS3.SSS4.p1.1.m1.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS4.p1.1.m1.1b"><apply id="S4.SS3.SSS4.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS4.p1.1.m1.1.1"><eq id="S4.SS3.SSS4.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS4.p1.1.m1.1.1.1"></eq><ci id="S4.SS3.SSS4.p1.1.m1.1.1.2.cmml" xref="S4.SS3.SSS4.p1.1.m1.1.1.2">𝑡</ci><cn id="S4.SS3.SSS4.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.SSS4.p1.1.m1.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS4.p1.1.m1.1c">t=500</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS4.p1.1.m1.1d">italic_t = 500</annotation></semantics></math> (half of the noise schedule) in the 20% of cases where images appear before their captions.
Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.T8" title="Table 8 ‣ 4.3.4 Image Noising ‣ 4.3 Architecture Ablations ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">8</span></a> shows that noise limiting significantly improves image captioning, as measure by CIDEr, while having a relatively small effect (less than 1%) on other benchmarks.</p>
</div>
<figure class="ltx_table" id="S4.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T8.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T8.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T8.8.9.1.1"><span class="ltx_text ltx_font_bold" id="S4.T8.8.9.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T8.8.9.1.2"><span class="ltx_text ltx_font_bold" id="S4.T8.8.9.1.2.1" style="font-size:90%;">Noise</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.8.9.1.3"><span class="ltx_text ltx_font_bold" id="S4.T8.8.9.1.3.1" style="font-size:90%;">C4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.8.9.1.4"><span class="ltx_text ltx_font_bold" id="S4.T8.8.9.1.4.1" style="font-size:90%;">Wiki</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T8.8.9.1.5"><span class="ltx_text ltx_font_bold" id="S4.T8.8.9.1.5.1" style="font-size:90%;">Llama</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T8.8.9.1.6"><span class="ltx_text ltx_font_bold" id="S4.T8.8.9.1.6.1" style="font-size:90%;">MS-COCO</span></th>
</tr>
<tr class="ltx_tr" id="S4.T8.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T8.6.6.7"><span class="ltx_text ltx_font_bold" id="S4.T8.6.6.7.1" style="font-size:90%;">Params</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row" id="S4.T8.6.6.8"><span class="ltx_text ltx_font_bold" id="S4.T8.6.6.8.1" style="font-size:90%;">Limit</span></th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T8.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T8.1.1.1.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T8.1.1.1.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T8.1.1.1.m1.1"><semantics id="S4.T8.1.1.1.m1.1a"><mo id="S4.T8.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T8.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.1.1.1.m1.1b"><ci id="S4.T8.1.1.1.m1.1.1.cmml" xref="S4.T8.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.1.1.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T8.1.1.1.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T8.1.1.1.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T8.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T8.2.2.2.1" style="font-size:90%;">PPL</span><span class="ltx_text" id="S4.T8.2.2.2.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T8.2.2.2.m1.1"><semantics id="S4.T8.2.2.2.m1.1a"><mo id="S4.T8.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T8.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.2.2.2.m1.1b"><ci id="S4.T8.2.2.2.m1.1.1.cmml" xref="S4.T8.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T8.2.2.2.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T8.2.2.2.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T8.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T8.3.3.3.1" style="font-size:90%;">Acc</span><span class="ltx_text" id="S4.T8.3.3.3.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T8.3.3.3.m1.1"><semantics id="S4.T8.3.3.3.m1.1a"><mo id="S4.T8.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T8.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.3.3.3.m1.1b"><ci id="S4.T8.3.3.3.m1.1.1.cmml" xref="S4.T8.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T8.3.3.3.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T8.3.3.3.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T8.4.4.4">
<span class="ltx_text ltx_font_bold" id="S4.T8.4.4.4.1" style="font-size:90%;">CDr</span><span class="ltx_text" id="S4.T8.4.4.4.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T8.4.4.4.m1.1"><semantics id="S4.T8.4.4.4.m1.1a"><mo id="S4.T8.4.4.4.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T8.4.4.4.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.4.4.4.m1.1b"><ci id="S4.T8.4.4.4.m1.1.1.cmml" xref="S4.T8.4.4.4.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.4.4.4.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T8.4.4.4.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T8.4.4.4.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column" id="S4.T8.5.5.5">
<span class="ltx_text ltx_font_bold" id="S4.T8.5.5.5.1" style="font-size:90%;">FID</span><span class="ltx_text" id="S4.T8.5.5.5.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T8.5.5.5.m1.1"><semantics id="S4.T8.5.5.5.m1.1a"><mo id="S4.T8.5.5.5.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T8.5.5.5.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T8.5.5.5.m1.1b"><ci id="S4.T8.5.5.5.m1.1.1.cmml" xref="S4.T8.5.5.5.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.5.5.5.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T8.5.5.5.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T8.5.5.5.3" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_nopad_r ltx_align_right ltx_th ltx_th_column" id="S4.T8.6.6.6">
<span class="ltx_text ltx_font_bold" id="S4.T8.6.6.6.1" style="font-size:90%;">CLIP</span><span class="ltx_text" id="S4.T8.6.6.6.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T8.6.6.6.m1.1"><semantics id="S4.T8.6.6.6.m1.1a"><mo id="S4.T8.6.6.6.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T8.6.6.6.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T8.6.6.6.m1.1b"><ci id="S4.T8.6.6.6.m1.1.1.cmml" xref="S4.T8.6.6.6.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.6.6.6.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T8.6.6.6.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T8.6.6.6.3" style="font-size:90%;">)</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T8.8.10.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T8.8.10.1.1" rowspan="2"><span class="ltx_text" id="S4.T8.8.10.1.1.1" style="font-size:90%;">0.76B</span></th>
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T8.8.10.1.2"></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.10.1.3"><span class="ltx_text" id="S4.T8.8.10.1.3.1" style="font-size:90%;">10.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.10.1.4"><span class="ltx_text" id="S4.T8.8.10.1.4.1" style="font-size:90%;">5.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.10.1.5"><span class="ltx_text" id="S4.T8.8.10.1.5.1" style="font-size:90%;">51.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.10.1.6"><span class="ltx_text" id="S4.T8.8.10.1.6.1" style="font-size:90%;">25.4</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.10.1.7"><span class="ltx_text" id="S4.T8.8.10.1.7.1" style="font-size:90%;">16.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T8.8.10.1.8"><span class="ltx_text" id="S4.T8.8.10.1.8.1" style="font-size:90%;">25.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row" id="S4.T8.7.7.1"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T8.7.7.1.m1.1"><semantics id="S4.T8.7.7.1.m1.1a"><mi id="S4.T8.7.7.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T8.7.7.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T8.7.7.1.m1.1b"><ci id="S4.T8.7.7.1.m1.1.1.cmml" xref="S4.T8.7.7.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.7.7.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T8.7.7.1.m1.1d">✓</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right" id="S4.T8.7.7.2"><span class="ltx_text" id="S4.T8.7.7.2.1" style="font-size:90%;">10.3</span></td>
<td class="ltx_td ltx_align_right" id="S4.T8.7.7.3"><span class="ltx_text" id="S4.T8.7.7.3.1" style="font-size:90%;">5.9</span></td>
<td class="ltx_td ltx_align_right" id="S4.T8.7.7.4"><span class="ltx_text" id="S4.T8.7.7.4.1" style="font-size:90%;">52.1</span></td>
<td class="ltx_td ltx_align_right" id="S4.T8.7.7.5"><span class="ltx_text ltx_font_bold" id="S4.T8.7.7.5.1" style="font-size:90%;">29.4</span></td>
<td class="ltx_td ltx_align_right" id="S4.T8.7.7.6"><span class="ltx_text" id="S4.T8.7.7.6.1" style="font-size:90%;">16.5</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right" id="S4.T8.7.7.7"><span class="ltx_text" id="S4.T8.7.7.7.1" style="font-size:90%;">25.4</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.11.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T8.8.11.2.1" rowspan="2"><span class="ltx_text" id="S4.T8.8.11.2.1.1" style="font-size:90%;">7B</span></th>
<th class="ltx_td ltx_th ltx_th_row ltx_border_t" id="S4.T8.8.11.2.2"></th>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.11.2.3"><span class="ltx_text" id="S4.T8.8.11.2.3.1" style="font-size:90%;">7.8</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.11.2.4"><span class="ltx_text" id="S4.T8.8.11.2.4.1" style="font-size:90%;">4.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.11.2.5"><span class="ltx_text" id="S4.T8.8.11.2.5.1" style="font-size:90%;">61.1</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.11.2.6"><span class="ltx_text" id="S4.T8.8.11.2.6.1" style="font-size:90%;">33.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T8.8.11.2.7"><span class="ltx_text" id="S4.T8.8.11.2.7.1" style="font-size:90%;">16.0</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_t" id="S4.T8.8.11.2.8"><span class="ltx_text" id="S4.T8.8.11.2.8.1" style="font-size:90%;">26.5</span></td>
</tr>
<tr class="ltx_tr" id="S4.T8.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb" id="S4.T8.8.8.1"><math alttext="\checkmark" class="ltx_Math" display="inline" id="S4.T8.8.8.1.m1.1"><semantics id="S4.T8.8.8.1.m1.1a"><mi id="S4.T8.8.8.1.m1.1.1" mathsize="90%" mathvariant="normal" xref="S4.T8.8.8.1.m1.1.1.cmml">✓</mi><annotation-xml encoding="MathML-Content" id="S4.T8.8.8.1.m1.1b"><ci id="S4.T8.8.8.1.m1.1.1.cmml" xref="S4.T8.8.8.1.m1.1.1">✓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.8.8.1.m1.1c">\checkmark</annotation><annotation encoding="application/x-llamapun" id="S4.T8.8.8.1.m1.1d">✓</annotation></semantics></math></th>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T8.8.8.2"><span class="ltx_text" id="S4.T8.8.8.2.1" style="font-size:90%;">7.7</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T8.8.8.3"><span class="ltx_text" id="S4.T8.8.8.3.1" style="font-size:90%;">4.3</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T8.8.8.4"><span class="ltx_text" id="S4.T8.8.8.4.1" style="font-size:90%;">60.9</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T8.8.8.5"><span class="ltx_text ltx_font_bold" id="S4.T8.8.8.5.1" style="font-size:90%;">35.2</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T8.8.8.6"><span class="ltx_text" id="S4.T8.8.8.6.1" style="font-size:90%;">15.7</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_right ltx_border_bb" id="S4.T8.8.8.7"><span class="ltx_text" id="S4.T8.8.8.7.1" style="font-size:90%;">26.3</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 8: </span>Performance of Transfusion with and without limiting the amount of sampled diffusion noise to a maximum of <math alttext="t=500" class="ltx_Math" display="inline" id="S4.T8.11.m1.1"><semantics id="S4.T8.11.m1.1b"><mrow id="S4.T8.11.m1.1.1" xref="S4.T8.11.m1.1.1.cmml"><mi id="S4.T8.11.m1.1.1.2" xref="S4.T8.11.m1.1.1.2.cmml">t</mi><mo id="S4.T8.11.m1.1.1.1" xref="S4.T8.11.m1.1.1.1.cmml">=</mo><mn id="S4.T8.11.m1.1.1.3" xref="S4.T8.11.m1.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T8.11.m1.1c"><apply id="S4.T8.11.m1.1.1.cmml" xref="S4.T8.11.m1.1.1"><eq id="S4.T8.11.m1.1.1.1.cmml" xref="S4.T8.11.m1.1.1.1"></eq><ci id="S4.T8.11.m1.1.1.2.cmml" xref="S4.T8.11.m1.1.1.2">𝑡</ci><cn id="S4.T8.11.m1.1.1.3.cmml" type="integer" xref="S4.T8.11.m1.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.11.m1.1d">t=500</annotation><annotation encoding="application/x-llamapun" id="S4.T8.11.m1.1e">italic_t = 500</annotation></semantics></math> when images appear before the caption.
The models are U-Net variants encoding 2<math alttext="\times" class="ltx_Math" display="inline" id="S4.T8.12.m2.1"><semantics id="S4.T8.12.m2.1b"><mo id="S4.T8.12.m2.1.1" xref="S4.T8.12.m2.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T8.12.m2.1c"><times id="S4.T8.12.m2.1.1.cmml" xref="S4.T8.12.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T8.12.m2.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T8.12.m2.1e">×</annotation></semantics></math>2 latent pixel patches.
Metrics that change by over 1% are bolded.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Comparison with Image Generation Literature</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">Our experiments thus far have covered controlled comparisons with Chameleon and Llama, but we have yet to compare Transfusion’s image generation capabilities to those of state-of-the-art image generation models.
To that end, we train a 7B parameter model with U-Net encoding/decoding layers (2<math alttext="\times" class="ltx_Math" display="inline" id="S4.SS4.p1.1.m1.1"><semantics id="S4.SS4.p1.1.m1.1a"><mo id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><times id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">\times</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p1.1.m1.1d">×</annotation></semantics></math>2 latent pixel patches) over the equivalent of 2T tokens, comprising of 1T text corpus tokens and 3.5B images and their captions.
While the Transfusion variant in §<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS2" title="4.2 Controlled Comparison with Chameleon ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.2</span></a> favored simplicity and experimental control, the design choices and data mixture (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1" title="4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.1</span></a>) of this variant lean a bit more towards image generation.
Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S1.F2" title="Figure 2 ‣ 1 Introduction ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">2</span></a> and Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#A2" title="Appendix B Examples: Image Generation ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">B</span></a> showcase generated images from this model.</p>
</div>
<div class="ltx_para" id="S4.SS4.p2">
<p class="ltx_p" id="S4.SS4.p2.1">We compare the performance of our model to reported results of other similar scale image generation models, as well as some publicly available text generating models for reference.
Table <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.T9" title="Table 9 ‣ 4.4 Comparison with Image Generation Literature ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">9</span></a> shows that Transfusion achieves similar performance to high-performing image generation models such as DeepFloyd <cite class="ltx_cite ltx_citemacro_citep">(Stability AI, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib44" title="">2024</a>)</cite>, while surpassing previously published models including SDXL <cite class="ltx_cite ltx_citemacro_citep">(Podell et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib32" title="">2023</a>)</cite>.
While Transfusion does lag behind SD 3 <cite class="ltx_cite ltx_citemacro_citep">(Esser et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib16" title="">2024a</a>)</cite>, this model leveraged synthetic image captions through backtranslation <cite class="ltx_cite ltx_citemacro_citep">(Betker et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib4" title="">2023</a>)</cite>, which enhances its GenEval performance by 6.5% absolute (0.433<math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.SS4.p2.1.m1.1"><semantics id="S4.SS4.p2.1.m1.1a"><mo id="S4.SS4.p2.1.m1.1.1" stretchy="false" xref="S4.SS4.p2.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><ci id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.SS4.p2.1.m1.1d">→</annotation></semantics></math>0.498) at smaller scale; for simplicity, our experimental setup only included natural data.
Finally, we note that our Transfusion model can also generate text, and performs on par with the Llama models, which were trained on the same text data distribution (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS1" title="4.1 Setup ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.1</span></a>).</p>
</div>
<figure class="ltx_table" id="S4.T9">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T9.12">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T9.12.13.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_tt" id="S4.T9.12.13.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T9.12.13.1.1.1" style="font-size:90%;">Model</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T9.12.13.1.2"><span class="ltx_text ltx_font_bold" id="S4.T9.12.13.1.2.1" style="font-size:90%;">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T9.12.13.1.3"><span class="ltx_text ltx_font_bold" id="S4.T9.12.13.1.3.1" style="font-size:90%;">Text</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T9.12.13.1.4" rowspan="2"><span class="ltx_text ltx_font_bold" id="S4.T9.12.13.1.4.1" style="font-size:90%;">Images</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T9.12.13.1.5"><span class="ltx_text ltx_font_bold" id="S4.T9.12.13.1.5.1" style="font-size:90%;">Llama</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T9.12.13.1.6"><span class="ltx_text ltx_font_bold" id="S4.T9.12.13.1.6.1" style="font-size:90%;">COCO</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T9.12.13.1.7"><span class="ltx_text ltx_font_bold" id="S4.T9.12.13.1.7.1" style="font-size:90%;">Gen</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.3.3">
<td class="ltx_td ltx_align_center" id="S4.T9.3.3.4"><span class="ltx_text ltx_font_bold" id="S4.T9.3.3.4.1" style="font-size:90%;">Params</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.3.3.5"><span class="ltx_text ltx_font_bold" id="S4.T9.3.3.5.1" style="font-size:90%;">Tokens</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.1.1.1">
<span class="ltx_text ltx_font_bold" id="S4.T9.1.1.1.1" style="font-size:90%;">Acc</span><span class="ltx_text" id="S4.T9.1.1.1.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T9.1.1.1.m1.1"><semantics id="S4.T9.1.1.1.m1.1a"><mo id="S4.T9.1.1.1.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T9.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T9.1.1.1.m1.1b"><ci id="S4.T9.1.1.1.m1.1.1.cmml" xref="S4.T9.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T9.1.1.1.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T9.1.1.1.3" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.2.2.2">
<span class="ltx_text ltx_font_bold" id="S4.T9.2.2.2.1" style="font-size:90%;">FID</span><span class="ltx_text" id="S4.T9.2.2.2.2" style="font-size:90%;"> (</span><math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T9.2.2.2.m1.1"><semantics id="S4.T9.2.2.2.m1.1a"><mo id="S4.T9.2.2.2.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T9.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T9.2.2.2.m1.1b"><ci id="S4.T9.2.2.2.m1.1.1.cmml" xref="S4.T9.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T9.2.2.2.m1.1d">↓</annotation></semantics></math><span class="ltx_text" id="S4.T9.2.2.2.3" style="font-size:90%;">)</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.3.3.3">
<span class="ltx_text ltx_font_bold" id="S4.T9.3.3.3.1" style="font-size:90%;">Eval</span><span class="ltx_text" id="S4.T9.3.3.3.2" style="font-size:90%;"> (</span><math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T9.3.3.3.m1.1"><semantics id="S4.T9.3.3.3.m1.1a"><mo id="S4.T9.3.3.3.m1.1.1" mathsize="90%" stretchy="false" xref="S4.T9.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T9.3.3.3.m1.1b"><ci id="S4.T9.3.3.3.m1.1.1.cmml" xref="S4.T9.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T9.3.3.3.m1.1d">↑</annotation></semantics></math><span class="ltx_text" id="S4.T9.3.3.3.3" style="font-size:90%;">)</span>
</td>
</tr>
<tr class="ltx_tr" id="S4.T9.12.14.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T9.12.14.2.1">
<span class="ltx_text" id="S4.T9.12.14.2.1.1" style="font-size:90%;">Llama 1 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.12.14.2.1.2.1" style="font-size:90%;">(</span>Touvron et al.<span class="ltx_text" id="S4.T9.12.14.2.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib46" title="">2023a</a><span class="ltx_text" id="S4.T9.12.14.2.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.12.14.2.2"><span class="ltx_text" id="S4.T9.12.14.2.2.1" style="font-size:90%;">7B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.12.14.2.3"><span class="ltx_text" id="S4.T9.12.14.2.3.1" style="font-size:90%;">1.4T</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.12.14.2.4"><span class="ltx_text" id="S4.T9.12.14.2.4.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.12.14.2.5"><span class="ltx_text" id="S4.T9.12.14.2.5.1" style="font-size:90%;">66.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.12.14.2.6"><span class="ltx_text" id="S4.T9.12.14.2.6.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T9.12.14.2.7"><span class="ltx_text" id="S4.T9.12.14.2.7.1" style="font-size:90%;">—</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.12.15.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.12.15.3.1">
<span class="ltx_text" id="S4.T9.12.15.3.1.1" style="font-size:90%;">Llama 2 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.12.15.3.1.2.1" style="font-size:90%;">(</span>Touvron et al.<span class="ltx_text" id="S4.T9.12.15.3.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib47" title="">2023b</a><span class="ltx_text" id="S4.T9.12.15.3.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T9.12.15.3.2"><span class="ltx_text" id="S4.T9.12.15.3.2.1" style="font-size:90%;">7B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.15.3.3"><span class="ltx_text" id="S4.T9.12.15.3.3.1" style="font-size:90%;">2.0T</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.15.3.4"><span class="ltx_text" id="S4.T9.12.15.3.4.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.15.3.5"><span class="ltx_text" id="S4.T9.12.15.3.5.1" style="font-size:90%;">66.3</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.15.3.6"><span class="ltx_text" id="S4.T9.12.15.3.6.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.12.15.3.7"><span class="ltx_text" id="S4.T9.12.15.3.7.1" style="font-size:90%;">—</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.12.16.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.12.16.4.1">
<span class="ltx_text" id="S4.T9.12.16.4.1.1" style="font-size:90%;">Chameleon </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.12.16.4.1.2.1" style="font-size:90%;">(</span>Chameleon Team<span class="ltx_text" id="S4.T9.12.16.4.1.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib6" title="">2024</a><span class="ltx_text" id="S4.T9.12.16.4.1.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T9.12.16.4.2"><span class="ltx_text" id="S4.T9.12.16.4.2.1" style="font-size:90%;">7B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.16.4.3"><span class="ltx_text" id="S4.T9.12.16.4.3.1" style="font-size:90%;">6.0T</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.16.4.4"><span class="ltx_text" id="S4.T9.12.16.4.4.1" style="font-size:90%;">3.5B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.16.4.5"><span class="ltx_text" id="S4.T9.12.16.4.5.1" style="font-size:90%;">67.1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.16.4.6"><span class="ltx_text" id="S4.T9.12.16.4.6.1" style="font-size:90%;">26.74</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.12.16.4.7"><span class="ltx_text" id="S4.T9.12.16.4.7.1" style="font-size:90%;">0.39</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T9.4.4.2">
<span class="ltx_text" id="S4.T9.4.4.2.1" style="font-size:90%;">Imagen </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.4.4.2.2.1" style="font-size:90%;">(</span>Saharia et al.<span class="ltx_text" id="S4.T9.4.4.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib39" title="">2022</a><span class="ltx_text" id="S4.T9.4.4.2.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.1">
<span class="ltx_text" id="S4.T9.4.4.1.1" style="font-size:90%;">2.6B + 4.7B</span><sup class="ltx_sup" id="S4.T9.4.4.1.2"><span class="ltx_text ltx_font_italic" id="S4.T9.4.4.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.3"><span class="ltx_text" id="S4.T9.4.4.3.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.4"><span class="ltx_text" id="S4.T9.4.4.4.1" style="font-size:90%;">5.0B</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.5"><span class="ltx_text" id="S4.T9.4.4.5.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T9.4.4.6"><span class="ltx_text" id="S4.T9.4.4.6.1" style="font-size:90%;">7.27</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T9.4.4.7"><span class="ltx_text" id="S4.T9.4.4.7.1" style="font-size:90%;">—</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.5.5.2">
<span class="ltx_text" id="S4.T9.5.5.2.1" style="font-size:90%;">Parti </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.5.5.2.2.1" style="font-size:90%;">(</span>Yu et al.<span class="ltx_text" id="S4.T9.5.5.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib50" title="">2022</a><span class="ltx_text" id="S4.T9.5.5.2.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T9.5.5.3"><span class="ltx_text" id="S4.T9.5.5.3.1" style="font-size:90%;">20B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.5.5.4"><span class="ltx_text" id="S4.T9.5.5.4.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.5.5.5"><span class="ltx_text" id="S4.T9.5.5.5.1" style="font-size:90%;">4.8B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.5.5.6"><span class="ltx_text" id="S4.T9.5.5.6.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.5.5.1">
<sup class="ltx_sup" id="S4.T9.5.5.1.1"><span class="ltx_text ltx_font_italic" id="S4.T9.5.5.1.1.1" style="font-size:90%;">r</span></sup><span class="ltx_text" id="S4.T9.5.5.1.2" style="font-size:90%;">7.23</span>
</td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.5.5.7"><span class="ltx_text" id="S4.T9.5.5.7.1" style="font-size:90%;">—</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.6.6.2">
<span class="ltx_text" id="S4.T9.6.6.2.1" style="font-size:90%;">SD 1.5 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.6.6.2.2.1" style="font-size:90%;">(</span>Rombach et al.<span class="ltx_text" id="S4.T9.6.6.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib38" title="">2022b</a><span class="ltx_text" id="S4.T9.6.6.2.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T9.6.6.1">
<span class="ltx_text" id="S4.T9.6.6.1.1" style="font-size:90%;">0.9B + 0.1B</span><sup class="ltx_sup" id="S4.T9.6.6.1.2"><span class="ltx_text ltx_font_italic" id="S4.T9.6.6.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.6.6.3"><span class="ltx_text" id="S4.T9.6.6.3.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.6.6.4"><span class="ltx_text" id="S4.T9.6.6.4.1" style="font-size:90%;">4.0B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.6.6.5"><span class="ltx_text" id="S4.T9.6.6.5.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.6.6.6"><span class="ltx_text" id="S4.T9.6.6.6.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.6.6.7"><span class="ltx_text" id="S4.T9.6.6.7.1" style="font-size:90%;">0.43</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.7.7.2">
<span class="ltx_text" id="S4.T9.7.7.2.1" style="font-size:90%;">SD 2.1 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.7.7.2.2.1" style="font-size:90%;">(</span>Rombach et al.<span class="ltx_text" id="S4.T9.7.7.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib38" title="">2022b</a><span class="ltx_text" id="S4.T9.7.7.2.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T9.7.7.1">
<span class="ltx_text" id="S4.T9.7.7.1.1" style="font-size:90%;">0.9B + 0.1B</span><sup class="ltx_sup" id="S4.T9.7.7.1.2"><span class="ltx_text ltx_font_italic" id="S4.T9.7.7.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.7.7.3"><span class="ltx_text" id="S4.T9.7.7.3.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.7.7.4"><span class="ltx_text" id="S4.T9.7.7.4.1" style="font-size:90%;">2.3B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.7.7.5"><span class="ltx_text" id="S4.T9.7.7.5.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.7.7.6"><span class="ltx_text" id="S4.T9.7.7.6.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.7.7.7"><span class="ltx_text" id="S4.T9.7.7.7.1" style="font-size:90%;">0.50</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.8.8.2">
<span class="ltx_text" id="S4.T9.8.8.2.1" style="font-size:90%;">DALL-E 2 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.8.8.2.2.1" style="font-size:90%;">(</span>Ramesh et al.<span class="ltx_text" id="S4.T9.8.8.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib36" title="">2022</a><span class="ltx_text" id="S4.T9.8.8.2.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T9.8.8.1">
<span class="ltx_text" id="S4.T9.8.8.1.1" style="font-size:90%;">4.2B + 1B</span><sup class="ltx_sup" id="S4.T9.8.8.1.2"><span class="ltx_text ltx_font_italic" id="S4.T9.8.8.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.8.3"><span class="ltx_text" id="S4.T9.8.8.3.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.8.4"><span class="ltx_text" id="S4.T9.8.8.4.1" style="font-size:90%;">2.6B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.8.5"><span class="ltx_text" id="S4.T9.8.8.5.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.8.8.6"><span class="ltx_text" id="S4.T9.8.8.6.1" style="font-size:90%;">10.39</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.8.8.7"><span class="ltx_text" id="S4.T9.8.8.7.1" style="font-size:90%;">0.52</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.9.9.2">
<span class="ltx_text" id="S4.T9.9.9.2.1" style="font-size:90%;">SDXL </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.9.9.2.2.1" style="font-size:90%;">(</span>Podell et al.<span class="ltx_text" id="S4.T9.9.9.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib32" title="">2023</a><span class="ltx_text" id="S4.T9.9.9.2.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T9.9.9.1">
<span class="ltx_text" id="S4.T9.9.9.1.1" style="font-size:90%;">2.6B + 0.8B</span><sup class="ltx_sup" id="S4.T9.9.9.1.2"><span class="ltx_text" id="S4.T9.9.9.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.9.9.3"><span class="ltx_text" id="S4.T9.9.9.3.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.9.9.4"><span class="ltx_text" id="S4.T9.9.9.4.1" style="font-size:90%;">1.6B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.9.9.5"><span class="ltx_text" id="S4.T9.9.9.5.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.9.9.6"><span class="ltx_text" id="S4.T9.9.9.6.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.9.9.7"><span class="ltx_text" id="S4.T9.9.9.7.1" style="font-size:90%;">0.55</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.10.10.2">
<span class="ltx_text" id="S4.T9.10.10.2.1" style="font-size:90%;">DeepFloyd </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.10.10.2.2.1" style="font-size:90%;">(</span>Stability AI<span class="ltx_text" id="S4.T9.10.10.2.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib44" title="">2024</a><span class="ltx_text" id="S4.T9.10.10.2.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T9.10.10.1">
<span class="ltx_text" id="S4.T9.10.10.1.1" style="font-size:90%;">5.5B + 4.7B</span><sup class="ltx_sup" id="S4.T9.10.10.1.2"><span class="ltx_text ltx_font_italic" id="S4.T9.10.10.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.10.10.3"><span class="ltx_text" id="S4.T9.10.10.3.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.10.10.4"><span class="ltx_text" id="S4.T9.10.10.4.1" style="font-size:90%;">7.5B</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.10.10.5"><span class="ltx_text" id="S4.T9.10.10.5.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.10.10.6"><span class="ltx_text" id="S4.T9.10.10.6.1" style="font-size:90%;">6.66</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.10.10.7"><span class="ltx_text" id="S4.T9.10.10.7.1" style="font-size:90%;">0.61</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T9.12.12.3">
<span class="ltx_text" id="S4.T9.12.12.3.1" style="font-size:90%;">SD 3 </span><cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="S4.T9.12.12.3.2.1" style="font-size:90%;">(</span>Esser et al.<span class="ltx_text" id="S4.T9.12.12.3.3.2.1.1" style="font-size:90%;">, </span><a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib17" title="">2024b</a><span class="ltx_text" id="S4.T9.12.12.3.4.3" style="font-size:90%;">)</span></cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T9.11.11.1">
<span class="ltx_text" id="S4.T9.11.11.1.1" style="font-size:90%;">8B + 4.7B</span><sup class="ltx_sup" id="S4.T9.11.11.1.2"><span class="ltx_text ltx_font_italic" id="S4.T9.11.11.1.2.1" style="font-size:90%;">∗</span></sup>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.12.4"><span class="ltx_text" id="S4.T9.12.12.4.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.12.2">
<sup class="ltx_sup" id="S4.T9.12.12.2.1"><span class="ltx_text ltx_font_italic" id="S4.T9.12.12.2.1.1" style="font-size:90%;">s</span></sup><span class="ltx_text" id="S4.T9.12.12.2.2" style="font-size:90%;">2.0B</span>
</td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.12.5"><span class="ltx_text" id="S4.T9.12.12.5.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_align_center" id="S4.T9.12.12.6"><span class="ltx_text" id="S4.T9.12.12.6.1" style="font-size:90%;">—</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T9.12.12.7"><span class="ltx_text" id="S4.T9.12.12.7.1" style="font-size:90%;">0.68</span></td>
</tr>
<tr class="ltx_tr" id="S4.T9.12.17.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S4.T9.12.17.5.1"><span class="ltx_text" id="S4.T9.12.17.5.1.1" style="font-size:90%;">Transfusion (Ours)</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T9.12.17.5.2"><span class="ltx_text" id="S4.T9.12.17.5.2.1" style="font-size:90%;">7.3B</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T9.12.17.5.3"><span class="ltx_text" id="S4.T9.12.17.5.3.1" style="font-size:90%;">1.0T</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T9.12.17.5.4"><span class="ltx_text" id="S4.T9.12.17.5.4.1" style="font-size:90%;">3.5B</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T9.12.17.5.5"><span class="ltx_text" id="S4.T9.12.17.5.5.1" style="font-size:90%;">66.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T9.12.17.5.6"><span class="ltx_text" id="S4.T9.12.17.5.6.1" style="font-size:90%;">6.78</span></td>
<td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb ltx_border_t" id="S4.T9.12.17.5.7"><span class="ltx_text" id="S4.T9.12.17.5.7.1" style="font-size:90%;">0.63</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 9: </span>Performance of a 7B Transfusion model (U-Net encoder/decoder layers, 2<math alttext="\times" class="ltx_Math" display="inline" id="S4.T9.17.m1.1"><semantics id="S4.T9.17.m1.1b"><mo id="S4.T9.17.m1.1.1" xref="S4.T9.17.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S4.T9.17.m1.1c"><times id="S4.T9.17.m1.1.1.cmml" xref="S4.T9.17.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T9.17.m1.1d">\times</annotation><annotation encoding="application/x-llamapun" id="S4.T9.17.m1.1e">×</annotation></semantics></math>2 latent pixel patches) trained on the equivalent of 2T tokens, compared to similar scale models in the literature.
Except Chameleon, all the other models are restricted to generating one modality (either text or image).
<sup class="ltx_sup" id="S4.T9.31.1"><span class="ltx_text ltx_font_italic" id="S4.T9.31.1.1">∗</span></sup> Frozen text encoder parameters.
<sup class="ltx_sup" id="S4.T9.32.2"><span class="ltx_text ltx_font_italic" id="S4.T9.32.2.1">r</span></sup> Parti samples 16 images for every prompt and then reranks with an auxiliary scoring model.
<sup class="ltx_sup" id="S4.T9.33.3"><span class="ltx_text ltx_font_italic" id="S4.T9.33.3.1">s</span></sup> SD 3 trains with synthetic caption data, which provides boosts GenEval performance.
</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Image Editing</h3>
<div class="ltx_para" id="S4.SS5.p1">
<p class="ltx_p" id="S4.SS5.p1.1">Our Transfusion models, which have been pretrained on text-text, image-text, and text-image data, perform well across these modality pairings.
Can these models extend their capabilities to generate images based on other images?
To investigate, we fine-tuned our 7B model (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS4" title="4.4 Comparison with Image Generation Literature ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.4</span></a>) using a dataset of only 8k publicly available image editing examples, where each example consists of an input image, an edit prompt, and an output image.
This approach, inspired by LIMA <cite class="ltx_cite ltx_citemacro_citep">(Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib54" title="">2024</a>)</cite>, allows us to assess how well the model can generalize to image-to-image generation, a scenario not covered during pretraining.</p>
</div>
<div class="ltx_para" id="S4.SS5.p2">
<p class="ltx_p" id="S4.SS5.p2.1">Manual examination of random examples from the EmuEdit test set <cite class="ltx_cite ltx_citemacro_citep">(Sheynin et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib43" title="">2024</a>)</cite>, shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.F6" title="Figure 6 ‣ 4.5 Image Editing ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">6</span></a> and Appendix <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS5" title="4.5 Image Editing ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.5</span></a>, reveals that our fine-tuned Transfusion model performs image edits as instructed.
Despite the limitations of this experiment, the findings suggest that Transfusion models can indeed adapt to and generalize across new modality combinations.
We leave further exploration of this promising direction to future research.</p>
</div>
<figure class="ltx_figure" id="S4.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="S4.F6.sf1.g1" src="extracted/5802141/img_edit_samples/0_remove_cupcake.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="S4.F6.sf1.g2" src="extracted/5802141/img_edit_samples/1_remove_cupcake.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.sf1.2.1.1" style="font-size:90%;">((a))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="S4.F6.sf2.g1" src="extracted/5802141/img_edit_samples/0_change_tomato_to_olive.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="S4.F6.sf2.g2" src="extracted/5802141/img_edit_samples/1_change_tomato_to_olive.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.sf2.2.1.1" style="font-size:90%;">((b))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="S4.F6.sf3.g1" src="extracted/5802141/img_edit_samples/0_zebra.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="S4.F6.sf3.g2" src="extracted/5802141/img_edit_samples/2_zebra.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.sf3.2.1.1" style="font-size:90%;">((c))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F6.sf4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="S4.F6.sf4.g1" src="extracted/5802141/img_edit_samples/0_cartoon_style.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="S4.F6.sf4.g2" src="extracted/5802141/img_edit_samples/1_cartoon_style.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.sf4.2.1.1" style="font-size:90%;">((d))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S4.F6.3.2" style="font-size:90%;">Edited images from a fine-tuned 7B Transfusion model.</span></figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Related Work</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Most existing multi-modal models are built on the idea of attaching two or more modality-specific architectures together, often pretraining each component separately in advance.
State-of-the-art image and video generation models, for instance, use large pretrained text encoders to represent their input prompts in latent space, which can then be used to condition diffusion models <cite class="ltx_cite ltx_citemacro_citep">(Saharia et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib39" title="">2022</a>)</cite>.
In fact, recent work fuses representations from multiple off-the-shelf encoders to enhance performance <cite class="ltx_cite ltx_citemacro_citep">(Podell et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib32" title="">2023</a>; Esser et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib17" title="">2024b</a>)</cite>.
A similar pattern can be observed in the vision language model literature, where typically a pretrained language model is complemented by pretrained modality-specific encoders/decoders via projection layers to/from the pretrained text space.
Examples include Flamingo <cite class="ltx_cite ltx_citemacro_citep">(Alayrac et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib1" title="">2022</a>)</cite> and LLaVA <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib28" title="">2024</a>)</cite> for visual understanding, GILL <cite class="ltx_cite ltx_citemacro_citep">(Koh et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib24" title="">2024</a>)</cite> for visual generation, and DreamLLM <cite class="ltx_cite ltx_citemacro_citep">(Dong et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib13" title="">2024</a>)</cite> for both visual comprehension and generation.
In contrast, Transfusion has one unified architecture learned end-to-end to generate both text and images.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Prior work on end-to-end multi-modal models includes examples such as Fuyu <cite class="ltx_cite ltx_citemacro_citep">(Bavishi et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib3" title="">2023</a>)</cite>, which uses image patches as inputs for visual understanding, and Chameleon <cite class="ltx_cite ltx_citemacro_citep">(Chameleon Team, <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib6" title="">2024</a>)</cite>, which converts each image to a sequence of discretized tokens and then trains over the combined text-image token sequences.
However, these approaches are either restricted to input-level multi-modal tasks, or lag behind state-of-the-art models (i.e. diffusion models) in continuous data generation.
Transfusion provides a simple, end-to-end solution to multi-modal learning that understands and generates high-quality multi-modal data.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">An interesting area of recent acrive research is the application diffusion models and their generalizations to discrete text generation <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib25" title="">2022</a>; Gat et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib18" title="">2024</a>)</cite>.
However, this approach has yet to achieve the performance and scale of standard autoregressive language models.
Future research in this direction may unlock new ways to fuse discrete and continuous modalities in a single model.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This work explores how to bridge the gap between the state of the art in discrete sequence modeling (next token prediction) and continuous media generation (diffusion).
We propose a simple, yet previously unexplored solution: train a single joint model on two objectives, tying each modality to its preferred objective.
Our experiments show that Transfusion scales efficiently, incurring little to no parameter sharing cost, while enabling the generation of any modality.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments and Disclosure of Funding</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We would like to thank Horace He, Songlin Yang, Jiatao Gu, and Ishan Misra for helpful discussions throughout this project.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alayrac et al. (2022)</span>
<span class="ltx_bibblock">
Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr, Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds, et al.

</span>
<span class="ltx_bibblock">Flamingo: a visual language model for few-shot learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Advances in neural information processing systems</em>, 35:23716–23736, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bar-Tal et al. (2024)</span>
<span class="ltx_bibblock">
Omer Bar-Tal, Hila Chefer, Omer Tov, Charles Herrmann, Roni Paiss, Shiran Zada, Ariel Ephrat, Junhwa Hur, Yuanzhen Li, Tomer Michaeli, et al.

</span>
<span class="ltx_bibblock">Lumiere: A space-time diffusion model for video generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2401.12945</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bavishi et al. (2023)</span>
<span class="ltx_bibblock">
Rohan Bavishi, Erich Elsen, Curtis Hawthorne, Maxwell Nye, Augustus Odena, Arushi Somani, and Sağnak Taşırlar.

</span>
<span class="ltx_bibblock">Introducing our multimodal models, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.adept.ai/blog/fuyu-8b" title="">https://www.adept.ai/blog/fuyu-8b</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Betker et al. (2023)</span>
<span class="ltx_bibblock">
James Betker, Gabriel Goh, Li Jing, Tim Brooks, Jianfeng Wang, Linjie Li, Long Ouyang, Juntang Zhuang, Joyce Lee, Yufei Guo, Wesam Manassra, Prafulla Dhariwal, Casey Chu, Yunxin Jiao, and Aditya Ramesh.

</span>
<span class="ltx_bibblock">Improving image generation with better captions, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:264403242" title="">https://api.semanticscholar.org/CorpusID:264403242</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bisk et al. (2020)</span>
<span class="ltx_bibblock">
Yonatan Bisk, Rowan Zellers, Jianfeng Gao, Yejin Choi, et al.

</span>
<span class="ltx_bibblock">Piqa: Reasoning about physical commonsense in natural language.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the AAAI conference on artificial intelligence</em>, pages 7432–7439, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chameleon Team (2024)</span>
<span class="ltx_bibblock">
Chameleon Team.

</span>
<span class="ltx_bibblock">Chameleon: Mixed-modal early-fusion foundation models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2405.09818</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Changpinyo et al. (2021)</span>
<span class="ltx_bibblock">
Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut.

</span>
<span class="ltx_bibblock">Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">CoRR</em>, abs/2102.08981, 2021.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2102.08981" title="">https://arxiv.org/abs/2102.08981</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2020)</span>
<span class="ltx_bibblock">
Xinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He.

</span>
<span class="ltx_bibblock">Improved baselines with momentum contrastive learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2003.04297</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et al. (2019)</span>
<span class="ltx_bibblock">
Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Boolq: Exploring the surprising difficulty of natural yes/no questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:1905.10044</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clark et al. (2018)</span>
<span class="ltx_bibblock">
Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish Sabharwal, Carissa Schoenick, and Oyvind Tafjord.

</span>
<span class="ltx_bibblock">Think you have solved question answering? try arc, the ai2 reasoning challenge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:1803.05457</em>, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. (2023)</span>
<span class="ltx_bibblock">
Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiaofang Wang, Abhimanyu Dubey, et al.

</span>
<span class="ltx_bibblock">Emu: Enhancing image generation models using photogenic needles in a haystack.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2309.15807</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2023)</span>
<span class="ltx_bibblock">
Runpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge, Jinrong Yang, Liang Zhao, Jianjian Sun, Hongyu Zhou, Haoran Wei, et al.

</span>
<span class="ltx_bibblock">Dreamllm: Synergistic multimodal comprehension and creation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2309.11499</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2024)</span>
<span class="ltx_bibblock">
Runpei Dong, Chunrui Han, Yuang Peng, Zekun Qi, Zheng Ge, Jinrong Yang, Liang Zhao, Jianjian Sun, Hongyu Zhou, Haoran Wei, et al.

</span>
<span class="ltx_bibblock">Dreamllm: Synergistic multimodal comprehension and creation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">The Twelfth International Conference on Learning Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. (2024)</span>
<span class="ltx_bibblock">
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang, Archi Mitra, Archie Sravankumar, Artem Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen Gregerson, Ava Spataru, Baptiste Roziere, Bethany Biron, Binh Tang, Bobbie Chern, Charlotte Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Allonsius, Daniel Song, Danielle Pintz, Danny Livshits, David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab AlBadawy, Elina Lobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Graeme Nail, Gregoire Mialon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Hannah Korevaar, Hu Xu, Hugo Touvron, Iliyan Zarov,
Imanol Arrieta Ibarra, Isabel Kloumann, Ishan Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, Jelmer van der Linde, Jennifer Billock, Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, Joshua Johnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, Kartikeya Upasani, Kate Plawiak, Ke Li, Kenneth Heafield, Kevin Stone, Khalid El-Arini, Krithika Iyer, Kshitiz Malik, Kuenley Chiu, Kunal Bhalla, Lauren Rantala-Yeary, Laurens van der Maaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish Madaan, Lubo Malo, Lukas Blecher, Lukas Landzaat, Luke de Oliveira, Madeline Muzzi, Mahesh Pasupuleti, Mannat Singh, Manohar Paluri, Marcin Kardas, Mathew Oldham, Mathieu Rita, Maya Pavlova, Melanie Kambadur, Mike Lewis, Min Si, Mitesh Kumar Singh, Mona Hassan, Naman Goyal, Narjes Torabi, Nikolay Bashlykov, Nikolay Bogoychev, Niladri Chatterji, Olivier
Duchenne, Onur Çelebi, Patrick Alrassy, Pengchuan Zhang, Pengwei Li, Petar Vasic, Peter Weng, Prajjwal Bhargava, Pratik Dubal, Praveen Krishnan, Punit Singh Koura, Puxin Xu, Qing He, Qingxiao Dong, Ragavan Srinivasan, Raj Ganapathy, Ramon Calderer, Ricardo Silveira Cabral, Robert Stojnic, Roberta Raileanu, Rohit Girdhar, Rohit Patel, Romain Sauvestre, Ronnie Polidoro, Roshan Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, Saghar Hosseini, Sahana Chennabasappa, Sanjay Singh, Sean Bell, Seohyun Sonia Kim, Sergey Edunov, Shaoliang Nie, Sharan Narang, Sharath Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale, Shun Zhang, Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, Stephane Collot, Suchin Gururangan, Sydney Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha, Thomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal Karn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent Gonguet, Virginie Do, Vish Vogeti, Vladan Petrovic, Weiwei Chu,
Wenhan Xiong, Wenyin Fu, Whitney Meers, Xavier Martinet, Xiaodong Wang, Xiaoqing Ellen Tan, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine Babaei, Yi Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert, Zheng Yan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh, Aaron Grattafiori, Abha Jain, Adam Kelsey, Adam Shajnfeld, Adithya Gangidi, Adolfo Victoria, Ahuva Goldstand, Ajay Menon, Ajay Sharma, Alex Boesenberg, Alex Vaughan, Alexei Baevski, Allie Feinstein, Amanda Kallet, Amit Sangani, Anam Yunus, Andrei Lupu, Andres Alvarado, Andrew Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit Ramchandani, Annie Franco, Aparajita Saraf, Arkabandhu Chowdhury, Ashley Gabriel, Ashwin Bharambe, Assaf Eisenman, Azadeh Yazdan, Beau James, Ben Maurer, Benjamin Leonhardi, Bernie Huang, Beth Loyd, Beto De Paola, Bhargavi Paranjape, Bing Liu, Bo Wu, Boyu Ni, Braden Hancock, Bram Wasti, Brandon Spence, Brani Stojkovic, Brian Gamido, Britt Montalvo, Carl
Parker, Carly Burton, Catalina Mejia, Changhan Wang, Changkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal, Christoph Feichtenhofer, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, Danny Wyatt, David Adkins, David Xu, Davide Testuggine, Delia David, Devi Parikh, Diana Liskovich, Didem Foss, Dingkang Wang, Duc Le, Dustin Holland, Edward Dowling, Eissa Jamil, Elaine Montgomery, Eleonora Presani, Emily Hahn, Emily Wood, Erik Brinkman, Esteban Arcaute, Evan Dunbar, Evan Smothers, Fei Sun, Felix Kreuk, Feng Tian, Firat Ozgenel, Francesco Caggioni, Francisco Guzmán, Frank Kanayet, Frank Seide, Gabriela Medina Florez, Gabriella Schwarz, Gada Badeer, Georgia Swee, Gil Halpern, Govind Thattai, Grant Herman, Grigory Sizov, Guangyi, Zhang, Guna Lakshminarayanan, Hamid Shojanazeri, Han Zou, Hannah Wang, Hanwen Zha, Haroun Habeeb, Harrison Rudolph, Helen Suk, Henry Aspegren, Hunter Goldman, Igor Molybog, Igor Tufanov, Irina-Elena Veliche, Itai Gat, Jake Weissman, James Geboski, James Kohli,
Japhet Asher, Jean-Baptiste Gaya, Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny Zhen, Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong, Jian Jin, Jingyi Yang, Joe Cummings, Jon Carvill, Jon Shepard, Jonathan McPhie, Jonathan Torres, Josh Ginsburg, Junjie Wang, Kai Wu, Kam Hou U, Karan Saxena, Karthik Prasad, Kartikay Khandelwal, Katayoun Zand, Kathy Matosich, Kaushik Veeraraghavan, Kelly Michelena, Keqian Li, Kun Huang, Kunal Chawla, Kushal Lakhotia, Kyle Huang, Lailin Chen, Lakshya Garg, Lavender A, Leandro Silva, Lee Bell, Lei Zhang, Liangpeng Guo, Licheng Yu, Liron Moshkovich, Luca Wehrstedt, Madian Khabsa, Manav Avalani, Manish Bhatt, Maria Tsimpoukelli, Martynas Mankus, Matan Hasson, Matthew Lennie, Matthias Reso, Maxim Groshev, Maxim Naumov, Maya Lathi, Meghan Keneally, Michael L. Seltzer, Michal Valko, Michelle Restrepo, Mihir Patel, Mik Vyatskov, Mikayel Samvelyan, Mike Clark, Mike Macey, Mike Wang, Miquel Jubert Hermoso, Mo Metanat, Mohammad Rastegari, Munish Bansal, Nandhini Santhanam, Natascha
Parks, Natasha White, Navyata Bawa, Nayan Singhal, Nick Egebo, Nicolas Usunier, Nikolay Pavlovich Laptev, Ning Dong, Ning Zhang, Norman Cheng, Oleg Chernoguz, Olivia Hart, Omkar Salpekar, Ozlem Kalinli, Parkin Kent, Parth Parekh, Paul Saab, Pavan Balaji, Pedro Rittner, Philip Bontrager, Pierre Roux, Piotr Dollar, Polina Zvyagina, Prashant Ratanchandani, Pritish Yuvraj, Qian Liang, Rachad Alao, Rachel Rodriguez, Rafi Ayub, Raghotham Murthy, Raghu Nayani, Rahul Mitra, Raymond Li, Rebekkah Hogan, Robin Battey, Rocky Wang, Rohan Maheswari, Russ Howes, Ruty Rinott, Sai Jayesh Bondu, Samyak Datta, Sara Chugh, Sara Hunt, Sargun Dhillon, Sasha Sidorov, Satadru Pan, Saurabh Verma, Seiji Yamamoto, Sharadh Ramaswamy, Shaun Lindsay, Shaun Lindsay, Sheng Feng, Shenghao Lin, Shengxin Cindy Zha, Shiva Shankar, Shuqiang Zhang, Shuqiang Zhang, Sinong Wang, Sneha Agarwal, Soji Sajuyigbe, Soumith Chintala, Stephanie Max, Stephen Chen, Steve Kehoe, Steve Satterfield, Sudarshan Govindaprasad, Sumit Gupta, Sungmin Cho, Sunny
Virk, Suraj Subramanian, Sy Choudhury, Sydney Goldman, Tal Remez, Tamar Glaser, Tamara Best, Thilo Kohler, Thomas Robinson, Tianhe Li, Tianjun Zhang, Tim Matthews, Timothy Chou, Tzook Shaked, Varun Vontimitta, Victoria Ajayi, Victoria Montanez, Vijai Mohan, Vinay Satish Kumar, Vishal Mangla, Vlad Ionescu, Vlad Poenaru, Vlad Tiberiu Mihailescu, Vladimir Ivanov, Wei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, Will Constable, Xiaocheng Tang, Xiaofang Wang, Xiaojian Wu, Xiaolan Wang, Xide Xia, Xilun Wu, Xinbo Gao, Yanjun Chen, Ye Hu, Ye Jia, Ye Qi, Yenda Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam, Yu, Wang, Yuchen Hao, Yundi Qian, Yuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen, Zhenyu Yang, and Zhiwei Zhao.

</span>
<span class="ltx_bibblock">The llama 3 herd of models, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2407.21783" title="">https://arxiv.org/abs/2407.21783</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esser et al. (2021)</span>
<span class="ltx_bibblock">
Patrick Esser, Robin Rombach, and Bjorn Ommer.

</span>
<span class="ltx_bibblock">Taming transformers for high-resolution image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pages 12873–12883, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esser et al. (2024a)</span>
<span class="ltx_bibblock">
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, et al.

</span>
<span class="ltx_bibblock">Scaling rectified flow transformers for high-resolution image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Forty-first International Conference on Machine Learning</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Esser et al. (2024b)</span>
<span class="ltx_bibblock">
Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek, and Robin Rombach.

</span>
<span class="ltx_bibblock">Scaling rectified flow transformers for high-resolution image synthesis, 2024b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2403.03206" title="">https://arxiv.org/abs/2403.03206</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gat et al. (2024)</span>
<span class="ltx_bibblock">
Itai Gat, Tal Remez, Neta Shaul, Felix Kreuk, Ricky TQ Chen, Gabriel Synnaeve, Yossi Adi, and Yaron Lipman.

</span>
<span class="ltx_bibblock">Discrete flow matching.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2407.15595</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosh et al. (2023)</span>
<span class="ltx_bibblock">
Dhruba Ghosh, Hannaneh Hajishirzi, and Ludwig Schmidt.

</span>
<span class="ltx_bibblock">Geneval: An object-focused framework for evaluating text-to-image alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Advances in Neural Information Processing Systems</em>, 36, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heusel et al. (2017)</span>
<span class="ltx_bibblock">
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.

</span>
<span class="ltx_bibblock">Gans trained by a two time-scale update rule converge to a local nash equilibrium.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho and Salimans (2022)</span>
<span class="ltx_bibblock">
Jonathan Ho and Tim Salimans.

</span>
<span class="ltx_bibblock">Classifier-free diffusion guidance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2207.12598</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Advances in neural information processing systems</em>, 33:6840–6851, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kingma and Welling (2013)</span>
<span class="ltx_bibblock">
Diederik P Kingma and Max Welling.

</span>
<span class="ltx_bibblock">Auto-encoding variational bayes.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">arXiv preprint arXiv:1312.6114</em>, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koh et al. (2024)</span>
<span class="ltx_bibblock">
Jing Yu Koh, Daniel Fried, and Russ R Salakhutdinov.

</span>
<span class="ltx_bibblock">Generating images with multimodal language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022)</span>
<span class="ltx_bibblock">
Xiang Lisa Li, John Thickstun, Ishaan Gulrajani, Percy Liang, and Tatsunori Hashimoto.

</span>
<span class="ltx_bibblock">Diffusion-lm improves controllable text generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">ArXiv</em>, abs/2205.14217, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2014)</span>
<span class="ltx_bibblock">
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick.

</span>
<span class="ltx_bibblock">Microsoft coco: Common objects in context.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">European conference on computer vision</em>, pages 740–755. Springer, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lipman et al. (2022)</span>
<span class="ltx_bibblock">
Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le.

</span>
<span class="ltx_bibblock">Flow matching for generative modeling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2210.02747</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee.

</span>
<span class="ltx_bibblock">Visual instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Advances in neural information processing systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Shilong Liu, Hao Cheng, Haotian Liu, Hao Zhang, Feng Li, Tianhe Ren, Xueyan Zou, Jianwei Yang, Hang Su, Jun Zhu, et al.

</span>
<span class="ltx_bibblock">Llava-plus: Learning to use tools for creating multimodal agents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2311.05437</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nichol and Dhariwal (2021)</span>
<span class="ltx_bibblock">
Alexander Quinn Nichol and Prafulla Dhariwal.

</span>
<span class="ltx_bibblock">Improved denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">International conference on machine learning</em>, pages 8162–8171. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI et al. (2024)</span>
<span class="ltx_bibblock">
OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo
Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, Ryan
Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez,
Nick Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B. Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia
Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph.

</span>
<span class="ltx_bibblock">Gpt-4 technical report, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2303.08774" title="">https://arxiv.org/abs/2303.08774</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Podell et al. (2023)</span>
<span class="ltx_bibblock">
Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna, and Robin Rombach.

</span>
<span class="ltx_bibblock">Sdxl: Improving latent diffusion models for high-resolution image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2307.01952</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2103.00020</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al. (2019)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu.

</span>
<span class="ltx_bibblock">Exploring the limits of transfer learning with a unified text-to-text transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">CoRR</em>, abs/1910.10683, 2019.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1910.10683" title="">http://arxiv.org/abs/1910.10683</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et al. (2021)</span>
<span class="ltx_bibblock">
Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever.

</span>
<span class="ltx_bibblock">Zero-shot text-to-image generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">International conference on machine learning</em>, pages 8821–8831. Pmlr, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et al. (2022)</span>
<span class="ltx_bibblock">
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.

</span>
<span class="ltx_bibblock">Hierarchical text-conditional image generation with clip latents, 2022.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2204.06125" title="">https://arxiv.org/abs/2204.06125</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach et al. (2022a)</span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pages 10684–10695, 2022a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach et al. (2022b)</span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pages 10684–10695, 2022b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saharia et al. (2022)</span>
<span class="ltx_bibblock">
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.

</span>
<span class="ltx_bibblock">Photorealistic text-to-image diffusion models with deep language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Advances in neural information processing systems</em>, 35:36479–36494, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sakaguchi et al. (2021)</span>
<span class="ltx_bibblock">
Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi.

</span>
<span class="ltx_bibblock">Winogrande: An adversarial winograd schema challenge at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Communications of the ACM</em>, 64(9):99–106, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sap et al. (2019)</span>
<span class="ltx_bibblock">
Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi.

</span>
<span class="ltx_bibblock">Socialiqa: Commonsense reasoning about social interactions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">arXiv preprint arXiv:1904.09728</em>, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shazeer (2020)</span>
<span class="ltx_bibblock">
Noam Shazeer.

</span>
<span class="ltx_bibblock">Glu variants improve transformer.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">arXiv preprint arXiv:2002.05202</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheynin et al. (2024)</span>
<span class="ltx_bibblock">
Shelly Sheynin, Adam Polyak, Uriel Singer, Yuval Kirstain, Amit Zohar, Oron Ashual, Devi Parikh, and Yaniv Taigman.

</span>
<span class="ltx_bibblock">Emu edit: Precise image editing via recognition and generation tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pages 8871–8879, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stability AI (2024)</span>
<span class="ltx_bibblock">
Stability AI.

</span>
<span class="ltx_bibblock">If by deepfloyd lab at stabilityai, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://stability.ai/news/deepfloyd-if-text-to-image-model" title="">https://stability.ai/news/deepfloyd-if-text-to-image-model</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. (2024)</span>
<span class="ltx_bibblock">
Jianlin Su, Murtadha Ahmed, Yu Lu, Shengfeng Pan, Wen Bo, and Yunfeng Liu.

</span>
<span class="ltx_bibblock">Roformer: Enhanced transformer with rotary position embedding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">Neurocomputing</em>, 568:127063, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:2302.13971</em>, 2023a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2307.09288</em>, 2023b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Van Den Oord et al. (2017)</span>
<span class="ltx_bibblock">
Aaron Van Den Oord, Oriol Vinyals, et al.

</span>
<span class="ltx_bibblock">Neural discrete representation learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Advances in neural information processing systems</em>, 30, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vedantam et al. (2015)</span>
<span class="ltx_bibblock">
Ramakrishna Vedantam, C Lawrence Zitnick, and Devi Parikh.

</span>
<span class="ltx_bibblock">Cider: Consensus-based image description evaluation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pages 4566–4575, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, et al.

</span>
<span class="ltx_bibblock">Scaling autoregressive models for content-rich text-to-image generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">arXiv preprint arXiv:2206.10789</em>, 2(3):5, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023)</span>
<span class="ltx_bibblock">
Lili Yu, Bowen Shi, Ramakanth Pasunuru, Benjamin Muller, Olga Golovneva, Tianlu Wang, Arun Babu, Binh Tang, Brian Karrer, Shelly Sheynin, et al.

</span>
<span class="ltx_bibblock">Scaling autoregressive multi-modal models: Pretraining and instruction tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2309.02591</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zellers et al. (2019)</span>
<span class="ltx_bibblock">
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.

</span>
<span class="ltx_bibblock">Hellaswag: Can a machine really finish your sentence?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL-2019)</em>. Association for Computational Linguistics, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2018)</span>
<span class="ltx_bibblock">
Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang.

</span>
<span class="ltx_bibblock">The unreasonable effectiveness of deep features as a perceptual metric.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pages 586–595, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer, Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, Ping Yu, Lili Yu, et al.

</span>
<span class="ltx_bibblock">Lima: Less is more for alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Autoencoder Details</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.6">The training objective for our VAE closely follows that of <cite class="ltx_cite ltx_citemacro_cite">Esser et al. [<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib15" title="">2021</a>]</cite>:</p>
<table class="ltx_equation ltx_eqn_table" id="A1.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{VAE}}=\mathcal{L}_{1}+\mathcal{L}_{\text{LPIPS}}+0.5%
\mathcal{L}_{\text{GAN}}+0.2\mathcal{L}_{\text{ID}}+0.000001\mathcal{L}_{\text%
{KL}}" class="ltx_Math" display="block" id="A1.Ex1.m1.1"><semantics id="A1.Ex1.m1.1a"><mrow id="A1.Ex1.m1.1.1" xref="A1.Ex1.m1.1.1.cmml"><msub id="A1.Ex1.m1.1.1.2" xref="A1.Ex1.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex1.m1.1.1.2.2" xref="A1.Ex1.m1.1.1.2.2.cmml">ℒ</mi><mtext id="A1.Ex1.m1.1.1.2.3" xref="A1.Ex1.m1.1.1.2.3a.cmml">VAE</mtext></msub><mo id="A1.Ex1.m1.1.1.1" xref="A1.Ex1.m1.1.1.1.cmml">=</mo><mrow id="A1.Ex1.m1.1.1.3" xref="A1.Ex1.m1.1.1.3.cmml"><msub id="A1.Ex1.m1.1.1.3.2" xref="A1.Ex1.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex1.m1.1.1.3.2.2" xref="A1.Ex1.m1.1.1.3.2.2.cmml">ℒ</mi><mn id="A1.Ex1.m1.1.1.3.2.3" xref="A1.Ex1.m1.1.1.3.2.3.cmml">1</mn></msub><mo id="A1.Ex1.m1.1.1.3.1" xref="A1.Ex1.m1.1.1.3.1.cmml">+</mo><msub id="A1.Ex1.m1.1.1.3.3" xref="A1.Ex1.m1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex1.m1.1.1.3.3.2" xref="A1.Ex1.m1.1.1.3.3.2.cmml">ℒ</mi><mtext id="A1.Ex1.m1.1.1.3.3.3" xref="A1.Ex1.m1.1.1.3.3.3a.cmml">LPIPS</mtext></msub><mo id="A1.Ex1.m1.1.1.3.1a" xref="A1.Ex1.m1.1.1.3.1.cmml">+</mo><mrow id="A1.Ex1.m1.1.1.3.4" xref="A1.Ex1.m1.1.1.3.4.cmml"><mn id="A1.Ex1.m1.1.1.3.4.2" xref="A1.Ex1.m1.1.1.3.4.2.cmml">0.5</mn><mo id="A1.Ex1.m1.1.1.3.4.1" xref="A1.Ex1.m1.1.1.3.4.1.cmml">⁢</mo><msub id="A1.Ex1.m1.1.1.3.4.3" xref="A1.Ex1.m1.1.1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex1.m1.1.1.3.4.3.2" xref="A1.Ex1.m1.1.1.3.4.3.2.cmml">ℒ</mi><mtext id="A1.Ex1.m1.1.1.3.4.3.3" xref="A1.Ex1.m1.1.1.3.4.3.3a.cmml">GAN</mtext></msub></mrow><mo id="A1.Ex1.m1.1.1.3.1b" xref="A1.Ex1.m1.1.1.3.1.cmml">+</mo><mrow id="A1.Ex1.m1.1.1.3.5" xref="A1.Ex1.m1.1.1.3.5.cmml"><mn id="A1.Ex1.m1.1.1.3.5.2" xref="A1.Ex1.m1.1.1.3.5.2.cmml">0.2</mn><mo id="A1.Ex1.m1.1.1.3.5.1" xref="A1.Ex1.m1.1.1.3.5.1.cmml">⁢</mo><msub id="A1.Ex1.m1.1.1.3.5.3" xref="A1.Ex1.m1.1.1.3.5.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex1.m1.1.1.3.5.3.2" xref="A1.Ex1.m1.1.1.3.5.3.2.cmml">ℒ</mi><mtext id="A1.Ex1.m1.1.1.3.5.3.3" xref="A1.Ex1.m1.1.1.3.5.3.3a.cmml">ID</mtext></msub></mrow><mo id="A1.Ex1.m1.1.1.3.1c" xref="A1.Ex1.m1.1.1.3.1.cmml">+</mo><mrow id="A1.Ex1.m1.1.1.3.6" xref="A1.Ex1.m1.1.1.3.6.cmml"><mn id="A1.Ex1.m1.1.1.3.6.2" xref="A1.Ex1.m1.1.1.3.6.2.cmml">0.000001</mn><mo id="A1.Ex1.m1.1.1.3.6.1" xref="A1.Ex1.m1.1.1.3.6.1.cmml">⁢</mo><msub id="A1.Ex1.m1.1.1.3.6.3" xref="A1.Ex1.m1.1.1.3.6.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex1.m1.1.1.3.6.3.2" xref="A1.Ex1.m1.1.1.3.6.3.2.cmml">ℒ</mi><mtext id="A1.Ex1.m1.1.1.3.6.3.3" xref="A1.Ex1.m1.1.1.3.6.3.3a.cmml">KL</mtext></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex1.m1.1b"><apply id="A1.Ex1.m1.1.1.cmml" xref="A1.Ex1.m1.1.1"><eq id="A1.Ex1.m1.1.1.1.cmml" xref="A1.Ex1.m1.1.1.1"></eq><apply id="A1.Ex1.m1.1.1.2.cmml" xref="A1.Ex1.m1.1.1.2"><csymbol cd="ambiguous" id="A1.Ex1.m1.1.1.2.1.cmml" xref="A1.Ex1.m1.1.1.2">subscript</csymbol><ci id="A1.Ex1.m1.1.1.2.2.cmml" xref="A1.Ex1.m1.1.1.2.2">ℒ</ci><ci id="A1.Ex1.m1.1.1.2.3a.cmml" xref="A1.Ex1.m1.1.1.2.3"><mtext id="A1.Ex1.m1.1.1.2.3.cmml" mathsize="70%" xref="A1.Ex1.m1.1.1.2.3">VAE</mtext></ci></apply><apply id="A1.Ex1.m1.1.1.3.cmml" xref="A1.Ex1.m1.1.1.3"><plus id="A1.Ex1.m1.1.1.3.1.cmml" xref="A1.Ex1.m1.1.1.3.1"></plus><apply id="A1.Ex1.m1.1.1.3.2.cmml" xref="A1.Ex1.m1.1.1.3.2"><csymbol cd="ambiguous" id="A1.Ex1.m1.1.1.3.2.1.cmml" xref="A1.Ex1.m1.1.1.3.2">subscript</csymbol><ci id="A1.Ex1.m1.1.1.3.2.2.cmml" xref="A1.Ex1.m1.1.1.3.2.2">ℒ</ci><cn id="A1.Ex1.m1.1.1.3.2.3.cmml" type="integer" xref="A1.Ex1.m1.1.1.3.2.3">1</cn></apply><apply id="A1.Ex1.m1.1.1.3.3.cmml" xref="A1.Ex1.m1.1.1.3.3"><csymbol cd="ambiguous" id="A1.Ex1.m1.1.1.3.3.1.cmml" xref="A1.Ex1.m1.1.1.3.3">subscript</csymbol><ci id="A1.Ex1.m1.1.1.3.3.2.cmml" xref="A1.Ex1.m1.1.1.3.3.2">ℒ</ci><ci id="A1.Ex1.m1.1.1.3.3.3a.cmml" xref="A1.Ex1.m1.1.1.3.3.3"><mtext id="A1.Ex1.m1.1.1.3.3.3.cmml" mathsize="70%" xref="A1.Ex1.m1.1.1.3.3.3">LPIPS</mtext></ci></apply><apply id="A1.Ex1.m1.1.1.3.4.cmml" xref="A1.Ex1.m1.1.1.3.4"><times id="A1.Ex1.m1.1.1.3.4.1.cmml" xref="A1.Ex1.m1.1.1.3.4.1"></times><cn id="A1.Ex1.m1.1.1.3.4.2.cmml" type="float" xref="A1.Ex1.m1.1.1.3.4.2">0.5</cn><apply id="A1.Ex1.m1.1.1.3.4.3.cmml" xref="A1.Ex1.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="A1.Ex1.m1.1.1.3.4.3.1.cmml" xref="A1.Ex1.m1.1.1.3.4.3">subscript</csymbol><ci id="A1.Ex1.m1.1.1.3.4.3.2.cmml" xref="A1.Ex1.m1.1.1.3.4.3.2">ℒ</ci><ci id="A1.Ex1.m1.1.1.3.4.3.3a.cmml" xref="A1.Ex1.m1.1.1.3.4.3.3"><mtext id="A1.Ex1.m1.1.1.3.4.3.3.cmml" mathsize="70%" xref="A1.Ex1.m1.1.1.3.4.3.3">GAN</mtext></ci></apply></apply><apply id="A1.Ex1.m1.1.1.3.5.cmml" xref="A1.Ex1.m1.1.1.3.5"><times id="A1.Ex1.m1.1.1.3.5.1.cmml" xref="A1.Ex1.m1.1.1.3.5.1"></times><cn id="A1.Ex1.m1.1.1.3.5.2.cmml" type="float" xref="A1.Ex1.m1.1.1.3.5.2">0.2</cn><apply id="A1.Ex1.m1.1.1.3.5.3.cmml" xref="A1.Ex1.m1.1.1.3.5.3"><csymbol cd="ambiguous" id="A1.Ex1.m1.1.1.3.5.3.1.cmml" xref="A1.Ex1.m1.1.1.3.5.3">subscript</csymbol><ci id="A1.Ex1.m1.1.1.3.5.3.2.cmml" xref="A1.Ex1.m1.1.1.3.5.3.2">ℒ</ci><ci id="A1.Ex1.m1.1.1.3.5.3.3a.cmml" xref="A1.Ex1.m1.1.1.3.5.3.3"><mtext id="A1.Ex1.m1.1.1.3.5.3.3.cmml" mathsize="70%" xref="A1.Ex1.m1.1.1.3.5.3.3">ID</mtext></ci></apply></apply><apply id="A1.Ex1.m1.1.1.3.6.cmml" xref="A1.Ex1.m1.1.1.3.6"><times id="A1.Ex1.m1.1.1.3.6.1.cmml" xref="A1.Ex1.m1.1.1.3.6.1"></times><cn id="A1.Ex1.m1.1.1.3.6.2.cmml" type="float" xref="A1.Ex1.m1.1.1.3.6.2">0.000001</cn><apply id="A1.Ex1.m1.1.1.3.6.3.cmml" xref="A1.Ex1.m1.1.1.3.6.3"><csymbol cd="ambiguous" id="A1.Ex1.m1.1.1.3.6.3.1.cmml" xref="A1.Ex1.m1.1.1.3.6.3">subscript</csymbol><ci id="A1.Ex1.m1.1.1.3.6.3.2.cmml" xref="A1.Ex1.m1.1.1.3.6.3.2">ℒ</ci><ci id="A1.Ex1.m1.1.1.3.6.3.3a.cmml" xref="A1.Ex1.m1.1.1.3.6.3.3"><mtext id="A1.Ex1.m1.1.1.3.6.3.3.cmml" mathsize="70%" xref="A1.Ex1.m1.1.1.3.6.3.3">KL</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex1.m1.1c">\mathcal{L}_{\text{VAE}}=\mathcal{L}_{1}+\mathcal{L}_{\text{LPIPS}}+0.5%
\mathcal{L}_{\text{GAN}}+0.2\mathcal{L}_{\text{ID}}+0.000001\mathcal{L}_{\text%
{KL}}</annotation><annotation encoding="application/x-llamapun" id="A1.Ex1.m1.1d">caligraphic_L start_POSTSUBSCRIPT VAE end_POSTSUBSCRIPT = caligraphic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT LPIPS end_POSTSUBSCRIPT + 0.5 caligraphic_L start_POSTSUBSCRIPT GAN end_POSTSUBSCRIPT + 0.2 caligraphic_L start_POSTSUBSCRIPT ID end_POSTSUBSCRIPT + 0.000001 caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A1.p1.5">where <math alttext="L_{1}" class="ltx_Math" display="inline" id="A1.p1.1.m1.1"><semantics id="A1.p1.1.m1.1a"><msub id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml"><mi id="A1.p1.1.m1.1.1.2" xref="A1.p1.1.m1.1.1.2.cmml">L</mi><mn id="A1.p1.1.m1.1.1.3" xref="A1.p1.1.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><apply id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.p1.1.m1.1.1.1.cmml" xref="A1.p1.1.m1.1.1">subscript</csymbol><ci id="A1.p1.1.m1.1.1.2.cmml" xref="A1.p1.1.m1.1.1.2">𝐿</ci><cn id="A1.p1.1.m1.1.1.3.cmml" type="integer" xref="A1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">L_{1}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.1.m1.1d">italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> is L1 loss in pixel space, <math alttext="L_{\text{LPIPS}}" class="ltx_Math" display="inline" id="A1.p1.2.m2.1"><semantics id="A1.p1.2.m2.1a"><msub id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml"><mi id="A1.p1.2.m2.1.1.2" xref="A1.p1.2.m2.1.1.2.cmml">L</mi><mtext id="A1.p1.2.m2.1.1.3" xref="A1.p1.2.m2.1.1.3a.cmml">LPIPS</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><apply id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.p1.2.m2.1.1.1.cmml" xref="A1.p1.2.m2.1.1">subscript</csymbol><ci id="A1.p1.2.m2.1.1.2.cmml" xref="A1.p1.2.m2.1.1.2">𝐿</ci><ci id="A1.p1.2.m2.1.1.3a.cmml" xref="A1.p1.2.m2.1.1.3"><mtext id="A1.p1.2.m2.1.1.3.cmml" mathsize="70%" xref="A1.p1.2.m2.1.1.3">LPIPS</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">L_{\text{LPIPS}}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.2.m2.1d">italic_L start_POSTSUBSCRIPT LPIPS end_POSTSUBSCRIPT</annotation></semantics></math> is perceptual loss based on LPIPS similarity <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. [<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib53" title="">2018</a>]</cite>, <math alttext="L_{GAN}" class="ltx_Math" display="inline" id="A1.p1.3.m3.1"><semantics id="A1.p1.3.m3.1a"><msub id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml"><mi id="A1.p1.3.m3.1.1.2" xref="A1.p1.3.m3.1.1.2.cmml">L</mi><mrow id="A1.p1.3.m3.1.1.3" xref="A1.p1.3.m3.1.1.3.cmml"><mi id="A1.p1.3.m3.1.1.3.2" xref="A1.p1.3.m3.1.1.3.2.cmml">G</mi><mo id="A1.p1.3.m3.1.1.3.1" xref="A1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.3.m3.1.1.3.3" xref="A1.p1.3.m3.1.1.3.3.cmml">A</mi><mo id="A1.p1.3.m3.1.1.3.1a" xref="A1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="A1.p1.3.m3.1.1.3.4" xref="A1.p1.3.m3.1.1.3.4.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><apply id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A1.p1.3.m3.1.1.1.cmml" xref="A1.p1.3.m3.1.1">subscript</csymbol><ci id="A1.p1.3.m3.1.1.2.cmml" xref="A1.p1.3.m3.1.1.2">𝐿</ci><apply id="A1.p1.3.m3.1.1.3.cmml" xref="A1.p1.3.m3.1.1.3"><times id="A1.p1.3.m3.1.1.3.1.cmml" xref="A1.p1.3.m3.1.1.3.1"></times><ci id="A1.p1.3.m3.1.1.3.2.cmml" xref="A1.p1.3.m3.1.1.3.2">𝐺</ci><ci id="A1.p1.3.m3.1.1.3.3.cmml" xref="A1.p1.3.m3.1.1.3.3">𝐴</ci><ci id="A1.p1.3.m3.1.1.3.4.cmml" xref="A1.p1.3.m3.1.1.3.4">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">L_{GAN}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.3.m3.1d">italic_L start_POSTSUBSCRIPT italic_G italic_A italic_N end_POSTSUBSCRIPT</annotation></semantics></math> is a patch-based discriminator loss, <math alttext="L_{\text{ID}}" class="ltx_Math" display="inline" id="A1.p1.4.m4.1"><semantics id="A1.p1.4.m4.1a"><msub id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml"><mi id="A1.p1.4.m4.1.1.2" xref="A1.p1.4.m4.1.1.2.cmml">L</mi><mtext id="A1.p1.4.m4.1.1.3" xref="A1.p1.4.m4.1.1.3a.cmml">ID</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b"><apply id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A1.p1.4.m4.1.1.1.cmml" xref="A1.p1.4.m4.1.1">subscript</csymbol><ci id="A1.p1.4.m4.1.1.2.cmml" xref="A1.p1.4.m4.1.1.2">𝐿</ci><ci id="A1.p1.4.m4.1.1.3a.cmml" xref="A1.p1.4.m4.1.1.3"><mtext id="A1.p1.4.m4.1.1.3.cmml" mathsize="70%" xref="A1.p1.4.m4.1.1.3">ID</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">L_{\text{ID}}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.4.m4.1d">italic_L start_POSTSUBSCRIPT ID end_POSTSUBSCRIPT</annotation></semantics></math> is a perceptual loss based on internal features of the Moco v2 model <cite class="ltx_cite ltx_citemacro_cite">Chen et al. [<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib8" title="">2020</a>]</cite>, and <math alttext="L_{\text{KL}}" class="ltx_Math" display="inline" id="A1.p1.5.m5.1"><semantics id="A1.p1.5.m5.1a"><msub id="A1.p1.5.m5.1.1" xref="A1.p1.5.m5.1.1.cmml"><mi id="A1.p1.5.m5.1.1.2" xref="A1.p1.5.m5.1.1.2.cmml">L</mi><mtext id="A1.p1.5.m5.1.1.3" xref="A1.p1.5.m5.1.1.3a.cmml">KL</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b"><apply id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A1.p1.5.m5.1.1.1.cmml" xref="A1.p1.5.m5.1.1">subscript</csymbol><ci id="A1.p1.5.m5.1.1.2.cmml" xref="A1.p1.5.m5.1.1.2">𝐿</ci><ci id="A1.p1.5.m5.1.1.3a.cmml" xref="A1.p1.5.m5.1.1.3"><mtext id="A1.p1.5.m5.1.1.3.cmml" mathsize="70%" xref="A1.p1.5.m5.1.1.3">KL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">L_{\text{KL}}</annotation><annotation encoding="application/x-llamapun" id="A1.p1.5.m5.1d">italic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT</annotation></semantics></math> is the standard KL-regularization term to encourage encoder outputs towards a normal distribution.
We delay the beginning of GAN training (i.e. including the adversarial loss in the loss function) to 50,000 steps, in order to let the VAE achieve sufficiently good reconstruction performance.
We use a latent dimension of 8.</p>
</div>
<div class="ltx_para" id="A1.p2">
<p class="ltx_p" id="A1.p2.4">The training objective for the VQ-GAN matches that of the VAE, with one notable exception: we replace the <math alttext="\mathcal{L}_{\text{KL}}" class="ltx_Math" display="inline" id="A1.p2.1.m1.1"><semantics id="A1.p2.1.m1.1a"><msub id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.p2.1.m1.1.1.2" xref="A1.p2.1.m1.1.1.2.cmml">ℒ</mi><mtext id="A1.p2.1.m1.1.1.3" xref="A1.p2.1.m1.1.1.3a.cmml">KL</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><apply id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.p2.1.m1.1.1.1.cmml" xref="A1.p2.1.m1.1.1">subscript</csymbol><ci id="A1.p2.1.m1.1.1.2.cmml" xref="A1.p2.1.m1.1.1.2">ℒ</ci><ci id="A1.p2.1.m1.1.1.3a.cmml" xref="A1.p2.1.m1.1.1.3"><mtext id="A1.p2.1.m1.1.1.3.cmml" mathsize="70%" xref="A1.p2.1.m1.1.1.3">KL</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">\mathcal{L}_{\text{KL}}</annotation><annotation encoding="application/x-llamapun" id="A1.p2.1.m1.1d">caligraphic_L start_POSTSUBSCRIPT KL end_POSTSUBSCRIPT</annotation></semantics></math> loss with the standard codebook commitment loss <math alttext="\mathcal{L}_{\text{codebook}}" class="ltx_Math" display="inline" id="A1.p2.2.m2.1"><semantics id="A1.p2.2.m2.1a"><msub id="A1.p2.2.m2.1.1" xref="A1.p2.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.p2.2.m2.1.1.2" xref="A1.p2.2.m2.1.1.2.cmml">ℒ</mi><mtext id="A1.p2.2.m2.1.1.3" xref="A1.p2.2.m2.1.1.3a.cmml">codebook</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.p2.2.m2.1b"><apply id="A1.p2.2.m2.1.1.cmml" xref="A1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.p2.2.m2.1.1.1.cmml" xref="A1.p2.2.m2.1.1">subscript</csymbol><ci id="A1.p2.2.m2.1.1.2.cmml" xref="A1.p2.2.m2.1.1.2">ℒ</ci><ci id="A1.p2.2.m2.1.1.3a.cmml" xref="A1.p2.2.m2.1.1.3"><mtext id="A1.p2.2.m2.1.1.3.cmml" mathsize="70%" xref="A1.p2.2.m2.1.1.3">codebook</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.2.m2.1c">\mathcal{L}_{\text{codebook}}</annotation><annotation encoding="application/x-llamapun" id="A1.p2.2.m2.1d">caligraphic_L start_POSTSUBSCRIPT codebook end_POSTSUBSCRIPT</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">[Van Den Oord et al., <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#bib.bib48" title="">2017</a>]</cite>, which encourages encoder outputs and codebook vectors to be close together.
We use <math alttext="\beta=0.25" class="ltx_Math" display="inline" id="A1.p2.3.m3.1"><semantics id="A1.p2.3.m3.1a"><mrow id="A1.p2.3.m3.1.1" xref="A1.p2.3.m3.1.1.cmml"><mi id="A1.p2.3.m3.1.1.2" xref="A1.p2.3.m3.1.1.2.cmml">β</mi><mo id="A1.p2.3.m3.1.1.1" xref="A1.p2.3.m3.1.1.1.cmml">=</mo><mn id="A1.p2.3.m3.1.1.3" xref="A1.p2.3.m3.1.1.3.cmml">0.25</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.p2.3.m3.1b"><apply id="A1.p2.3.m3.1.1.cmml" xref="A1.p2.3.m3.1.1"><eq id="A1.p2.3.m3.1.1.1.cmml" xref="A1.p2.3.m3.1.1.1"></eq><ci id="A1.p2.3.m3.1.1.2.cmml" xref="A1.p2.3.m3.1.1.2">𝛽</ci><cn id="A1.p2.3.m3.1.1.3.cmml" type="float" xref="A1.p2.3.m3.1.1.3">0.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.3.m3.1c">\beta=0.25</annotation><annotation encoding="application/x-llamapun" id="A1.p2.3.m3.1d">italic_β = 0.25</annotation></semantics></math>, and use loss weighting <math alttext="1.0" class="ltx_Math" display="inline" id="A1.p2.4.m4.1"><semantics id="A1.p2.4.m4.1a"><mn id="A1.p2.4.m4.1.1" xref="A1.p2.4.m4.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A1.p2.4.m4.1b"><cn id="A1.p2.4.m4.1.1.cmml" type="float" xref="A1.p2.4.m4.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.4.m4.1c">1.0</annotation><annotation encoding="application/x-llamapun" id="A1.p2.4.m4.1d">1.0</annotation></semantics></math>.
The final loss function for the VQ-VAE is therefore:</p>
<table class="ltx_equation ltx_eqn_table" id="A1.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\text{VQ-VAE}}=\mathcal{L}_{1}+\mathcal{L}_{\text{LPIPS}}+0.5%
\mathcal{L}_{\text{GAN}}+0.2\mathcal{L}_{\text{ID}}+\mathcal{L}_{\text{%
codebook}}" class="ltx_Math" display="block" id="A1.Ex2.m1.1"><semantics id="A1.Ex2.m1.1a"><mrow id="A1.Ex2.m1.1.1" xref="A1.Ex2.m1.1.1.cmml"><msub id="A1.Ex2.m1.1.1.2" xref="A1.Ex2.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex2.m1.1.1.2.2" xref="A1.Ex2.m1.1.1.2.2.cmml">ℒ</mi><mtext id="A1.Ex2.m1.1.1.2.3" xref="A1.Ex2.m1.1.1.2.3a.cmml">VQ-VAE</mtext></msub><mo id="A1.Ex2.m1.1.1.1" xref="A1.Ex2.m1.1.1.1.cmml">=</mo><mrow id="A1.Ex2.m1.1.1.3" xref="A1.Ex2.m1.1.1.3.cmml"><msub id="A1.Ex2.m1.1.1.3.2" xref="A1.Ex2.m1.1.1.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex2.m1.1.1.3.2.2" xref="A1.Ex2.m1.1.1.3.2.2.cmml">ℒ</mi><mn id="A1.Ex2.m1.1.1.3.2.3" xref="A1.Ex2.m1.1.1.3.2.3.cmml">1</mn></msub><mo id="A1.Ex2.m1.1.1.3.1" xref="A1.Ex2.m1.1.1.3.1.cmml">+</mo><msub id="A1.Ex2.m1.1.1.3.3" xref="A1.Ex2.m1.1.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex2.m1.1.1.3.3.2" xref="A1.Ex2.m1.1.1.3.3.2.cmml">ℒ</mi><mtext id="A1.Ex2.m1.1.1.3.3.3" xref="A1.Ex2.m1.1.1.3.3.3a.cmml">LPIPS</mtext></msub><mo id="A1.Ex2.m1.1.1.3.1a" xref="A1.Ex2.m1.1.1.3.1.cmml">+</mo><mrow id="A1.Ex2.m1.1.1.3.4" xref="A1.Ex2.m1.1.1.3.4.cmml"><mn id="A1.Ex2.m1.1.1.3.4.2" xref="A1.Ex2.m1.1.1.3.4.2.cmml">0.5</mn><mo id="A1.Ex2.m1.1.1.3.4.1" xref="A1.Ex2.m1.1.1.3.4.1.cmml">⁢</mo><msub id="A1.Ex2.m1.1.1.3.4.3" xref="A1.Ex2.m1.1.1.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex2.m1.1.1.3.4.3.2" xref="A1.Ex2.m1.1.1.3.4.3.2.cmml">ℒ</mi><mtext id="A1.Ex2.m1.1.1.3.4.3.3" xref="A1.Ex2.m1.1.1.3.4.3.3a.cmml">GAN</mtext></msub></mrow><mo id="A1.Ex2.m1.1.1.3.1b" xref="A1.Ex2.m1.1.1.3.1.cmml">+</mo><mrow id="A1.Ex2.m1.1.1.3.5" xref="A1.Ex2.m1.1.1.3.5.cmml"><mn id="A1.Ex2.m1.1.1.3.5.2" xref="A1.Ex2.m1.1.1.3.5.2.cmml">0.2</mn><mo id="A1.Ex2.m1.1.1.3.5.1" xref="A1.Ex2.m1.1.1.3.5.1.cmml">⁢</mo><msub id="A1.Ex2.m1.1.1.3.5.3" xref="A1.Ex2.m1.1.1.3.5.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex2.m1.1.1.3.5.3.2" xref="A1.Ex2.m1.1.1.3.5.3.2.cmml">ℒ</mi><mtext id="A1.Ex2.m1.1.1.3.5.3.3" xref="A1.Ex2.m1.1.1.3.5.3.3a.cmml">ID</mtext></msub></mrow><mo id="A1.Ex2.m1.1.1.3.1c" xref="A1.Ex2.m1.1.1.3.1.cmml">+</mo><msub id="A1.Ex2.m1.1.1.3.6" xref="A1.Ex2.m1.1.1.3.6.cmml"><mi class="ltx_font_mathcaligraphic" id="A1.Ex2.m1.1.1.3.6.2" xref="A1.Ex2.m1.1.1.3.6.2.cmml">ℒ</mi><mtext id="A1.Ex2.m1.1.1.3.6.3" xref="A1.Ex2.m1.1.1.3.6.3a.cmml">codebook</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.Ex2.m1.1b"><apply id="A1.Ex2.m1.1.1.cmml" xref="A1.Ex2.m1.1.1"><eq id="A1.Ex2.m1.1.1.1.cmml" xref="A1.Ex2.m1.1.1.1"></eq><apply id="A1.Ex2.m1.1.1.2.cmml" xref="A1.Ex2.m1.1.1.2"><csymbol cd="ambiguous" id="A1.Ex2.m1.1.1.2.1.cmml" xref="A1.Ex2.m1.1.1.2">subscript</csymbol><ci id="A1.Ex2.m1.1.1.2.2.cmml" xref="A1.Ex2.m1.1.1.2.2">ℒ</ci><ci id="A1.Ex2.m1.1.1.2.3a.cmml" xref="A1.Ex2.m1.1.1.2.3"><mtext id="A1.Ex2.m1.1.1.2.3.cmml" mathsize="70%" xref="A1.Ex2.m1.1.1.2.3">VQ-VAE</mtext></ci></apply><apply id="A1.Ex2.m1.1.1.3.cmml" xref="A1.Ex2.m1.1.1.3"><plus id="A1.Ex2.m1.1.1.3.1.cmml" xref="A1.Ex2.m1.1.1.3.1"></plus><apply id="A1.Ex2.m1.1.1.3.2.cmml" xref="A1.Ex2.m1.1.1.3.2"><csymbol cd="ambiguous" id="A1.Ex2.m1.1.1.3.2.1.cmml" xref="A1.Ex2.m1.1.1.3.2">subscript</csymbol><ci id="A1.Ex2.m1.1.1.3.2.2.cmml" xref="A1.Ex2.m1.1.1.3.2.2">ℒ</ci><cn id="A1.Ex2.m1.1.1.3.2.3.cmml" type="integer" xref="A1.Ex2.m1.1.1.3.2.3">1</cn></apply><apply id="A1.Ex2.m1.1.1.3.3.cmml" xref="A1.Ex2.m1.1.1.3.3"><csymbol cd="ambiguous" id="A1.Ex2.m1.1.1.3.3.1.cmml" xref="A1.Ex2.m1.1.1.3.3">subscript</csymbol><ci id="A1.Ex2.m1.1.1.3.3.2.cmml" xref="A1.Ex2.m1.1.1.3.3.2">ℒ</ci><ci id="A1.Ex2.m1.1.1.3.3.3a.cmml" xref="A1.Ex2.m1.1.1.3.3.3"><mtext id="A1.Ex2.m1.1.1.3.3.3.cmml" mathsize="70%" xref="A1.Ex2.m1.1.1.3.3.3">LPIPS</mtext></ci></apply><apply id="A1.Ex2.m1.1.1.3.4.cmml" xref="A1.Ex2.m1.1.1.3.4"><times id="A1.Ex2.m1.1.1.3.4.1.cmml" xref="A1.Ex2.m1.1.1.3.4.1"></times><cn id="A1.Ex2.m1.1.1.3.4.2.cmml" type="float" xref="A1.Ex2.m1.1.1.3.4.2">0.5</cn><apply id="A1.Ex2.m1.1.1.3.4.3.cmml" xref="A1.Ex2.m1.1.1.3.4.3"><csymbol cd="ambiguous" id="A1.Ex2.m1.1.1.3.4.3.1.cmml" xref="A1.Ex2.m1.1.1.3.4.3">subscript</csymbol><ci id="A1.Ex2.m1.1.1.3.4.3.2.cmml" xref="A1.Ex2.m1.1.1.3.4.3.2">ℒ</ci><ci id="A1.Ex2.m1.1.1.3.4.3.3a.cmml" xref="A1.Ex2.m1.1.1.3.4.3.3"><mtext id="A1.Ex2.m1.1.1.3.4.3.3.cmml" mathsize="70%" xref="A1.Ex2.m1.1.1.3.4.3.3">GAN</mtext></ci></apply></apply><apply id="A1.Ex2.m1.1.1.3.5.cmml" xref="A1.Ex2.m1.1.1.3.5"><times id="A1.Ex2.m1.1.1.3.5.1.cmml" xref="A1.Ex2.m1.1.1.3.5.1"></times><cn id="A1.Ex2.m1.1.1.3.5.2.cmml" type="float" xref="A1.Ex2.m1.1.1.3.5.2">0.2</cn><apply id="A1.Ex2.m1.1.1.3.5.3.cmml" xref="A1.Ex2.m1.1.1.3.5.3"><csymbol cd="ambiguous" id="A1.Ex2.m1.1.1.3.5.3.1.cmml" xref="A1.Ex2.m1.1.1.3.5.3">subscript</csymbol><ci id="A1.Ex2.m1.1.1.3.5.3.2.cmml" xref="A1.Ex2.m1.1.1.3.5.3.2">ℒ</ci><ci id="A1.Ex2.m1.1.1.3.5.3.3a.cmml" xref="A1.Ex2.m1.1.1.3.5.3.3"><mtext id="A1.Ex2.m1.1.1.3.5.3.3.cmml" mathsize="70%" xref="A1.Ex2.m1.1.1.3.5.3.3">ID</mtext></ci></apply></apply><apply id="A1.Ex2.m1.1.1.3.6.cmml" xref="A1.Ex2.m1.1.1.3.6"><csymbol cd="ambiguous" id="A1.Ex2.m1.1.1.3.6.1.cmml" xref="A1.Ex2.m1.1.1.3.6">subscript</csymbol><ci id="A1.Ex2.m1.1.1.3.6.2.cmml" xref="A1.Ex2.m1.1.1.3.6.2">ℒ</ci><ci id="A1.Ex2.m1.1.1.3.6.3a.cmml" xref="A1.Ex2.m1.1.1.3.6.3"><mtext id="A1.Ex2.m1.1.1.3.6.3.cmml" mathsize="70%" xref="A1.Ex2.m1.1.1.3.6.3">codebook</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.Ex2.m1.1c">\mathcal{L}_{\text{VQ-VAE}}=\mathcal{L}_{1}+\mathcal{L}_{\text{LPIPS}}+0.5%
\mathcal{L}_{\text{GAN}}+0.2\mathcal{L}_{\text{ID}}+\mathcal{L}_{\text{%
codebook}}</annotation><annotation encoding="application/x-llamapun" id="A1.Ex2.m1.1d">caligraphic_L start_POSTSUBSCRIPT VQ-VAE end_POSTSUBSCRIPT = caligraphic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT LPIPS end_POSTSUBSCRIPT + 0.5 caligraphic_L start_POSTSUBSCRIPT GAN end_POSTSUBSCRIPT + 0.2 caligraphic_L start_POSTSUBSCRIPT ID end_POSTSUBSCRIPT + caligraphic_L start_POSTSUBSCRIPT codebook end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="A1.p2.5">The vector quantization layer is applied after projecting the encoder outputs to 8-dimensional space.
Outside of the loss function change and the quantization layer, the training setup for the VAE (for Transfusion) and VQ-VAE (for Chameleon) are the same (e.g. same amount of training compute, same training data, and same encoder/decoder architecture).</p>
</div>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Examples: Image Generation</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#A3.F7" title="Figure 7 ‣ Appendix C Examples: Image Editing ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">7</span></a> and Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#A3.F8" title="Figure 8 ‣ Appendix C Examples: Image Editing ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">8</span></a> show examples of images generated from a 7B Transfusion model trained on 2T multi-modal tokens (§<a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#S4.SS4" title="4.4 Comparison with Image Generation Literature ‣ 4 Experiments ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">4.4</span></a>).</p>
</div>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Examples: Image Editing</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2408.11039v1#A3.F9" title="Figure 9 ‣ Appendix C Examples: Image Editing ‣ Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model"><span class="ltx_text ltx_ref_tag">9</span></a> show random examples of image editing by a fine-tuned 7B Transfusion model.</p>
</div>
<figure class="ltx_figure" id="A3.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf1.g1" src="extracted/5802141/samples/downtown_seattle_sunset.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf1.2.1.1" style="font-size:90%;">((a))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf2.g1" src="extracted/5802141/samples/vegetable_car.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf2.2.1.1" style="font-size:90%;">((b))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf3.g1" src="extracted/5802141/samples/diffusion_sign.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf3.2.1.1" style="font-size:90%;">((c))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf4.g1" src="extracted/5802141/samples/basketball_shoe.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf4.2.1.1" style="font-size:90%;">((d))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf5.g1" src="extracted/5802141/samples/coffee_from_human_souls.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf5.2.1.1" style="font-size:90%;">((e))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf6.g1" src="extracted/5802141/samples/fox_and_unicorn_2.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf6.2.1.1" style="font-size:90%;">((f))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf7.g1" src="extracted/5802141/samples/yellow_wall.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf7.2.1.1" style="font-size:90%;">((g))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf8.g1" src="extracted/5802141/samples/crab_cheese.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf8.2.1.1" style="font-size:90%;">((h))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf9"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf9.g1" src="extracted/5802141/samples/beam_raccoon.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf9.2.1.1" style="font-size:90%;">((i))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf10"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf10.g1" src="extracted/5802141/samples/greek_island.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf10.2.1.1" style="font-size:90%;">((j))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf11"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf11.g1" src="extracted/5802141/samples/be_excellent_to_each_toher.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf11.2.1.1" style="font-size:90%;">((k))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf12"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf12.g1" src="extracted/5802141/samples/cave_tree.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf12.2.1.1" style="font-size:90%;">((l))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf13"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf13.g1" src="extracted/5802141/samples/cow_man_tie.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf13.2.1.1" style="font-size:90%;">((m))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf14"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf14.g1" src="extracted/5802141/samples/lychee_chair_2.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf14.2.1.1" style="font-size:90%;">((n))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf15"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf15.g1" src="extracted/5802141/samples/old_rusted_robot.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf15.2.1.1" style="font-size:90%;">((o))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F7.sf16"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F7.sf16.g1" src="extracted/5802141/samples/burger.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.sf16.2.1.1" style="font-size:90%;">((p))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F7.2.1.1" style="font-size:90%;">Figure 7</span>: </span><span class="ltx_text" id="A3.F7.3.2" style="font-size:90%;">Generated images from a 7B Transfusion trained on 2T multi-modal tokens.</span></figcaption>
</figure>
<figure class="ltx_figure" id="A3.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf1.g1" src="extracted/5802141/samples/woman_under_blanket.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf1.2.1.1" style="font-size:90%;">((a))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf2.g1" src="extracted/5802141/samples/small_blue_book_red_large_book.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf2.2.1.1" style="font-size:90%;">((b))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf3.g1" src="extracted/5802141/samples/horse_read_a_book.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf3.2.1.1" style="font-size:90%;">((c))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf4.g1" src="extracted/5802141/samples/light_bulb_sailboat.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf4.2.1.1" style="font-size:90%;">((d))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf5.g1" src="extracted/5802141/samples/monarch_butterfly.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf5.2.1.1" style="font-size:90%;">((e))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf6.g1" src="extracted/5802141/samples/rowboat_bike.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf6.2.1.1" style="font-size:90%;">((f))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf7.g1" src="extracted/5802141/samples/cookie_dip.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf7.2.1.1" style="font-size:90%;">((g))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf8.g1" src="extracted/5802141/samples/angry_duck_1.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf8.2.1.1" style="font-size:90%;">((h))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf9"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf9.g1" src="extracted/5802141/samples/panda_with_red_hat.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf9.2.1.1" style="font-size:90%;">((i))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf10"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf10.g1" src="extracted/5802141/samples/japanese_garden.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf10.2.1.1" style="font-size:90%;">((j))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf11"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf11.g1" src="extracted/5802141/samples/spaceship_pretzel.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf11.2.1.1" style="font-size:90%;">((k))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf12"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf12.g1" src="extracted/5802141/samples/graffiti_dog.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf12.2.1.1" style="font-size:90%;">((l))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf13"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf13.g1" src="extracted/5802141/samples/spacious_japanese_room.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf13.2.1.1" style="font-size:90%;">((m))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf14"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf14.g1" src="extracted/5802141/samples/raccoon_cowboy.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf14.2.1.1" style="font-size:90%;">((n))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf15"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf15.g1" src="extracted/5802141/samples/floating_garlic.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf15.2.1.1" style="font-size:90%;">((o))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F8.sf16"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="138" id="A3.F8.sf16.g1" src="extracted/5802141/samples/bear_in_the_river.jpg" width="138"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.sf16.2.1.1" style="font-size:90%;">((p))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F8.2.1.1" style="font-size:90%;">Figure 8</span>: </span><span class="ltx_text" id="A3.F8.3.2" style="font-size:90%;">Generated images from a 7B Transfusion trained on 2T multi-modal tokens.</span></figcaption>
</figure>
<figure class="ltx_figure" id="A3.F9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F9.sf1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf1.g1" src="extracted/5802141/img_edit_samples/0_change_cloest_keyboard_to_black.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf1.g2" src="extracted/5802141/img_edit_samples/1_change_cloest_keyboard_to_black.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.sf1.2.1.1" style="font-size:90%;">((a))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F9.sf2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf2.g1" src="extracted/5802141/img_edit_samples/0_calligraphy.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf2.g2" src="extracted/5802141/img_edit_samples/1_calligraphy.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.sf2.2.1.1" style="font-size:90%;">((b))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F9.sf3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf3.g1" src="extracted/5802141/img_edit_samples/0_mountains.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf3.g2" src="extracted/5802141/img_edit_samples/1_mountains.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.sf3.2.1.1" style="font-size:90%;">((c))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F9.sf4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf4.g1" src="extracted/5802141/img_edit_samples/0_helicopter.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf4.g2" src="extracted/5802141/img_edit_samples/1_helicopter.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.sf4.2.1.1" style="font-size:90%;">((d))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F9.sf5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf5.g1" src="extracted/5802141/img_edit_samples/0_add_blue_rug.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf5.g2" src="extracted/5802141/img_edit_samples/1_add_blue_rug.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.sf5.2.1.1" style="font-size:90%;">((e))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F9.sf6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf6.g1" src="extracted/5802141/img_edit_samples/0_remove_light.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf6.g2" src="extracted/5802141/img_edit_samples/2_remove_light.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.sf6.2.1.1" style="font-size:90%;">((f))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F9.sf7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf7.g1" src="extracted/5802141/img_edit_samples/0_thread_to_wire.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf7.g2" src="extracted/5802141/img_edit_samples/1_thread_to_wire.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.sf7.2.1.1" style="font-size:90%;">((g))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A3.F9.sf8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf8.g1" src="extracted/5802141/img_edit_samples/0_change_bat_to_brown.jpg" width="138"/></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img alt="Refer to caption" class="ltx_graphics ltx_figure_panel ltx_img_square" height="138" id="A3.F9.sf8.g2" src="extracted/5802141/img_edit_samples/1_change_bat_to_brown.jpg" width="138"/></div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.sf8.2.1.1" style="font-size:90%;">((h))</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A3.F9.2.1.1" style="font-size:90%;">Figure 9</span>: </span><span class="ltx_text" id="A3.F9.3.2" style="font-size:90%;">Edited images from a fine-tuned 7B Transfusion model.</span></figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Aug 20 08:57:06 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
